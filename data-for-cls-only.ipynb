{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves images from \"full_imgs\" and stores each VOI separately in \"train_imgs\". Retrieves spreadsheet listing VOIs and stores them in text file. Requires data-retrieval to be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import helper_fxns as hf\n",
    "import transforms as tr\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(\"train_list.txt\", \"r\") as f:\n",
    "    vois = [x.split(',') for x in f.read().split(\"\\n\")]\n",
    "\n",
    "voi_df = pd.DataFrame(vois, columns = [\"Filename\", \"x1\", \"x2\", \"y1\", \"y2\", \"z1\", \"z2\", \"cls\"]).dropna()\n",
    "voi_df = voi_df.astype({\"x1\": int, \"x2\": int, \"y1\": int, \"y2\": int, \"z1\": int, \"z2\": int})\n",
    "\n",
    "voi_df['dx'] = voi_df.apply(lambda row: row['x2'] - row['x1'], axis=1)\n",
    "voi_df['dy'] = voi_df.apply(lambda row: row['y2'] - row['y1'], axis=1)\n",
    "voi_df['dz'] = voi_df.apply(lambda row: row['z2'] - row['z1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\config.py'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = config.Config()\n",
    "final_size = C.dims\n",
    "\n",
    "voi_df = pd.read_csv('vois.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voi_df = voi_df[~voi_df['cls'].isin(['colorectal', 'adenoma', 'fnh'])]\n",
    "#set(voi_df['cls'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(img, final_size, num_samples = 100, translate=None):\n",
    "    aug_imgs = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        temp_img = img\n",
    "        angle = random.randint(0, 359)\n",
    "        temp_img = tr.rotate(temp_img, angle)\n",
    "        \n",
    "        #scales = [0.9, 1.1]\n",
    "        #scale = [random.uniform(scales[0],scales[1]), random.uniform(scales[0],scales[1]), random.uniform(scales[0],scales[1])]\n",
    "        #temp_img = tr.scale3d(temp_img, scale)\n",
    "        \n",
    "        if translate is not None:\n",
    "            trans = [random.randint(-translate[0], translate[0]),\n",
    "                     random.randint(-translate[1], translate[1]),\n",
    "                     random.randint(-translate[2], translate[2])]\n",
    "        else:\n",
    "            trans = [0,0,0]\n",
    "        \n",
    "        flip = [random.choice([-1, 1]), random.choice([-1, 1]), random.choice([-1, 1])]\n",
    "        \n",
    "        crops = [temp_img.shape[i] - final_size[i] for i in range(3)]\n",
    "        \n",
    "        aug_imgs.append(temp_img[math.floor(crops[0]/2)*flip[0] + trans[0] : -math.ceil(crops[0]/2)*flip[0] + trans[0] : flip[0],\n",
    "                                 math.floor(crops[1]/2)*flip[1] + trans[1] : -math.ceil(crops[1]/2)*flip[1] + trans[1] : flip[1],\n",
    "                                 math.floor(crops[2]/2)*flip[2] + trans[2] : -math.ceil(crops[2]/2)*flip[2] + trans[2] : flip[2], :])\n",
    "    \n",
    "    return aug_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_voi(img, voi, final_size, aug=False):\n",
    "    \"\"\"Input: image, a voi from the image (as pd.Series), target size in voxels, and whether to augment.\n",
    "    Outputs list of images (np.ndarray) and list of classes (string).\n",
    "    Assumes that there is no voi so close to the edge that getting a volume of size final_size would make it go out of bounds.\n",
    "    \"\"\"\n",
    "    voi_imgs = []\n",
    "    classes = []\n",
    "    \n",
    "    # if augmenting, take a larger volume from the original image so rotating it will not cut off any part\n",
    "    if aug:\n",
    "        crop_size = [math.ceil(x*math.sqrt(2)) for x in final_size]\n",
    "    else:\n",
    "        crop_size = final_size\n",
    "    \n",
    "    exceed_ratio = max(voi['dx']/crop_size[0], voi['dy']/crop_size[1], voi['dz']/crop_size[2], 1) / 1\n",
    "\n",
    "    # downscale image until it fits in final_size and cannot be cut off by rotation\n",
    "    if exceed_ratio > 1:\n",
    "        temp_img = tr.scale3d(img, [1/exceed_ratio]*3)\n",
    "        x1 = round(voi['x1'] / exceed_ratio)\n",
    "        x2 = round(voi['x2'] / exceed_ratio)\n",
    "        y1 = round(voi['y1'] / exceed_ratio)\n",
    "        y2 = round(voi['y2'] / exceed_ratio)\n",
    "        z1 = round(voi['z1'] / exceed_ratio)\n",
    "        z2 = round(voi['z2'] / exceed_ratio)\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dz = z2 - z1\n",
    "    else:\n",
    "        temp_img = copy.deepcopy(img)\n",
    "        x1 = voi['x1']\n",
    "        x2 = voi['x2']\n",
    "        y1 = voi['y1']\n",
    "        y2 = voi['y2']\n",
    "        z1 = voi['z1']\n",
    "        z2 = voi['z2']\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dz = z2 - z1\n",
    "        \n",
    "    xpad = max(crop_size[0] - dx,0)\n",
    "    ypad = max(crop_size[1] - dy,0)\n",
    "    zpad = max(crop_size[2] - dz,0)\n",
    "\n",
    "    \"\"\"plt.subplot(121)\n",
    "    plt.imshow(np.transpose(img[voi['x1']:voi['x2'],\n",
    "                                voi['y2']:voi['y1']:-1,\n",
    "                                (voi['z1']+voi['z2'])//2, 0], (1,0)), cmap='gray')\"\"\"\n",
    "\n",
    "    side_padding = math.ceil(max(xpad, ypad, zpad) / 2)\n",
    "\n",
    "    pad_img = []\n",
    "\n",
    "    for ch in range(temp_img.shape[-1]):\n",
    "        pad_img.append(np.pad(temp_img[:,:,:,ch], side_padding, 'constant'))\n",
    "\n",
    "    pad_img = np.stack(pad_img, axis=3)\n",
    "\n",
    "    x1 += side_padding - math.ceil(xpad/2)\n",
    "    x2 += side_padding + math.floor(xpad/2)\n",
    "    y1 += side_padding - math.ceil(ypad/2)\n",
    "    y2 += side_padding + math.floor(ypad/2)\n",
    "    z1 += side_padding - math.ceil(zpad/2)\n",
    "    z2 += side_padding + math.floor(zpad/2)\n",
    "\n",
    "    pad_img = pad_img[x1:x2, y1:y2, z1:z2, :]\n",
    "        \n",
    "    if aug:\n",
    "        aug_imgs = augment(pad_img, final_size, translate=[1,1,0], num_samples = C.aug_factor[voi['cls']])\n",
    "        voi_imgs = voi_imgs + aug_imgs\n",
    "        classes = classes + [voi['cls']] * len(aug_imgs)\n",
    "\n",
    "    else:\n",
    "        voi_imgs = [pad_img]\n",
    "        if voi_imgs[0].shape[0] != final_size[0] or voi_imgs[0].shape[1] != final_size[1] or voi_imgs[0].shape[2] != final_size[2]:\n",
    "            print(voi)\n",
    "            print(x1,x2,y1,y2,z1,z2)\n",
    "            print(voi_imgs[0].shape, final_size, zpad)\n",
    "            raise ValueError(\"zzz\")\n",
    "        \n",
    "        classes = [voi['cls']]\n",
    "\n",
    "    \"\"\"img = pad_img\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.transpose(img[voi['x1']:voi['x2'],\n",
    "                                voi['y2']:voi['y1']:-1,\n",
    "                                (voi['z1']+voi['z2'])//2, 1], (1,0)), cmap='gray')\"\"\"\n",
    "        \n",
    "    return voi_imgs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path aug_imgs\\ already exists.\n",
      "...."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-4cd502e9f105>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# iterate over each voi in that image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvoi_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvois\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mcropped_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_voi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-8ca7fbfe3627>\u001b[0m in \u001b[0;36mextract_voi\u001b[1;34m(img, voi, final_size, aug)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mpad_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside_padding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mpad_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \u001b[1;31m# If we get here, use new padding method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m     \u001b[0mnewmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m     \u001b[1;31m# API preserved, but completely new algorithm which pads by building the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aug=True\n",
    "t = time.time()\n",
    "\n",
    "if os.path.exists(C.aug_dir):\n",
    "    print(\"Path\", C.aug_dir, \"already exists.\")\n",
    "    exit(0)\n",
    "else:\n",
    "    os.makedirs(C.aug_dir)\n",
    "if not os.path.exists(C.orig_dir):\n",
    "    os.makedirs(C.orig_dir)\n",
    "    \n",
    "# iterate over image series\n",
    "for img_fn in os.listdir(\"full_imgs\\\\\"):\n",
    "    img = np.load(\"full_imgs\\\\\"+img_fn)\n",
    "    vois = voi_df[voi_df[\"Filename\"] == img_fn]\n",
    "    \n",
    "    # iterate over each voi in that image\n",
    "    for voi_num, voi in enumerate(vois.iterrows()):\n",
    "        cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=aug)\n",
    "\n",
    "        if not os.path.exists(C.orig_dir+classes[0]):\n",
    "            os.makedirs(C.orig_dir+classes[0])\n",
    "        if not os.path.exists(C.aug_dir+classes[0]):\n",
    "            os.makedirs(C.aug_dir+classes[0])\n",
    "\n",
    "        for i in range(len(cropped_imgs)):\n",
    "            np.save(C.aug_dir+classes[i]+\"\\\\\"+img_fn[:-4]+\"_\"+str(voi_num)+\"_\"+str(i), cropped_imgs[i])\n",
    "    \n",
    "        # save unaugmented vois as well\n",
    "        if aug:\n",
    "            cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=False)\n",
    "            i = 0\n",
    "            fn_stem = C.orig_dir+classes[i]+\"\\\\\"+img_fn[:-4]+\"_\"\n",
    "            while os.path.exists(fn_stem + str(i) + \".npy\"):\n",
    "                i += 1\n",
    "            np.save(fn_stem + str(i), cropped_imgs[0])\n",
    "        \n",
    "        if voi_num % 20 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "print(\"\") \n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in os.listdir(\"train_imgs\\\\hcc\\\\\"):\n",
    "    if x[-6] != \"_\" and int(x[-6:-4]) > 30:\n",
    "        os.remove(\"train_imgs\\\\hcc\\\\\" + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x for x in os.listdir(\"train_imgs\\\\hcc\\\\\") if x[-6] != \"_\" and int(x[-6:-4]) > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.listdir(\"train_imgs\\\\hcc\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1731015d438>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEU5JREFUeJzt3V9o3fd5x/HPY1nyH0lxZDsWSuzEdmwn1s1cMKYkYaR0\nKW5vnEIIDWH4ouBeZGaFQgi9aW8GuWm7XpSCu5h40MYrtFl8ETZSM8gGo9QtoXGbDQfjkQjHnmM7\n/iNLsuRnFzoC1bX0fSR99TvSnvcLgo6OHp/zPb/f+eSnc86j52fuLgD5rGj3AgC0B+EHkiL8QFKE\nH0iK8ANJEX4gKcIPJEX4gaQIP5DUyibvzMyK7YSdnZ3F21m/fn3kvqrUdHR0VLkdSVq5sry5V6wo\n//+4Vs2dO3eKNaOjo8WakZGRYs3ExESV9URqIvtj9erVxRpJ6u7urnJbkX1/+fLlYs1HH31UrHH3\n0BNyQeE3s/2SfiipQ9I/uPurC7k9Sdq4cWOx5sUXXyzWRDZ2ZKf19PRUuS9J6u/vL9asXbu2WNPV\n1VXldm7dulWsOXv2bLHmzJkzxZpPP/20WDM8PFysuX37drEm8j++Xbt2FWskad++fcWaxx9/vFiz\nadOmYs3x48eLNYcPHy7WRM37134z65D0I0lfljQo6QUzG6y1MACLayGv+fdJ+tDdz7r7mKTjkg7U\nWRaAxbaQ8D8kafoLkI9b1wFYBhb9DT8zOyTp0GLfD4C5WUj4hyRtmfb95tZ1f8Ldj0g6IsXe7QfQ\njIX82v8bSTvNbJuZdUn6mqQTdZYFYLHN+8jv7uNm9jeS/lWTH/Uddfc/VFsZgEW1oNf87v62pLej\n9WZW/Gz9mWeeKd7O+Ph4sSbyeXCtxpPe3t5ijRT7HLuWyLovXbpUrLly5UqV+4o0AkX2a+S+IqL7\nIvL4b9y4UayJNKY999xzxZqBgYFZf/7yyy8Xb2MK7b1AUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTh\nB5JqdJJPb2+vnnjiiVlrIgM2ak2OqTXtJzJ9SIpNxYk0sUQamCK3Exmw8dlnnxVrrl69WqyJNNVE\n9lmtKUaR55BU77GNjY0VayJDWp588slZfx4ZPjOFIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4\ngaQabfJZuXKl+vr6Zq2JnEUmMvElcsaaSFOJe3nmaKSpRJJu3rxZrKl1CrHIY4s0+USaXCI1165d\nK9asWbOmWFOrySeyX6V6pyuL1ESafKKnhovgyA8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKlG\nm3wmJiaKpzaKTDyJNPBEJgLVaqiJnvopUheZwBNpYok0p1y/fr1YEzldVa1TekVqajW5rFq1KlQX\nmdIUec5GaiLNaytX1ossR34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0k13uRTmugSmbASaXSI\nNIxE7qtWY44UO81WpIklMqUn0jASeWyRyUqRpqPI44rs10jTVW9vb7Em0gQmxZp8Io8/su8j+yw6\nNSqCIz+Q1IKO/GZ2TtJ1SROSxt19b41FAVh8NX7t/4K7X6pwOwAaxK/9QFILDb9L+pWZ/dbMDt2r\nwMwOmdkpMzsVedMDQDMW+mv/U+4+ZGabJL1jZv/l7u9OL3D3I5KOSFJvb29sWDqARbegI7+7D7W+\nXpT0pqR9NRYFYPHNO/xm1m1mvVOXJX1J0ulaCwOwuBbya3+/pDdbzRsrJf3M3f9loQuKNFVEmmoi\nk1NKU4WkWENNtMkn0sRR6xRikaaayLoj64ncV6QmMl0n0pwTeQ5FmoWk2NSoyP6o1XRWeg5FT0Mm\nLSD87n5W0l/M998DaC8+6gOSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFSjY7xWrFihNWvWzFpT\nq1sqMn5qZGSkWBPpFot0wUmxUU6Rmu7u7mJNrXFg0e7FkshorcjjqnUOxsh9SfVGi0XGb0W2danj\ncC7nMuTIDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqUabfMys2BARGXUVqRkdHS3WRJozao1f\nioo0w0TWXas5JTJaK9LA0tXVVazp6empcl+RNUdqpHojwSLrjtxXaTvO5Vx+HPmBpAg/kBThB5Ii\n/EBShB9IivADSRF+ICnCDyTVaJOPuxebZiLn2ItMc4modV686HoijS6R24rUPPDAA1VuJ9JQFdln\n0WlHJaVJUFJsmk2kCUqKNfDUOn9grcasKI78QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSarTJ\nRypPxqk1OabWaaYijTnRUz+tW7euWHP//fcXa3bs2FGsWb9+fWhNJTdv3izW3Lhxo1gzPDxcrKnV\nnBNZT6RZSIpNFyqdQkuq18BTq1lKChz5zeyomV00s9PTrltvZu+Y2ZnW175qKwLQiMiv/a9L2n/X\nda9IOunuOyWdbH0PYBkpht/d35V0+a6rD0g61rp8TNKzldcFYJHN9zV/v7ufb13+RFL/TIVmdkjS\nIaneH+QAWLgFv9vvk3/2NuOfvrn7EXff6+57I2+eAWjGfMN/wcwGJKn19WK9JQFownzDf0LSwdbl\ng5LeqrMcAE2JfNT3hqT/lPSYmX1sZl+X9KqkZ8zsjKS/an0PYBkpvuHn7i/M8KMvzvXO3L049SXS\n6BBpBomIvAEZabrp75/x/c4/sX379mLN1q1bizUbNmwo1kTeX4lMKbpy5UqxJtIINDIyUqyJNG9F\nbifSKBZp3pFizVKRU6xF9kfkeV3ruS/R3gukRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKlGJ/nc\nuXNHt27dmrUm0qARaQSKTFeJNMts27atWLN79+5ijSQNDAwUayJNJZFtFDmFVmTiTaQ5JdKc09dX\nnvcSmb4UeVyl55gUa8yRYs+RyKm4ajXwlB5/pHFrCkd+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK\n8ANJNdrk4+4aHx+ftSbSwBKpiTTLRJpzdu3aVazZvHlzsUaKTY+JNDBFmliuXr1arLl+/XqxJtLA\nE2kEipyuKjJZKdLEEjk1WPR0XZH9cfv27WJNZDuOjo4Wa0qPfy6nqePIDyRF+IGkCD+QFOEHkiL8\nQFKEH0iK8ANJEX4gqUabfMys2DQRafTo7u4u1jz22GPFmh07dhRrHn744SrrkWINI5FGj0gDz9DQ\nULEm0pwSaYZZt25dsSbS5BLZPhGR/RGZviNJExMTxZrIY6t1mq25NPGUcOQHkiL8QFKEH0iK8ANJ\nEX4gKcIPJEX4gaQIP5BU400+pSk8kdMoDQ4OFmsiDTyPPPJIsSZymqloA0ekQSNSE5nkU5qYJMWm\n4kQaWCJTeiLNMpH11JoaVHOfRRqGIs1rtRqBoop71syOmtlFMzs97brvmtmQmb3X+u8ri7tMALVF\nfu1/XdL+e1z/A3ff0/rv7brLArDYiuF393clXW5gLQAatJA3/A6b2e9bLwvKL4wBLCnzDf+PJW2X\ntEfSeUnfm6nQzA6Z2SkzOxX5KzIAzZhX+N39grtPuPsdST+RtG+W2iPuvtfd90b/jBLA4ptX+M1s\nYNq3X5V0eqZaAEtT8QNRM3tD0tOSNprZx5K+I+lpM9sjySWdk/SNRVwjgEVQDL+7v3CPq1+bz511\ndHQUm2Z27txZvJ1aTT79/f3Fmsh0mUhDjRRrGIlMoYk0QkUaZiKNN5FJPpFGoIhIk0tkf0S2c833\nnyKNRxFNvydGey+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQaneTT1dWlLVu2zFoTaeCJNAJt\n2LChWFOaKiTVm3YjxRpUIlN6Nm3aVKy57777ijVjY2PFmlrThyLbKNIsE7mvyCnPog01kXXX2o41\nJhnNZRoQR34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0k12uSzZs0a7d69e9aaSANPZNpNrYkv\nkaaJaGNFZHJORGSST63TbEVEmlNqNQJFbieynYeHh4s1ktTT01NlTZGmosiA21JDUWRfTOHIDyRF\n+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNVoh9+qVav06KOPzloTGT9VS6QbKtKZFe3ci9xW\npOsucm7ASLdcpAsycjuR7VhrzZFuuoi1a9eG6lavXl2sqbWtm8aRH0iK8ANJEX4gKcIPJEX4gaQI\nP5AU4QeSIvxAUsWOEjPbIukfJfVLcklH3P2HZrZe0j9J2irpnKTn3f3KbLfV2dmpBx98cNb7i5w/\nL9IIExmtFWm6GRkZKdZEm3xqna8t0lQSWVPNEWUltRqBIvs+MuYsqtY2qnXOw5rNQpEj/7ikb7n7\noKTPS3rJzAYlvSLppLvvlHSy9T2AZaIYfnc/7+6/a12+LukDSQ9JOiDpWKvsmKRnF2uRAOqb02t+\nM9sq6XOSfi2p393Pt370iSZfFgBYJsLhN7MeSb+Q9E13vzb9Zz75gu6eL+rM7JCZnTKzU1euzPqW\nAIAGhcJvZp2aDP5P3f2XrasvmNlA6+cDki7e69+6+xF33+vue/v6+mqsGUAFxfDb5FuZr0n6wN2/\nP+1HJyQdbF0+KOmt+ssDsFgif8//pKS/lvS+mb3Xuu7bkl6V9HMz+7qk/5H0/OIsEcBiKIbf3f9D\n0kwfZH6x7nIANKXRST4rVqwonvss0sBSa+LL6OhosabWeeiitzWXc63NpsnGk0hzTqTpKNLAE2kC\ni9RE9r0Ue2y1tlFXV1doTbXQ3gskRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKlGm3zMrNh8Umty\nzPDwcLGms7OzWBNp4IiuOdLAE2n0iNxfreakWvsjIrKeyD6LNPlEJ+KMjY0Va27dulWsiay7yclK\nEkd+IC3CDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJNdrk4+7F5pNIE0Ok8aLWKb1qnT4rWldrTRGR\n+4o+tpJap6KK1KxevbpYE31ckQaeyJSiyHO2yYYqiSM/kBbhB5Ii/EBShB9IivADSRF+ICnCDyRF\n+IGkrFbDSOjOzP5Xkyf1nLJR0qXGFlDPclw3a25OO9f9iLs/EClsNPx/dudmp9x9b9sWME/Lcd2s\nuTnLZd382g8kRfiBpNod/iNtvv/5Wo7rZs3NWRbrbutrfgDt0+4jP4A2aVv4zWy/mf23mX1oZq+0\nax1zYWbnzOx9M3vPzE61ez0zMbOjZnbRzE5Pu269mb1jZmdaX/vauca7zbDm75rZUGt7v2dmX2nn\nGu9mZlvM7N/M7I9m9gcz+9vW9Ut6W09pS/jNrEPSjyR9WdKgpBfMbLAda5mHL7j7niX+Uc7rkvbf\ndd0rkk66+05JJ1vfLyWv68/XLEk/aG3vPe7+dsNrKhmX9C13H5T0eUkvtZ7HS31bS2rfkX+fpA/d\n/ay7j0k6LulAm9by/467vyvp8l1XH5B0rHX5mKRnG11UwQxrXtLc/by7/651+bqkDyQ9pCW+rae0\nK/wPSfpo2vcft65b6lzSr8zst2Z2qN2LmaN+dz/fuvyJpP52LmYODpvZ71svC5bkr8+SZGZbJX1O\n0q+1TLY1b/jNzVPuvkeTL1deMrO/bPeC5sMnP+JZDh/z/FjSdkl7JJ2X9L32LufezKxH0i8kfdPd\nr03/2VLe1u0K/5CkLdO+39y6bklz96HW14uS3tTky5fl4oKZDUhS6+vFNq+nyN0vuPuEu9+R9BMt\nwe1tZp2aDP5P3f2XrauXxbZuV/h/I2mnmW0zsy5JX5N0ok1rCTGzbjPrnbos6UuSTs/+r5aUE5IO\nti4flPRWG9cSMhWglq9qiW1vmxy3+5qkD9z9+9N+tCy2dduafFof2/y9pA5JR93979qykCAz267J\no700OfL8Z0t1zWb2hqSnNfnXZRckfUfSP0v6uaSHNfmXlc+7+5J5g22GNT+tyV/5XdI5Sd+Y9lq6\n7czsKUn/Lul9SVOzyb+tydf9S3ZbT6HDD0iKN/yApAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyT1\nf+NfTyvUDA9oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1731011a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.load(\"orig_imgs\\\\cyst\\\\E100529980_1.npy\")\n",
    "plt.imshow(img[:,:,5,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_section(img, df, pad=30):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(np.transpose(img[df['x1']-pad:df['x2']+pad,\n",
    "                                df['y2']+pad:df['y1']-pad:-1,\n",
    "                                (df['z1']+df['z2'])//2, 0], (1,0)), cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.transpose(img[df['x1']-pad:df['x2']+pad,\n",
    "                                df['y2']+pad:df['y1']-pad:-1,\n",
    "                                (df['z1']+df['z2'])//2, 1], (1,0)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 36 is out of bounds for axis 2 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-61a1503b139e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"E100529980.npy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"orig_imgs\\\\cyst\\\\E100529980_1.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#np.load(\"full_imgs\\\\\"+img_fn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_section\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoi_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvoi_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Filename\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mimg_fn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-6e093e8024c4>\u001b[0m in \u001b[0;36mplot_section\u001b[1;34m(img, df, pad)\u001b[0m\n\u001b[0;32m      3\u001b[0m     plt.imshow(np.transpose(img[df['x1']-pad:df['x2']+pad,\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                 (df['z1']+df['z2'])//2, 0], (1,0)), cmap='gray')\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m122\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     plt.imshow(np.transpose(img[df['x1']-pad:df['x2']+pad,\n",
      "\u001b[1;31mIndexError\u001b[0m: index 36 is out of bounds for axis 2 with size 12"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAD8CAYAAADHTWCVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1730ffef940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_fn = \"E100529980.npy\"\n",
    "img = np.load(\"full_imgs\\\\\"+img_fn)\n",
    "plot_section(img, voi_df[voi_df[\"Filename\"] == img_fn].iloc[0], pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
