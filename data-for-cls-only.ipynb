{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves images from \"full_imgs\" and stores each VOI separately in \"train_imgs\". Retrieves spreadsheet listing VOIs and stores them in text file. Requires data-retrieval to be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import helper_fxns as hf\n",
    "import transforms as tr\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(\"train_list.txt\", \"r\") as f:\n",
    "    vois = [x.split(',') for x in f.read().split(\"\\n\")]\n",
    "\n",
    "voi_df = pd.DataFrame(vois, columns = [\"Filename\", \"x1\", \"x2\", \"y1\", \"y2\", \"z1\", \"z2\", \"cls\"]).dropna()\n",
    "voi_df = voi_df.astype({\"x1\": int, \"x2\": int, \"y1\": int, \"y2\": int, \"z1\": int, \"z2\": int})\n",
    "\n",
    "voi_df['dx'] = voi_df.apply(lambda row: row['x2'] - row['x1'], axis=1)\n",
    "voi_df['dy'] = voi_df.apply(lambda row: row['y2'] - row['y1'], axis=1)\n",
    "voi_df['dz'] = voi_df.apply(lambda row: row['z2'] - row['z1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = config.Config()\n",
    "final_size = C.dims\n",
    "\n",
    "voi_df = pd.read_csv('vois.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(img, final_size, num_samples = 100, translate=None):\n",
    "    aug_imgs = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        temp_img = img\n",
    "        angle = random.randint(0, 359)\n",
    "        temp_img = tr.rotate(temp_img, angle)\n",
    "        \n",
    "        #scales = [0.9, 1.1]\n",
    "        #scale = [random.uniform(scales[0],scales[1]), random.uniform(scales[0],scales[1]), random.uniform(scales[0],scales[1])]\n",
    "        #temp_img = tr.scale3d(temp_img, scale)\n",
    "        \n",
    "        if translate is not None:\n",
    "            trans = [random.randint(-translate[0], translate[0]),\n",
    "                     random.randint(-translate[1], translate[1]),\n",
    "                     random.randint(-translate[2], translate[2])]\n",
    "        else:\n",
    "            trans = [0,0,0]\n",
    "        \n",
    "        flip = [random.choice([-1, 1]), random.choice([-1, 1]), random.choice([-1, 1])]\n",
    "        \n",
    "        crops = [temp_img.shape[i] - final_size[i] for i in range(3)]\n",
    "        \n",
    "        aug_imgs.append(temp_img[math.floor(crops[0]/2)*flip[0] + trans[0] : -math.ceil(crops[0]/2)*flip[0] + trans[0] : flip[0],\n",
    "                                 math.floor(crops[1]/2)*flip[1] + trans[1] : -math.ceil(crops[1]/2)*flip[1] + trans[1] : flip[1],\n",
    "                                 math.floor(crops[2]/2)*flip[2] + trans[2] : -math.ceil(crops[2]/2)*flip[2] + trans[2] : flip[2], :])\n",
    "    \n",
    "    return aug_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_voi(img, voi, final_size, aug=False):\n",
    "    \"\"\"Input: image, a voi from the image (as pd.Series), target size in voxels, and whether to augment.\n",
    "    Outputs list of images (np.ndarray) and list of classes (string).\n",
    "    Assumes that there is no voi so close to the edge that getting a volume of size final_size would make it go out of bounds.\n",
    "    \"\"\"\n",
    "    voi_imgs = []\n",
    "    classes = []\n",
    "    \n",
    "    # if augmenting, take a larger volume from the original image so rotating it will not cut off any part\n",
    "    if aug:\n",
    "        crop_size = [math.ceil(x*math.sqrt(2)) for x in final_size]\n",
    "    else:\n",
    "        crop_size = final_size\n",
    "    \n",
    "    exceed_ratio = max(voi['dx']/crop_size[0], voi['dy']/crop_size[1], voi['dz']/crop_size[2], 1) / 1\n",
    "\n",
    "    # downscale image until it fits in final_size and cannot be cut off by rotation\n",
    "    if exceed_ratio > 1:\n",
    "        temp_img = tr.scale3d(img, [1/exceed_ratio]*3)\n",
    "        x1 = round(voi['x1'] / exceed_ratio)\n",
    "        x2 = round(voi['x2'] / exceed_ratio)\n",
    "        y1 = round(voi['y1'] / exceed_ratio)\n",
    "        y2 = round(voi['y2'] / exceed_ratio)\n",
    "        z1 = round(voi['z1'] / exceed_ratio)\n",
    "        z2 = round(voi['z2'] / exceed_ratio)\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dz = z2 - z1\n",
    "    else:\n",
    "        temp_img = copy.deepcopy(img)\n",
    "        x1 = voi['x1']\n",
    "        x2 = voi['x2']\n",
    "        y1 = voi['y1']\n",
    "        y2 = voi['y2']\n",
    "        z1 = voi['z1']\n",
    "        z2 = voi['z2']\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dz = z2 - z1\n",
    "        \n",
    "    xpad = max(crop_size[0] - dx,0)\n",
    "    ypad = max(crop_size[1] - dy,0)\n",
    "    zpad = max(crop_size[2] - dz,0)\n",
    "\n",
    "    \"\"\"plt.subplot(121)\n",
    "    plt.imshow(np.transpose(img[voi['x1']:voi['x2'],\n",
    "                                voi['y2']:voi['y1']:-1,\n",
    "                                (voi['z1']+voi['z2'])//2, 0], (1,0)), cmap='gray')\"\"\"\n",
    "\n",
    "    side_padding = math.ceil(max(xpad, ypad, zpad) / 2)\n",
    "\n",
    "    pad_img = []\n",
    "\n",
    "    for ch in range(temp_img.shape[-1]):\n",
    "        pad_img.append(np.pad(temp_img[:,:,:,ch], side_padding, 'constant'))\n",
    "\n",
    "    pad_img = np.stack(pad_img, axis=3)\n",
    "\n",
    "    x1 += side_padding - math.ceil(xpad/2)\n",
    "    x2 += side_padding + math.floor(xpad/2)\n",
    "    y1 += side_padding - math.ceil(ypad/2)\n",
    "    y2 += side_padding + math.floor(ypad/2)\n",
    "    z1 += side_padding - math.ceil(zpad/2)\n",
    "    z2 += side_padding + math.floor(zpad/2)\n",
    "\n",
    "    pad_img = pad_img[x1:x2, y1:y2, z1:z2, :]\n",
    "        \n",
    "    if aug:\n",
    "        aug_imgs = augment(pad_img, final_size, translate=[1,1,0], num_samples = 50)\n",
    "        voi_imgs = voi_imgs + aug_imgs\n",
    "        classes = classes + [voi['cls']] * len(aug_imgs)\n",
    "\n",
    "    else:\n",
    "        voi_imgs = [pad_img]\n",
    "        if voi_imgs[0].shape[0] != final_size[0] or voi_imgs[0].shape[1] != final_size[1] or voi_imgs[0].shape[2] != final_size[2]:\n",
    "            print(voi)\n",
    "            print(x1,x2,y1,y2,z1,z2)\n",
    "            print(voi_imgs[0].shape, final_size, zpad)\n",
    "            raise ValueError(\"zzz\")\n",
    "        \n",
    "        classes = [voi['cls']]\n",
    "\n",
    "    \"\"\"img = pad_img\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.transpose(img[voi['x1']:voi['x2'],\n",
    "                                voi['y2']:voi['y1']:-1,\n",
    "                                (voi['z1']+voi['z2'])//2, 1], (1,0)), cmap='gray')\"\"\"\n",
    "        \n",
    "    return voi_imgs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................\n",
      "102.07272434234619\n"
     ]
    }
   ],
   "source": [
    "aug=True\n",
    "t = time.time()\n",
    "\n",
    "if not os.path.exists(C.aug_dir):\n",
    "    os.makedirs(C.aug_dir)\n",
    "if not os.path.exists(C.orig_dir):\n",
    "    os.makedirs(C.orig_dir)\n",
    "    \n",
    "# iterate over image series\n",
    "for img_fn in os.listdir(\"full_imgs\\\\\"):\n",
    "    img = np.load(\"full_imgs\\\\\"+img_fn)\n",
    "    vois = voi_df[voi_df[\"Filename\"] == img_fn]\n",
    "    \n",
    "    # iterate over each voi in that image\n",
    "    for voi_num, voi in enumerate(vois.iterrows()):\n",
    "        cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=aug)\n",
    "\n",
    "        if not os.path.exists(C.orig_dir+classes[0]):\n",
    "            os.makedirs(C.orig_dir+classes[0])\n",
    "        if not os.path.exists(C.aug_dir+classes[0]):\n",
    "            os.makedirs(C.aug_dir+classes[0])\n",
    "\n",
    "        for i in range(len(cropped_imgs)):\n",
    "            np.save(C.aug_dir+classes[i]+\"\\\\\"+img_fn[:-4]+\"_\"+str(voi_num)+\"_\"+str(i), cropped_imgs[i])\n",
    "    \n",
    "        # save unaugmented vois as well\n",
    "        if aug:\n",
    "            cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=False)\n",
    "            i = 0\n",
    "            fn_stem = C.orig_dir+classes[i]+\"\\\\\"+img_fn[:-4]+\"_\"\n",
    "            while os.path.exists(fn_stem + str(i) + \".npy\"):\n",
    "                i += 1\n",
    "            np.save(fn_stem + str(i), cropped_imgs[0])\n",
    "        \n",
    "        if voi_num % 20 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "print(\"\") \n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in os.listdir(\"train_imgs\\\\hcc\\\\\"):\n",
    "    if x[-6] != \"_\" and int(x[-6:-4]) > 30:\n",
    "        os.remove(\"train_imgs\\\\hcc\\\\\" + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x for x in os.listdir(\"train_imgs\\\\hcc\\\\\") if x[-6] != \"_\" and int(x[-6:-4]) > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.listdir(\"train_imgs\\\\hcc\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = np.load(\"train_imgs\\\\cyst\\\\E100529980_1.npy\")\n",
    "#img = np.load(\"train_imgs\\\\cyst\\\\12302576_70.npy\")\n",
    "plt.imshow(img[:,:,5,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_section(img, df, pad=30):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(np.transpose(img[df['x1']-pad:df['x2']+pad,\n",
    "                                df['y2']+pad:df['y1']-pad:-1,\n",
    "                                (df['z1']+df['z2'])//2, 0], (1,0)), cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.transpose(img[df['x1']-pad:df['x2']+pad,\n",
    "                                df['y2']+pad:df['y1']-pad:-1,\n",
    "                                (df['z1']+df['z2'])//2, 1], (1,0)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNHQAKAQNHQAKQUMHgELQ0AGgEP8P/eJ7Xw4Gki8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a8cc114da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_fn = \"E100529980.npy\"\n",
    "img = np.load(\"full_imgs\\\\\"+img_fn)\n",
    "plot_section(img, voi_df[voi_df[\"Filename\"] == img_fn].iloc[0], pad=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
