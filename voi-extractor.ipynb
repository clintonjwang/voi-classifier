{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves images from \"full_imgs\" and stores each VOI separately in \"train_imgs\". Retrieves spreadsheet listing VOIs and stores them in text file. Requires data-retrieval to be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import helper_fxns as hf\n",
    "import transforms as tr\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(\"train_list.txt\", \"r\") as f:\n",
    "    vois = [x.split(',') for x in f.read().split(\"\\n\")]\n",
    "\n",
    "voi_df = pd.DataFrame(vois, columns = [\"Filename\", \"x1\", \"x2\", \"y1\", \"y2\", \"z1\", \"z2\", \"cls\"]).dropna()\n",
    "voi_df = voi_df.astype({\"x1\": int, \"x2\": int, \"y1\": int, \"y2\": int, \"z1\": int, \"z2\": int})\n",
    "\n",
    "voi_df['dx'] = voi_df.apply(lambda row: row['x2'] - row['x1'], axis=1)\n",
    "voi_df['dy'] = voi_df.apply(lambda row: row['y2'] - row['y1'], axis=1)\n",
    "voi_df['dz'] = voi_df.apply(lambda row: row['z2'] - row['z1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_fxns' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\helper_fxns.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = config.Config()\n",
    "final_size = C.dims\n",
    "\n",
    "voi_df_art = pd.read_csv(C.art_voi_path)\n",
    "voi_df_ven = pd.read_csv(C.ven_voi_path)\n",
    "voi_df_eq = pd.read_csv(C.eq_voi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#voi_df = voi_df[~voi_df['cls'].isin(['colorectal', 'adenoma', 'fnh'])]\n",
    "#set(voi_df['cls'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regenerate_imgs(acc_nums):\n",
    "    for acc_num in acc_nums:\n",
    "        for cls in os.listdir(C.aug_dir):\n",
    "            foldername = C.aug_dir + cls\n",
    "            for filename in os.listdir(foldername):\n",
    "                if acc_num in filename:\n",
    "                    os.remove(foldername + \"\\\\\" + filename)\n",
    "                    \n",
    "            foldername = C.aug_dir + cls\n",
    "            for filename in os.listdir(foldername):\n",
    "                if acc_num in filename:\n",
    "                    os.remove(foldername + \"\\\\\" + filename)\n",
    "                    \n",
    "        img_fn = acc_num + \".npy\"\n",
    "        img = np.load(C.full_img_dir+\"\\\\\"+img_fn)\n",
    "        art_vois = voi_df_art[(voi_df_art[\"Filename\"] == img_fn) & (voi_df_art[\"cls\"].isin(classes_to_include))]\n",
    "\n",
    "        # iterate over each voi in that image\n",
    "        for voi_num, voi in enumerate(art_vois.iterrows()):\n",
    "            ven_voi = voi_df_ven[voi_df_ven[\"id\"] == voi[1][\"id\"]]\n",
    "            eq_voi = voi_df_eq[voi_df_eq[\"id\"] == voi[1][\"id\"]]\n",
    "\n",
    "            try: \n",
    "                cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=aug, ven_voi=ven_voi, eq_voi=eq_voi)\n",
    "            except:\n",
    "                print(\"Exception\", img_fn)\n",
    "                break\n",
    "\n",
    "            for i in range(len(cropped_imgs)):\n",
    "                np.save(C.aug_dir + classes[i] + \"\\\\\" + img_fn[:-4] + \"_\" + str(voi_num) + \"_\" + str(i), cropped_imgs[i])\n",
    "\n",
    "            # save unaugmented vois as well\n",
    "            if aug:\n",
    "                cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=False, ven_voi=ven_voi, eq_voi=eq_voi)\n",
    "                np.save(C.orig_dir+classes[0]+\"\\\\\"+img_fn[:-4]+\"_\" + str(voi_num), cropped_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_voi(img, voi, final_size, aug=False, ven_voi=[], eq_voi=[]):\n",
    "    \"\"\"Input: image, a voi from the image (as pd.Series), target size in voxels, and whether to augment.\n",
    "    Outputs list of images (np.ndarray) and list of classes (string).\n",
    "    Assumes that there is no voi so close to the edge that getting a volume of size final_size would make it go out of bounds.\n",
    "    \"\"\"\n",
    "    \n",
    "    voi_imgs = []\n",
    "    classes = []\n",
    "    temp_img = copy.deepcopy(img)\n",
    "    \n",
    "    # if augmenting, take a larger volume from the original image so rotating it will not cut off any part\n",
    "    if aug:\n",
    "        crop_size = [math.ceil(x*math.sqrt(2)) for x in final_size]\n",
    "    else:\n",
    "        crop_size = final_size\n",
    "        \n",
    "    if len(ven_voi) > 0:\n",
    "        ven_voi = ven_voi.iloc[0]\n",
    "        temp_img = hf.align(temp_img, voi, ven_voi, 1)\n",
    "        \n",
    "    if len(eq_voi) > 0:\n",
    "        eq_voi = eq_voi.iloc[0]\n",
    "        temp_img = hf.align(temp_img, voi, eq_voi, 2)\n",
    "    \n",
    "    exceed_ratio = max(voi['dx']/crop_size[0], voi['dy']/crop_size[1], voi['dz']/crop_size[2]) / 1\n",
    "\n",
    "    # downscale image until it fits in final_size and cannot be cut off by rotation\n",
    "    if exceed_ratio > 1:\n",
    "        temp_img = tr.scale3d(temp_img, [1/exceed_ratio]*3)\n",
    "        x1 = round(voi['x1'] / exceed_ratio)\n",
    "        x2 = round(voi['x2'] / exceed_ratio)\n",
    "        y1 = round(voi['y1'] / exceed_ratio)\n",
    "        y2 = round(voi['y2'] / exceed_ratio)\n",
    "        z1 = round(voi['z1'] / exceed_ratio)\n",
    "        z2 = round(voi['z2'] / exceed_ratio)\n",
    "    else:\n",
    "        x1 = voi['x1']\n",
    "        x2 = voi['x2']\n",
    "        y1 = voi['y1']\n",
    "        y2 = voi['y2']\n",
    "        z1 = voi['z1']\n",
    "        z2 = voi['z2']\n",
    "\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    dz = z2 - z1\n",
    "        \n",
    "    xpad = max(crop_size[0] - dx,0)\n",
    "    ypad = max(crop_size[1] - dy,0)\n",
    "    zpad = max(crop_size[2] - dz,0)\n",
    "\n",
    "    side_padding = math.ceil(max(xpad, ypad, zpad) / 2)\n",
    "\n",
    "    pad_img = []\n",
    "\n",
    "    for ch in range(temp_img.shape[-1]):\n",
    "        pad_img.append(np.pad(temp_img[:,:,:,ch], side_padding, 'constant'))\n",
    "\n",
    "    pad_img = np.stack(pad_img, axis=3)\n",
    "\n",
    "    x1 += side_padding - math.ceil(xpad/2)\n",
    "    x2 += side_padding + math.floor(xpad/2)\n",
    "    y1 += side_padding - math.ceil(ypad/2)\n",
    "    y2 += side_padding + math.floor(ypad/2)\n",
    "    z1 += side_padding - math.ceil(zpad/2)\n",
    "    z2 += side_padding + math.floor(zpad/2)\n",
    "\n",
    "    pad_img = pad_img[x1:x2, y1:y2, z1:z2, :]\n",
    "        \n",
    "    if aug:\n",
    "        aug_imgs = hf.augment(pad_img, final_size, translate=[1,1,0], exceed_ratio=exceed_ratio, num_samples = C.aug_factor[voi['cls']])\n",
    "        voi_imgs = voi_imgs + aug_imgs\n",
    "        classes = classes + [voi['cls']] * len(aug_imgs)\n",
    "\n",
    "    else:\n",
    "        voi_imgs = [pad_img]\n",
    "        #if voi_imgs[0].shape[0] != final_size[0] or voi_imgs[0].shape[1] != final_size[1] or voi_imgs[0].shape[2] != final_size[2]:\n",
    "        #    print(voi)\n",
    "        #    print(x1,x2,y1,y2,z1,z2)\n",
    "        #    print(voi_imgs[0].shape, final_size, zpad)\n",
    "        #    raise ValueError(\"zzz\")\n",
    "        \n",
    "        classes = [voi['cls']]\n",
    "        \n",
    "    return voi_imgs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................\n",
      "348.5380849838257\n"
     ]
    }
   ],
   "source": [
    "aug=True\n",
    "t = time.time()\n",
    "classes_to_include = ['cyst', 'hcc', 'hemangioma', 'cholangio']#, 'colorectal', 'fnh']\n",
    "\n",
    "voi_df_ven[\"id\"] = str(voi_df_ven[\"id\"])\n",
    "voi_df_eq[\"id\"] = str(voi_df_eq[\"id\"])\n",
    "\n",
    "if os.path.exists(C.aug_dir):\n",
    "    print(\"Warning: path\", C.aug_dir, \"already exists.\")\n",
    "else:\n",
    "    os.makedirs(C.aug_dir)\n",
    "if not os.path.exists(C.orig_dir):\n",
    "    os.makedirs(C.orig_dir)\n",
    "    \n",
    "for cls in classes_to_include:\n",
    "    if not os.path.exists(C.orig_dir + cls):\n",
    "        os.makedirs(C.orig_dir + cls)\n",
    "    if not os.path.exists(C.aug_dir + cls):\n",
    "        os.makedirs(C.aug_dir + cls)\n",
    "    \n",
    "# iterate over image series\n",
    "for img_fn in os.listdir(C.full_img_dir):\n",
    "    img = np.load(C.full_img_dir+\"\\\\\"+img_fn)\n",
    "    art_vois = voi_df_art[(voi_df_art[\"Filename\"] == img_fn) & (voi_df_art[\"cls\"].isin(classes_to_include))]\n",
    "    \n",
    "    # iterate over each voi in that image\n",
    "    for voi_num, voi in enumerate(art_vois.iterrows()):\n",
    "        ven_voi = voi_df_ven[voi_df_ven[\"id\"] == voi[1][\"id\"]]\n",
    "        eq_voi = voi_df_eq[voi_df_eq[\"id\"] == voi[1][\"id\"]]\n",
    "        \n",
    "        try:\n",
    "            cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=aug, ven_voi=ven_voi, eq_voi=eq_voi)\n",
    "        except:\n",
    "            print(\"Exception\", img_fn)\n",
    "            break\n",
    "\n",
    "        for i in range(len(cropped_imgs)):\n",
    "            np.save(C.aug_dir + classes[i] + \"\\\\\" + img_fn[:-4] + \"_\" + str(voi_num) + \"_\" + str(i), cropped_imgs[i])\n",
    "\n",
    "        # save unaugmented vois as well\n",
    "        if aug:\n",
    "            cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=False, ven_voi=ven_voi, eq_voi=eq_voi)\n",
    "            np.save(C.orig_dir+classes[0]+\"\\\\\"+img_fn[:-4]+\"_\" + str(voi_num), cropped_imgs[0])\n",
    "                \n",
    "        if voi_num % 20 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "print(\"\")\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "img_fn = \"E100529980.npy\"\n",
    "img = np.load(C.full_img_dir+\"\\\\\"+img_fn)\n",
    "hf.plot_section(img, voi_df[voi_df[\"Filename\"] == img_fn].iloc[0], pad=0)\n",
    "#art_vois = voi_df_art[(voi_df_art[\"Filename\"] == img_fn) & (voi_df_art[\"cls\"].isin(classes_to_include))]\n",
    "\n",
    "#img = np.load(\"orig_imgs\\\\cyst\\\\E100529980_1.npy\")\n",
    "#plt.imshow(img[:,:,5,0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
