{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves images from \"full_imgs\" and stores each VOI separately in \"train_imgs\". Retrieves spreadsheet listing VOIs and stores them in text file. Requires data-retrieval to be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import helper_fxns as hf\n",
    "import transforms as tr\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(\"train_list.txt\", \"r\") as f:\n",
    "    vois = [x.split(',') for x in f.read().split(\"\\n\")]\n",
    "\n",
    "voi_df = pd.DataFrame(vois, columns = [\"Filename\", \"x1\", \"x2\", \"y1\", \"y2\", \"z1\", \"z2\", \"cls\"]).dropna()\n",
    "voi_df = voi_df.astype({\"x1\": int, \"x2\": int, \"y1\": int, \"y2\": int, \"z1\": int, \"z2\": int})\n",
    "\n",
    "voi_df['dx'] = voi_df.apply(lambda row: row['x2'] - row['x1'], axis=1)\n",
    "voi_df['dy'] = voi_df.apply(lambda row: row['y2'] - row['y1'], axis=1)\n",
    "voi_df['dz'] = voi_df.apply(lambda row: row['z2'] - row['z1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\config.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = config.Config()\n",
    "final_size = C.dims\n",
    "\n",
    "voi_df_art = pd.read_csv(C.art_voi_path)\n",
    "voi_df_ven = pd.read_csv(C.ven_voi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#voi_df = voi_df[~voi_df['cls'].isin(['colorectal', 'adenoma', 'fnh'])]\n",
    "#set(voi_df['cls'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_voi(img, voi, final_size, aug=False, ven_voi=None):\n",
    "    \"\"\"Input: image, a voi from the image (as pd.Series), target size in voxels, and whether to augment.\n",
    "    Outputs list of images (np.ndarray) and list of classes (string).\n",
    "    Assumes that there is no voi so close to the edge that getting a volume of size final_size would make it go out of bounds.\n",
    "    \"\"\"\n",
    "    \n",
    "    def align(img, voi, ven_voi):\n",
    "        temp_ven = copy.deepcopy(img[:,:,:,1])\n",
    "        dx = ((ven_voi[\"x1\"] + ven_voi[\"x2\"]) - (voi[\"x1\"] + voi[\"x2\"])) // 2\n",
    "        dy = ((ven_voi[\"y1\"] + ven_voi[\"y2\"]) - (voi[\"y1\"] + voi[\"y2\"])) // 2\n",
    "        dz = ((ven_voi[\"z1\"] + ven_voi[\"z2\"]) - (voi[\"z1\"] + voi[\"z2\"])) // 2\n",
    "        \n",
    "        pad = int(max(abs(dx), abs(dy), abs(dz)))+1\n",
    "        temp_ven = np.pad(temp_ven, pad, 'constant')[pad+dx:-pad+dx, pad+dy:-pad+dy, pad+dz:-pad+dz]\n",
    "        \n",
    "        return np.stack([img[:,:,:,0], temp_ven], axis=3)\n",
    "    \n",
    "    voi_imgs = []\n",
    "    classes = []\n",
    "    temp_img = copy.deepcopy(img)\n",
    "    \n",
    "    # if augmenting, take a larger volume from the original image so rotating it will not cut off any part\n",
    "    if aug:\n",
    "        crop_size = [math.ceil(x*math.sqrt(2)) for x in final_size]\n",
    "    else:\n",
    "        crop_size = final_size\n",
    "        \n",
    "    if ven_voi is not None:\n",
    "        temp_img = align(temp_img, voi, ven_voi)\n",
    "    \n",
    "    exceed_ratio = max(voi['dx']/crop_size[0], voi['dy']/crop_size[1], voi['dz']/crop_size[2], 1) / 1\n",
    "\n",
    "    # downscale image until it fits in final_size and cannot be cut off by rotation\n",
    "    if exceed_ratio > 1:\n",
    "        temp_img = tr.scale3d(temp_img, [1/exceed_ratio]*3)\n",
    "        x1 = round(voi['x1'] / exceed_ratio)\n",
    "        x2 = round(voi['x2'] / exceed_ratio)\n",
    "        y1 = round(voi['y1'] / exceed_ratio)\n",
    "        y2 = round(voi['y2'] / exceed_ratio)\n",
    "        z1 = round(voi['z1'] / exceed_ratio)\n",
    "        z2 = round(voi['z2'] / exceed_ratio)\n",
    "    else:\n",
    "        x1 = voi['x1']\n",
    "        x2 = voi['x2']\n",
    "        y1 = voi['y1']\n",
    "        y2 = voi['y2']\n",
    "        z1 = voi['z1']\n",
    "        z2 = voi['z2']\n",
    "        \n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    dz = z2 - z1\n",
    "        \n",
    "    xpad = max(crop_size[0] - dx,0)\n",
    "    ypad = max(crop_size[1] - dy,0)\n",
    "    zpad = max(crop_size[2] - dz,0)\n",
    "\n",
    "    \"\"\"plt.subplot(121)\n",
    "    plt.imshow(np.transpose(img[voi['x1']:voi['x2'],\n",
    "                                voi['y2']:voi['y1']:-1,\n",
    "                                (voi['z1']+voi['z2'])//2, 0], (1,0)), cmap='gray')\"\"\"\n",
    "\n",
    "    side_padding = math.ceil(max(xpad, ypad, zpad) / 2)\n",
    "\n",
    "    pad_img = []\n",
    "\n",
    "    for ch in range(temp_img.shape[-1]):\n",
    "        pad_img.append(np.pad(temp_img[:,:,:,ch], side_padding, 'constant'))\n",
    "\n",
    "    pad_img = np.stack(pad_img, axis=3)\n",
    "\n",
    "    x1 += side_padding - math.ceil(xpad/2)\n",
    "    x2 += side_padding + math.floor(xpad/2)\n",
    "    y1 += side_padding - math.ceil(ypad/2)\n",
    "    y2 += side_padding + math.floor(ypad/2)\n",
    "    z1 += side_padding - math.ceil(zpad/2)\n",
    "    z2 += side_padding + math.floor(zpad/2)\n",
    "\n",
    "    pad_img = pad_img[x1:x2, y1:y2, z1:z2, :]\n",
    "        \n",
    "    if aug:\n",
    "        aug_imgs = hf.augment(pad_img, final_size, translate=[1,1,0], num_samples = C.aug_factor[voi['cls']])\n",
    "        voi_imgs = voi_imgs + aug_imgs\n",
    "        classes = classes + [voi['cls']] * len(aug_imgs)\n",
    "\n",
    "    else:\n",
    "        voi_imgs = [pad_img]\n",
    "        #if voi_imgs[0].shape[0] != final_size[0] or voi_imgs[0].shape[1] != final_size[1] or voi_imgs[0].shape[2] != final_size[2]:\n",
    "        #    print(voi)\n",
    "        #    print(x1,x2,y1,y2,z1,z2)\n",
    "        #    print(voi_imgs[0].shape, final_size, zpad)\n",
    "        #    raise ValueError(\"zzz\")\n",
    "        \n",
    "        classes = [voi['cls']]\n",
    "\n",
    "    \"\"\"img = pad_img\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.transpose(img[voi['x1']:voi['x2'],\n",
    "                                voi['y2']:voi['y1']:-1,\n",
    "                                (voi['z1']+voi['z2'])//2, 1], (1,0)), cmap='gray')\"\"\"\n",
    "        \n",
    "    return voi_imgs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................."
     ]
    }
   ],
   "source": [
    "aug=True\n",
    "t = time.time()\n",
    "\n",
    "voi_df_ven[\"id\"] = str(voi_df_ven[\"id\"])\n",
    "\n",
    "if os.path.exists(C.aug_dir):\n",
    "    print(\"Warning: path\", C.aug_dir, \"already exists.\")\n",
    "else:\n",
    "    os.makedirs(C.aug_dir)\n",
    "if not os.path.exists(C.orig_dir):\n",
    "    os.makedirs(C.orig_dir)\n",
    "    \n",
    "# iterate over image series\n",
    "for img_fn in os.listdir(C.full_img_dir):\n",
    "    img = np.load(C.full_img_dir+\"\\\\\"+img_fn)\n",
    "    vois = voi_df_art[voi_df_art[\"Filename\"] == img_fn]\n",
    "    \n",
    "    # iterate over each voi in that image\n",
    "    for voi_num, voi in enumerate(vois.iterrows()):\n",
    "        ven_voi = voi_df_ven[voi_df_ven[\"id\"] == voi[1][\"id\"]]\n",
    "        \n",
    "        try:\n",
    "            if len(ven_voi) == 0: #venous voi was not specified separately\n",
    "                cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=aug)\n",
    "            else:\n",
    "                cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=aug, ven_voi=ven_voi.iloc[0])\n",
    "\n",
    "            if not os.path.exists(C.orig_dir+classes[0]):\n",
    "                os.makedirs(C.orig_dir+classes[0])\n",
    "            if not os.path.exists(C.aug_dir+classes[0]):\n",
    "                os.makedirs(C.aug_dir+classes[0])\n",
    "\n",
    "            for i in range(len(cropped_imgs)):\n",
    "                np.save(C.aug_dir+classes[i]+\"\\\\\"+img_fn[:-4]+\"_\"+str(voi_num)+\"_\"+str(i), cropped_imgs[i])\n",
    "\n",
    "            # save unaugmented vois as well\n",
    "            if aug:\n",
    "                if len(ven_voi) == 0: #venous voi was not specified separately\n",
    "                    cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=False)\n",
    "                else:\n",
    "                    cropped_imgs, classes = extract_voi(img, copy.deepcopy(voi[1]), final_size, aug=False, ven_voi=ven_voi.iloc[0])\n",
    "\n",
    "\n",
    "                i = 0\n",
    "                fn_stem = C.orig_dir+classes[i]+\"\\\\\"+img_fn[:-4]+\"_\"\n",
    "                while os.path.exists(fn_stem + str(i) + \".npy\"):\n",
    "                    i += 1\n",
    "                np.save(fn_stem + str(i), cropped_imgs[0])\n",
    "        except Exception as e:\n",
    "            print(\"Exception with\", img_fn, e)\n",
    "            continue\n",
    "                \n",
    "        if voi_num % 20 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "print(\"\")\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in os.listdir(\"train_imgs\\\\hcc\\\\\"):\n",
    "    if x[-6] != \"_\" and int(x[-6:-4]) > 30:\n",
    "        os.remove(\"train_imgs\\\\hcc\\\\\" + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x for x in os.listdir(\"train_imgs\\\\hcc\\\\\") if x[-6] != \"_\" and int(x[-6:-4]) > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.listdir(\"train_imgs\\\\hcc\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1731015d438>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf+NfTyvUDA9oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1731011a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.load(\"orig_imgs\\\\cyst\\\\E100529980_1.npy\")\n",
    "plt.imshow(img[:,:,5,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_fn = \"E100529980.npy\"\n",
    "img = np.load(\"full_imgs\\\\\"+img_fn)\n",
    "hf.plot_section(img, voi_df[voi_df[\"Filename\"] == img_fn].iloc[0], pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
