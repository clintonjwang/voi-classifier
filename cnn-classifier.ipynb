{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import cnn_builder as cbuild\n",
    "import cnn_methods as cfunc\n",
    "import config\n",
    "import csv\n",
    "import helper_fxns as hf\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(cfunc)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "C = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6cls accuracy: 0.8  - average: 0.8\n",
      "3cls accuracy: 0.8625  - average: 0.8625\n",
      "6cls accuracy: 0.8  - average: 0.8\n",
      "3cls accuracy: 0.8625  - average: 0.8625\n",
      "6cls accuracy: 0.7625  - average: 0.7875\n",
      "3cls accuracy: 0.8375  - average: 0.854166666667\n",
      "6cls accuracy: 0.8125  - average: 0.79375\n",
      "3cls accuracy: 0.9  - average: 0.865625\n"
     ]
    }
   ],
   "source": [
    "cbuild.overnight_run(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    \"\"\"Reruns everything except dimensions. Meant for overnight runs.\"\"\"\n",
    "    \n",
    "    import dr_methods as drm\n",
    "    import voi_methods as vm\n",
    "    import artif_gen_methods as agm\n",
    "    \n",
    "    C = config.Config()\n",
    "    drm.load_all_vois(C)\n",
    "    \n",
    "    intensity_df = drm.load_ints(C)\n",
    "    intensity_df.to_csv(C.int_df_path, index=False)\n",
    "    \n",
    "    n = 1500\n",
    "    for cls in C.classes_to_include:\n",
    "        agm.gen_imgs(cls, C, n)\n",
    "        if not os.path.exists(C.orig_dir + cls):\n",
    "            os.makedirs(C.orig_dir + cls)\n",
    "        if not os.path.exists(C.aug_dir + cls):\n",
    "            os.makedirs(C.aug_dir + cls)\n",
    "        if not os.path.exists(C.crops_dir + cls):\n",
    "            os.makedirs(C.crops_dir + cls)\n",
    "            \n",
    "    final_size = C.dims\n",
    "\n",
    "    voi_df_art = pd.read_csv(C.art_voi_path)\n",
    "    voi_df_ven = pd.read_csv(C.ven_voi_path)\n",
    "    voi_df_eq = pd.read_csv(C.eq_voi_path)\n",
    "    intensity_df = pd.read_csv(C.int_df_path)\n",
    "    \n",
    "    small_vois = {}\n",
    "    small_vois = vm.extract_vois(small_vois, C, voi_df_art, voi_df_ven, voi_df_eq, intensity_df)\n",
    "\n",
    "    with open(C.small_voi_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in small_vois.items():\n",
    "            writer.writerow([key, value])\n",
    "            \n",
    "    # scaled imgs\n",
    "    t = time.time()\n",
    "    for cls in C.classes_to_include:\n",
    "        for fn in os.listdir(C.crops_dir + cls):\n",
    "            img = np.load(C.crops_dir + cls + \"\\\\\" + fn)\n",
    "            unaug_img = vm.resize_img(img, C.dims, small_vois[fn[:-4]])\n",
    "            np.save(C.orig_dir + cls + \"\\\\\" + fn, unaug_img)\n",
    "    print(time.time()-t)\n",
    "    \n",
    "    # augmented imgs\n",
    "    t = time.time()\n",
    "    for cls in C.classes_to_include:\n",
    "        vm.parallel_augment(cls, small_vois, C)\n",
    "        print(cls, time.time()-t)\n",
    "        \n",
    "    for cls in C.classes_to_include:\n",
    "        vm.save_all_vois(cls, C)\n",
    "        \n",
    "    cbuild.overnight_run(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_69 (InputLayer)            (None, 36, 36, 12, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_70 (InputLayer)            (None, 36, 36, 12, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_71 (InputLayer)            (None, 36, 36, 12, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv3d_86 (Conv3D)               (None, 32, 32, 10, 64 1792        input_69[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv3d_87 (Conv3D)               (None, 32, 32, 10, 64 1792        input_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv3d_88 (Conv3D)               (None, 32, 32, 10, 64 1792        input_71[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 32, 32, 10, 64 256         conv3d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 32, 32, 10, 64 256         conv3d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, 32, 32, 10, 64 256         conv3d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_25 (ELU)                     (None, 32, 32, 10, 64 0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "elu_26 (ELU)                     (None, 32, 32, 10, 64 0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "elu_27 (ELU)                     (None, 32, 32, 10, 64 0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling3d_69 (MaxPooling3D)  (None, 16, 16, 5, 64) 0           elu_25[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling3d_70 (MaxPooling3D)  (None, 16, 16, 5, 64) 0           elu_26[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling3d_71 (MaxPooling3D)  (None, 16, 16, 5, 64) 0           elu_27[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)     (None, 16, 16, 5, 192 0           max_pooling3d_69[0][0]           \n",
      "                                                                   max_pooling3d_70[0][0]           \n",
      "                                                                   max_pooling3d_71[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3d_89 (Conv3D)               (None, 14, 14, 3, 128 663680      concatenate_35[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 14, 14, 3, 128 512         conv3d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_28 (ELU)                     (None, 14, 14, 3, 128 0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv3d_90 (Conv3D)               (None, 12, 12, 1, 100 345700      elu_28[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 12, 12, 1, 100 400         conv3d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_29 (ELU)                     (None, 12, 12, 1, 100 0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling3d_72 (MaxPooling3D)  (None, 6, 6, 1, 100)  0           elu_29[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 3600)          0           max_pooling3d_72[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_72 (InputLayer)            (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)     (None, 3602)          0           flatten_18[0][0]                 \n",
      "                                                                   input_72[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 100)           360300      concatenate_36[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 100)           400         dense_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "elu_30 (ELU)                     (None, 100)           0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 6)             606         elu_30[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 6)             24          dense_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 6)             0           batch_normalization_126[0][0]    \n",
      "====================================================================================================\n",
      "Total params: 1,377,766\n",
      "Trainable params: 1,376,714\n",
      "Non-trainable params: 1,052\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cbuild.build_cnn(C, 'adam')#Adam(lr=.005)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = cbuild.run_cnn(model, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hcc': 84, 'cholangio': 56, 'fnh': 59, 'colorectal': 72, 'hemangioma': 56, 'cyst': 75}\n"
     ]
    }
   ],
   "source": [
    "nb_classes = len(C.classes_to_include)\n",
    "voi_df = pd.read_csv(C.art_voi_path)\n",
    "orig_data_dict, num_samples = cfunc.collect_unaug_data(C, voi_df)\n",
    "print(num_samples)\n",
    "\n",
    "avg_X2 = {}\n",
    "for cls in C.classes_to_include:\n",
    "    avg_X2[cls] = np.mean(orig_data_dict[cls][1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcc has 67 samples for training (3350 after augmentation) and 17 for testing\n",
      "cholangio has 45 samples for training (2250 after augmentation) and 11 for testing\n",
      "fnh has 47 samples for training (2350 after augmentation) and 12 for testing\n",
      "colorectal has 58 samples for training (2900 after augmentation) and 14 for testing\n",
      "hemangioma has 45 samples for training (2250 after augmentation) and 11 for testing\n",
      "cyst has 60 samples for training (3000 after augmentation) and 15 for testing\n"
     ]
    }
   ],
   "source": [
    "train_ids = {} #filenames of training set originals\n",
    "test_ids = {} #filenames of test set\n",
    "X_test = []\n",
    "X2_test = []\n",
    "Y_test = []\n",
    "Z_test = []\n",
    "X_train_orig = []\n",
    "X2_train_orig = []\n",
    "Y_train_orig = []\n",
    "Z_train_orig = []\n",
    "\n",
    "train_samples = {}\n",
    "\n",
    "for cls_num, cls in enumerate(orig_data_dict):\n",
    "    cls_num = C.classes_to_include.index(cls)\n",
    "\n",
    "    train_samples[cls] = round(num_samples[cls]*C.train_frac)\n",
    "\n",
    "    order = np.random.permutation(list(range(num_samples[cls])))\n",
    "    train_ids[cls] = list(orig_data_dict[cls][2][order[:train_samples[cls]]])\n",
    "    test_ids[cls] = list(orig_data_dict[cls][2][order[train_samples[cls]:]])\n",
    "\n",
    "    X_test = X_test + list(orig_data_dict[cls][0][order[train_samples[cls]:]])\n",
    "    X2_test = X2_test + list(orig_data_dict[cls][1][order[train_samples[cls]:]])\n",
    "    Y_test = Y_test + [[0] * cls_num + [1] + [0] * (nb_classes - cls_num - 1)] * \\\n",
    "                        (num_samples[cls] - train_samples[cls])\n",
    "    Z_test = Z_test + test_ids[cls]\n",
    "\n",
    "    X_train_orig = X_train_orig + list(orig_data_dict[cls][0][order[:train_samples[cls]]])\n",
    "    X2_train_orig = X2_train_orig + list(orig_data_dict[cls][1][order[:train_samples[cls]]])\n",
    "    Y_train_orig = Y_train_orig + [[0] * cls_num + [1] + [0] * (nb_classes - cls_num - 1)] * \\\n",
    "                        (train_samples[cls])\n",
    "    Z_train_orig = Z_train_orig + train_ids[cls]\n",
    "\n",
    "    print(\"%s has %d samples for training (%d after augmentation) and %d for testing\" %\n",
    "          (cls, train_samples[cls], train_samples[cls] * C.aug_factor, num_samples[cls] - train_samples[cls]))\n",
    "\n",
    "#Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "#Y_train_orig = np_utils.to_categorical(Y_train_orig, nb_classes)\n",
    "X_test = [np.array(X_test), np.array(X2_test)]\n",
    "X_train_orig = [np.array(X_train_orig), np.array(X2_train_orig)]\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train_orig = np.array(Y_train_orig)\n",
    "\n",
    "Z_test = np.array(Z_test)\n",
    "Z_train_orig = np.array(Z_train_orig)\n",
    "\n",
    "X_test = cfunc.separate_phases(X_test)\n",
    "X_train_orig = cfunc.separate_phases(X_train_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator = train_generator_func()\n",
    "model_pretrain.fit_generator(train_generator, steps_per_epoch=120, epochs=50)#, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s - loss: 1.5403 - acc: 0.4375\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s - loss: 1.1763 - acc: 0.5208\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s - loss: 1.1641 - acc: 0.6458\n"
     ]
    }
   ],
   "source": [
    "#early_stopping = EarlyStopping(monitor='acc', min_delta=0.01, patience=4)\n",
    "train_generator = cbuild.train_generator_func(C, train_ids, voi_df, avg_X2, n=5, n_art=3)\n",
    "hist = model.fit_generator(train_generator, steps_per_epoch=1, epochs=3)#, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x131094c24a8>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8zjsCpqVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131096dab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "hist = model.fit(X_train2, Y_train2, batch_size=32, epochs=200, validation_data=(X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "voi_df_art = pd.read_csv(C.art_voi_path)\n",
    "voi_df_ven = pd.read_csv(C.ven_voi_path)\n",
    "voi_df_eq = pd.read_csv(C.eq_voi_path)\n",
    "\n",
    "with open(C.small_voi_path, 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    small_vois = dict(reader)\n",
    "for key in small_vois:\n",
    "    small_vois[key] = [int(x) for x in small_vois[key][1:-1].split(', ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbuild.overnight_run(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.output_img_dir = \"Z:\\\\OUTPUT\\\\12-08-2d-bn\"\n",
    "C.classes_to_include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_with_bbox(fn_list[2], cls_mapping[wrong_guesses[2]])\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#cfunc.save_output(Z_test, y_pred, y_true, voi_df_art, small_vois, C.classes_to_include, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_train_orig)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#cfunc.save_output(Z_train_orig, y_pred, y_true, voi_df_art, small_vois, C.classes_to_include, C, save_dir=\"Z:\\\\OUTPUT\\\\12-08-3d\\\\training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  2, 41,  2, 11],\n",
       "       [ 0,  0,  0, 24, 21,  0],\n",
       "       [ 0,  0, 10, 47,  1,  0],\n",
       "       [ 0,  0,  0, 58,  2,  0],\n",
       "       [ 0,  0,  0, 37,  8,  0],\n",
       "       [ 0,  0,  0, 11,  0, 36]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true_simp, y_pred_simp, _ = cfunc.condense_cm(y_true, y_pred, C.classes_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86250000000000004"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true_simp, y_pred_simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78749999999999998"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d: 77%/84%, 74%/80%\n",
    "3d: 78%/89%\n",
    "2d bn: 77%/82%, \n",
    "3d bn: 84%/87%, 74%/83%\n",
    "3d bn no artif: 84%/87%, 74%/83%\n",
    "3d bn/elu/dilation/3conv/64-128-100-100: 80%/86%, 82%/88%, 84%/91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fn_list = Z_test[~np.equal(y_pred, y_true)]\n",
    "wrong_guesses = np.array(y_pred)[~np.equal(y_pred, y_true)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "activ = model2.predict(X_train)\n",
    "#activ = model2.predict(np.expand_dims(X_train[10],axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import operator\n",
    "#print(\"Ground truth:\", [C.classes_to_include[max(enumerate(x), key=operator.itemgetter(1))[0]] for x in Y_val[::30]])\n",
    "Y_ = model.predict(X_test)\n",
    "print(\"Predictions:\", [C.classes_to_include[max(enumerate(x), key=operator.itemgetter(1))[0]] + \" (%.5f%% probability)\" % (max(x)*100) for x in Y_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
