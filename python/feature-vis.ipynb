{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import copy\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.transforms as tr\n",
    "import importlib\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "C = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"model_no_pad.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model_frozen.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_img = orig_data_dict['hcc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_ixs = list(range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer(model_frozen, 'conv3d_11', \"D:\\\\filters\", channel_ixs)#, init_img=init_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_trunc = cbuild.build_pretrain_model(model, last_layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "fig = cnna.tsne(filters_by_cls)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.flatten([list(feature_sheet[\"evidence1\"+cls].dropna().values) for cls in C.classes_to_include]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model_conv1 = cbuild.build_pretrain_model(model, last_layer=-6, add_activ=True)\n",
    "model_conv2 = cbuild.build_pretrain_model(model, last_layer=-5, add_activ=True)\n",
    "model_conv3 = cbuild.build_pretrain_model(model, last_layer=-4, add_activ=True)\n",
    "model_dense = cbuild.build_pretrain_model(model, last_layer=-3, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = 'cyst'\n",
    "cls_img_set = orig_data_dict[cls][0]\n",
    "cls_activ_set = model_conv3.predict(cls_img_set)\n",
    "\n",
    "nmf = NMF(4)\n",
    "cls_activ_set_xform = nmf.fit_transform(cls_activ_set.mean((1,2,3)))\n",
    "\n",
    "nmf_comps = [nmf.components_[i] * (nmf.components_[i] > np.median(nmf.components_,0)*2) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_analyzer' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_analyzer.py'>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer_weighted(model_frozen, 'conv3d_11', \"D:\\\\filters\", K.constant(nmf_comps[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activs0 = cls_activ_set[:,:,:,:,nmf_comps[1] > 0]\n",
    "activ_map0 = activs0.mean(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activ_map0, _ = tr.rescale_img(np.transpose(activ_map0, (1,2,3,0)), cls_img_set[img_id].shape[:3])\n",
    "activ_map0 = np.transpose(activ_map0, (3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFuxJREFUeJzt3UuPVVW3xvG5S+oGda+CSFmiHb/ACd/BS8MOxhiMCYkR\nhRhBg0RESMQrBJRAiICJUWxoYsfEy8d4m9IxoghyKSmgKOoGuE7jhM5J1vPsvQc7mHf8f93B3Osy\n51p7uM18qlFVVQEAAMiq636fAAAAwP1EMwQAAFKjGQIAAKnRDAEAgNRohgAAQGo0QwAAIDWaIQAA\nkBrNEAAASI1mCAAApLaipX+8YkXV09PT1oEajUZb4+5ySdmRz+/kZz/yyCNtj22GOvdourgbr+ru\nnp07d07Wp6am2j52dD5///330tfXJ//Nv1X0OYt4+OGHZT2yXqI6mbTvzv3s2bOyvm7dOlnv1DN+\n+vTp+7pelH/reZUSW+dRXV3694sHHnhA1u/cuVNbi7zvSynlzz//lHV339Scu+tWY6enp8vs7Kxd\nUC01Qz09PeWxxx6rrasTdhfj/PPPP7Ie+fzoZ6v68ePH2zqnu9ziXl5erq0tLS2Fjn3r1i1ZVw+W\nu2dvv/22rO/fv1/WFxcXa2u3b9+WY3t7e2V9w4YNZf369bX1yAsnyh07+rJU3HUdPny47fHd3d1t\nndNd7hl2567Guy/mFSv0a3Tbtm2y7u6beg7dWlfnvn79etn0R78clcg7tRmRL1a3Vvbs2dP2+Oh/\nqLkfI0ZGRmT9xo0btTX3feGeMbfO33rrLVlXz9HAwEDbY91x7+J/kwEAgNRohgAAQGo0QwAAIDWa\nIQAAkBrNEAAASI1mCAAApNbS1npHbfOMbqV021fVlsXoVmd3bHXu0S3Dg4ODsq6u222VVNvTSyll\nZmYmNF5xc+K2oKot4m77+KpVq2S9FD/nSmT7epTbmhvZsuy2cS8sLMi62iLutgy7OAQ33uVGqXN3\n98x9tpuTSN3dFzVnjUYjtAU9khsVjYCI5M64sSqupJnx6p67+XLv1OvXr8v67OysrCvuuqLfZe6d\nH4kkUO/rZr//+WUIAACkRjMEAABSoxkCAACp0QwBAIDUaIYAAEBqNEMAACC1lvYPNxoNuYXNbb3t\npMhfUHbbON02a/XXfOfm5uRYd88if3ne/dV599luq7S653v37pVj3dZbd2ylv79f1t027EajIdeE\n26qptqhG/xq3W+eRLcduTtxz4raYK26tRmIcSoltC3bbod1f63Zz1sn15OYssh5cXXH3xNXdX1BX\n5+bGumO7taS+L9yx3XOg/up8KT4WQEW1uPfm9u3bZd1xa1E9B+661Pdos70BvwwBAIDUaIYAAEBq\nNEMAACA1miEAAJAazRAAAEiNZggAAKRGMwQAAFJrOWdIZSyozIto1obLX1CieRmRjIOLFy/KsU4k\nEyOSvVRKKR988IGsq/l2WRzuuiLXHc2sqapKrkeXDRXJtIlkt0Q/32XWuOsaHx+XdXXf3Zy53Kn5\n+XlZd3lfe/bsqa25fJRodpR7v6jPj77bOpUVFM3ycc9Y5PPdfLm6O3e1Xtz9dlld7rrdu+2dd96p\nrbl17uruvri8vk7laTW7xvllCAAApEYzBAAAUqMZAgAAqdEMAQCA1GiGAABAajRDAAAgNZohAACQ\nWks5Q6XoPfsqR8BlELh6JIvDcZ8dyRk6e/asHNvb2yvrLn/J5XEox44dk3V3bpF77vIyVB5GKaW8\n++67tTWXOePuaSn6/KK5Moo7t2hujFov0etyOSKDg4O1NZdh5K7L5as899xzsh55d7m17OzYsUPW\nDx061Pax3Zyq8dFcmXaP20zdPSfq3Nx1uXXs3rk9PT21taGhITl2eHhY1t27bdOmTbKuri2ap+Xm\nbPv27bL+6aef1tbcuan3BzlDAAAATaAZAgAAqdEMAQCA1GiGAABAajRDAAAgNZohAACQGs0QAABI\nraWcoaqqZMaCygKI5qdEsh9cLoSr37p1q+3x586dk2NVJkUpPrshct1PPvmkrE9NTcn6V199JeuK\nyyjZt2+frKv74nKhmsmFUevRrdVIXk80j8vV1blFMqtK8c9JX19fbc3dU/ecuPfDqVOnZH1ubq62\ntnXrVjk2mvVz+PBhWVci66GqKnnukXXebLZLuyLPmMuscee+cuVKWVdZQuPj43KsMzs7K+ufffaZ\nrKtncMuWLXJsNGfoyJEjsr6wsNBWrRT9fmg2B4xfhgAAQGo0QwAAIDWaIQAAkBrNEAAASI1mCAAA\npEYzBAAAUrunW+sjW3Pddke3tVYdO7I9vZn6008/XVubnp6WYxcXF2Xdnbu6b267sdtCOjAwIOvb\ntm2rrU1OTsqxe/bskXW1BbQUfV/cdTe71bJOZFtvlDt3N6eRLc/Hjx+Xdbe1Xm3zdmOj1+U+X62Z\nkydPyrGO25q/atUqWVf3za0HF2kSGavOKxo/ER2v5tN99jfffCPrbmv9yMhIbc3NtfsedMd2sSLq\ne/SHH36QY909f/zxx2U98t51z6+qs7UeAACgCTRDAAAgNZohAACQGs0QAABIjWYIAACkRjMEAABS\noxkCAACptZQzVIrOllC5FNHMG5cVoOpurLqmUkrZsGGDrF++fLm2NjMzI8fOzs7KusshGh4erq2t\nXbtWjnX1Bx98UNbHx8dra0NDQ3LsiRMnZN1lnKi6m0+XxeG49dTJHKJO5rd8/vnncqy7b0tLS7Ku\nskBu3rwpx7o5de8Xl1ul6i77xc2Jy2eKcPMdWQ+dzBly3D13863ydH766Sc51q0Vl7+mcobcebvr\nHh0dlXWXY6R0d3fLunsGv//+e1m/evWqrKvvOrcW1bun2fcxvwwBAIDUaIYAAEBqNEMAACA1miEA\nAJAazRAAAEiNZggAAKRGMwQAAFJrKWeo0WjIHASVLeHyFZzbt2/Lusoh2Lx5sxx75coVWf/1119l\n/cyZM7U1lzPk8hNUNksppczNzdXW3D1/9NFHZd1lVqjMi9WrV8ux7tzUdZXic2kUl+VRip+Xdj/f\nHTuSC1NKKSdPnpR1lRXiMq3cnLj6wsJCbc093yo3phS/Vt16U/PtnkF37k4keya6XtR6cLkyKm+r\nk/lHpZTy9ddfy/rY2Fhtza2lSI6Qq0fy05rhsuHUnLr74t5dbr2cO3dO1tV3pfts9e5p5n1fCr8M\nAQCA5GiGAABAajRDAAAgNZohAACQGs0QAABIjWYIAACkRjMEAABSi4X//D8qO+LDDz+UY+fn52Xd\nZQFdvny5tvbbb7/JsS5H6JdffpH1a9eu1dZcBonLGFFZHqWUsry8XFtbuXKlHDs9PS3ra9asafvY\n7romJiZkPZILc+PGDTnW3dOqqmy2jPLxxx/X1tyc9PX1ybo7L/UclKKfM5floXKCSvE5RWrOXE6Q\nq7vsF5cdo9ayezdFrrsUP+eq7vJ43FqPjFXv9N7eXjm2v78/VHdrUb2THbfWHDXfLotraWlJ1t0z\n6taS4tapO7b7rnN5P93d3bU194ypY7vzvotfhgAAQGo0QwAAIDWaIQAAkBrNEAAASI1mCAAApEYz\nBAAAUmtpa/3atWvL3r172zrQ1atXZd1th3Zb6y9evFhbc1vrT58+Let//fWXrKvt0oODg3Ks2/bn\nthSq7Ypqq2Ipfvu62+Z58+bN2prbZjk0NCTrbmutujZ3bHXepZQyOTlZ3nvvPflvFLVN291Tt43b\nPSfu2tTx3XpwW45dbICqu63xru6eM3fuKrLAPUcqUqQU/wy7+662z0e2O69bt67s3r27tu62gaut\n2O4ZdFvj3TZvt+2/p6en7bEursBRz79bC9Gt9a6url2ddyn+3eTiDCLX5q7LrZdm8MsQAABIjWYI\nAACkRjMEAABSoxkCAACp0QwBAIDUaIYAAEBqNEMAACC1lnKGGo2GzNxQGQYuq0PlQpRSSm9vr6yr\nrA83dnR0VNbduQ8MDLR9bJfH4fIT+vr6amurV6+WY909d3kbar7ddblsFnVdpejcGDfWZX10dXXJ\nz3f3TWX9XLp0SY49c+aMrP/999+y7taLWsturU5OTsr68PCwrE9MTNTW3DPocoRcxpHL8lHj3Xyr\nrK9SfDZUJBsmksdTVZU8tpsTdWyXIxTNGXLPuFrLLrPKzbfLKVLvPpd3Fc1+c+9dNd9uTmZmZmTd\n5Qw56tpdLp36rnLP5138MgQAAFKjGQIAAKnRDAEAgNRohgAAQGo0QwAAIDWaIQAAkBrNEAAASK2l\nnKEVK1bY7Jo6t27dknWV1VNKLPvBZVJMTU3JusqNKaWU5eXl2prLhVBjS/FZPyo3xmWz9Pf3y7rL\nblFZHu68n3jiCVn/8ccfZV2tJ5fb0kzuhFpPLmfk+vXrtbXz58/LsX/88YesX7hwQdbdc6aeI5cz\n5LJf3HoaHx9v67xK8WvRPePu3NWacNfl1tuLL74o60ePHpV1lf/i3k0uz0vl0rg8HvWMu7wc9wy5\n+XS5MyrPJ5oL5e65WssuiyvKPf+q7q5rbm5O1p9//nlZP3XqlKyrOXf5TOoZJGcIAACgCTRDAAAg\nNZohAACQGs0QAABIjWYIAACkRjMEAABSoxkCAACptZQz1NXVZTM36rgcEZWX08x4lanz0EMPybHX\nrl2T9cuXL7c93mU3uFwIN/7nn3+urbl8BZfd4LKf1Hi3Tlz9qaeekvUvvviituYyTFwuzJ07d8rV\nq1flv1EuXbpUW5uenpZjXf3MmTOyPjMzI+sqb8flUs3Pz8u6o+bc5ca8/PLLsu7WuptzlZnjMrNc\n3WXuvPrqq7K+f//+2prKCYpy2UyRexZ9P7j5XlxcrK2597m7p+79os7N5Sc988wzsu7uqzs3Nafu\nuqNrbdOmTbL+7bff1tZc9pN6N7l1fBe/DAEAgNRohgAAQGo0QwAAIDWaIQAAkBrNEAAASI1mCAAA\npNbS1vpS9Da15eXl2prbEhjZOu+47cbO7OysrKst5u66urp0P3ry5ElZV/c1ss2yGWrLsItKcOvB\nbePcuHFjbe2TTz6RY5vZeq+2Yru4g4WFhbZqpfiYB7f1/sKFC7KuntGJiQk5dmRkRNbXrFkj61eu\nXKmtvfLKK3Jsb2+vrEfXsnoO3dZ4t83b1V28xuuvv15bO3DggByrnqOqquR9c9uZ1T2Lvu/dPXfz\nrc49Gr3RTDRHnc2bN8ux7vvA3Vd3X1TdXZc7N1d39/3ZZ5+trR07dqztz2ZrPQAAQBNohgAAQGo0\nQwAAIDWaIQAAkBrNEAAASI1mCAAApEYzBAAAUms5Z0hRmRYug6Cvr0/Wx8fHZV3lL6hslVLiOSEq\nZ8hdt8vTWLlyZdvjXVaP485d3ReXM+S4TAp1bVu3bm17bCn/d09HR0dr6y7rQ+VSufl2z8HAwICs\nuywg9SwMDw/LsW4tuiwgtZ7cnLh77u6ro9aye/4dl98SsXPnzraP3Wg0wtdWx707XM6QW0tuPajs\npqWlJTnWieQMRXKAmuEyq9R7NTpnbk4cdW4vvfRS28deXFxs6vj8MgQAAFKjGQIAAKnRDAEAgNRo\nhgAAQGo0QwAAIDWaIQAAkBrNEAAASK3lcA6VRRDJV3BZQPPz87Ieycvo7++X9bGxMVmP5CsdOHBA\n1l2ujLqvLqvHcbkyKnfCZU5E8zZU1kc016XRaMi8H5UrVUopQ0NDtbW1a9fKsW69uGNfuXJF1lXm\nhss4WrNmjay75+jIkSO1NZdL5ebUrXV3X10eT7tjS/EZStFsGcU9J5HcGXVfovfMfR846p5GsnhK\n8ef+2muvtT3WiY5X35Muq8s9o269RL+POv3Z/DIEAABSoxkCAACp0QwBAIDUaIYAAEBqNEMAACA1\nmiEAAJAazRAAAEit5ZwhRe31d1kbru5yhlTGicu8GB8fl3WXv6IyLVwuxNGjR2V9165dsq5yI9x1\nu2wmlxvjcimUSI6QGx/N4ihFr2V37hMTE7W1kZEROXZqaqrtzy6llIsXL8r69evXa2tuPl3ulFsv\nL7zwQm3tyy+/lGNdjojKvCrFX1skt8q9u9y5368coqqqZOaOOy91z918uHui8rBK8eem5szl4Tju\nvXrw4MHa2htvvCHHRt+L7twic+aeIXdsl+8UeaeTMwQAABBEMwQAAFKjGQIAAKnRDAEAgNRohgAA\nQGo0QwAAILWW9kZXVVWWl5dr62rLotsyuLS0JOtuG7g6r4GBATl21apVsj48PCzrEW6bpzs3Nb67\nuzt0bDdeiWyjbKautlrei237s7OztXUX86DWqtt+vm7dOll3c+bqanusm+/R0VFZdxEUavurO+/o\n9nT3+WpNuGNHt/XeiyiIdjQaDXlf3DOs1lJ0vtzWenduka31nay7+xJ9d7nvSVV3W+fdZ0e3/Uc+\n+17glyEAAJAazRAAAEiNZggAAKRGMwQAAFKjGQIAAKnRDAEAgNRohgAAQGot5QzduXOnXLt2rbYe\nyVdwOQKRfAaX3eC4XAn1+W5sb2+vrH/33XeyvnHjRllXXO5DM3k8dVwOiMqFKsXnkKi6G+tUVSVz\nr9xaVHk9kayNUkoZHx+XdZcFMjY2Vltz16XGluLX8sLCQm3tzTfflGMPHz4s6+66I9kw0QykaEZK\n5L2qxjYaDTlnPT098rPVWnbX7OouG86NV+8f9+5xz2jkvfnRRx/JsTt37gwdO5KnFZ0z9z0beU6i\n781m8MsQAABIjWYIAACkRjMEAABSoxkCAACp0QwBAIDUaIYAAEBqNEMAACC1lnOGZmdna+sqC6DT\nWRz9/f21NZcrMT8/H6qrXBuVOVNKLC/D1Ves0NPrsllcboQ6tsrpcWObObaqR9dSo9GQ8xa5r+7c\n3Fpz+StDQ0OyPjk52bFju/uyuLhYW3P5KO45csfu6+uTdXX8aAaaq0dEMpCqqpLvLpczpJ5x93w7\nbq056rqjWT1OJC/HvZM7mTPk8tmi31Xu89U7vZPP0F38MgQAAFKjGQIAAKnRDAEAgNRohgAAQGo0\nQwAAIDWaIQAAkBrNEAAASK2lnKGqqmQWgMoRcRkF0fwFlTPi8g/csSOZGS4vxx3b1U+cOFFb27Jl\nixzr5sTV1bV1MnPCieaElKLXm/t8NWfRDCR3bJcN09vbW1tzWT6OuzZ1bhMTE3Ls0aNHZX3Xrl2y\n7q5N5Zi4tRjNQImMj6z1qqrkO9s9o5F75rjMq2j2U4S75+rd4d7nhw4dkvUdO3bIeuSd7ca69RB9\n50fm7F68c/llCAAApEYzBAAAUqMZAgAAqdEMAQCA1GiGAABAajRDAAAgtZa21l+4cKG8//77tXW1\nbc9tm4turd+3b19b51WK33rntlKq8W47YXQLqRKJBIh+fnSbpVsPkS3F7rPPnz9fdu/e3fZ4xZ23\ne04OHjwo62qrtPt8t9aWl5dl3enr66utjY2NybGDg4Ntf3Yz1DvCvT9cPRr1oMZHYh6i6zzyHLh7\nduDAAVmPbG/v9HeRipBQETClxKNY3LWpZzwaR+De6ZF4nWgkSTP4ZQgAAKRGMwQAAFKjGQIAAKnR\nDAEAgNRohgAAQGo0QwAAIDWaIQAAkFpLOUOltL/fP5q14fIVVMaBy0dxuRHumiPZLZGsjlJ0no/L\nnHG5EG7O1H1197yT9yWal9FJ0XO7efOmrLs5VTkm7p67OXXrRdVd/srAwICsR/NbVN3d00i2SzPU\n50cy0BqNhrxvkWfQXbOru/mM5CtFs3oiGUeR874XdXXfo+u00+fermavi1+GAABAajRDAAAgNZoh\nAACQGs0QAABIjWYIAACkRjMEAABSoxkCAACpNVrJFmg0GtOllD86dzrAv8L/lFL+c79PAugw1jky\neKSqqtXuH7XUDAEAAPy34X+TAQCA1GiGAABAajRDAAAgNZohAACQGs0QAABIjWYIAACkRjMEAABS\noxkCAACp0QwBAIDU/hcIDu1BotqjagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177a007b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 1\n",
    "alpha = 1.\n",
    "overlaid_img = cls_img_set[img_id] - np.amin(cls_img_set[img_id])\n",
    "overlaid_img = np.stack([((activ_map0[img_id] > np.mean(activ_map0[img_id])*alpha)+.5) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "hf.draw_slices(overlaid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf.draw_slices(cls_img_set[img_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_div(m1, sig1, m2, sig2, one_sided=\"none\"):\n",
    "    #returns kl(p,q) where p~N(m1,s1), q~N(m2,s2)\n",
    "    ret = np.log(sig2/sig1) + (sig1**2+(m1-m2)**2)/(2*sig2**2) - .5\n",
    "    if one_sided==\"less\":\n",
    "        return ret * (m1 < m2)\n",
    "    elif one_sided==\"greater\":\n",
    "        return ret * (m1 > m2)\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv1_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-6)#, add_activ=True)\n",
    "model_conv2_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-5)#, add_activ=True)\n",
    "model_conv3_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-4)#, add_activ=True)\n",
    "model_dense_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-3)#, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12572068_0', '13092836_1', 'E103354630_0', 'E105921537_0', 'E106010098_0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = sorted(list(feat_count.keys()))\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df = drm.get_voi_dfs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = np.concatenate([orig_data_dict[cls][1] for cls in C.classes_to_include], 0)\n",
    "\n",
    "all_conv2_ch = np.empty([0,128])\n",
    "all_conv3_ch = np.empty([0,128])\n",
    "\n",
    "aug_factor = 10\n",
    "for img_id in range(len(Z)):\n",
    "    voi_row = voi_df.loc[Z[img_id]]\n",
    "    for aug_id in range(aug_factor):\n",
    "        img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "        activ = model_conv2_pre.predict(np.expand_dims(img, 0))\n",
    "        all_conv2_ch = np.concatenate([all_conv2_ch, activ.mean(axis=(1,2,3))], axis=0)\n",
    "        activ = model_conv3_pre.predict(np.expand_dims(img, 0))\n",
    "        all_conv3_ch = np.concatenate([all_conv3_ch, activ.mean(axis=(1,2,3))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'arterial enhancement'), (1, 'continuous enhancing rim'), (2, 'delayed isointensity'), (3, 'heterogeneous'), (4, 'hyperintense mass on delayed phase'), (5, 'hypointense without enhancement'), (6, 'infiltrative'), (7, 'lobulated margins'), (8, 'nodular or discontinuous enhancement'), (9, 'progressive centripetal filling'), (10, 'progressive or concentric enhancement'), (11, 'regular spherical hypointense mass'), (12, 'thin well-defined walls'), (13, 'venous washout')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(range(len(all_features)), all_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevant_features = [1,10,11] #colorectal#[0,1,3,13] #hcc, [3,7,10] cholangio\n",
    "img_dir = \"D:\\\\feature_analysis\\\\crc\"\n",
    "if not exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "num_rel_f = len(relevant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D = np.empty((8,8,4))\n",
    "for x in range(D.shape[0]):\n",
    "    for y in range(D.shape[1]):\n",
    "        for z in range(D.shape[2]):\n",
    "            D[x,y,z] = (D.shape[0]-.5-x)**2 + (D.shape[1]-.5-y)**2 + 4*(D.shape[2]-.5-z)**2\n",
    "\n",
    "def get_shells(activ, D):\n",
    "    shell4 = activ[0, D > 85, :].mean(axis=0)\n",
    "    shell3 = activ[0, (D <= 85) & (D > 62), :].mean(axis=0)\n",
    "    shell2 = activ[0, (D <= 62) & (D > 39), :].mean(axis=0)\n",
    "    shell1 = activ[0, D <= 39, :].mean(axis=0)\n",
    "    return np.expand_dims(np.stack([shell1, shell2, shell3, shell4], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conv1_ch = {f:np.empty([0,12,12,6,128]) for f in all_features}\n",
    "#feature_conv2_ch = {f:np.empty([0,12,12,6,128]) for f in all_features}\n",
    "#feature_conv3_ch = {f:np.empty([0,12,12,6,128]) for f in all_features}\n",
    "#feature_conv3_sh = {f:np.empty([0,4,128]) for f in all_features}\n",
    "aug_factor = 80\n",
    "for f_ix in relevant_features:\n",
    "    f = all_features[f_ix]\n",
    "    Z_f = Z_features[f]\n",
    "    for img_id in range(len(Z_f)):\n",
    "        voi_row = voi_df.loc[Z_f[img_id]]\n",
    "        for aug_id in range(aug_factor):\n",
    "            img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z_f[img_id], aug_id)))\n",
    "            activ = model_conv1_pre.predict(np.expand_dims(img, 0))\n",
    "            feature_conv1_ch[f] = np.concatenate([feature_conv1_ch[f], activ], axis=0)\n",
    "            #activ = model_conv2_pre.predict(np.expand_dims(img, 0))\n",
    "            #feature_conv2_ch[f] = np.concatenate([feature_conv2_ch[f], activ], axis=0)\n",
    "            #activ = model_conv3_pre.predict(np.expand_dims(img, 0))\n",
    "            #feature_conv3_ch[f] = np.concatenate([feature_conv3_ch[f], activ], axis=0)\n",
    "            #feature_conv3_sh[f] = np.concatenate([feature_conv3_sh[f], get_shells(activ, D)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_ch_plus = copy.deepcopy(feature_conv1_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv1_ch_plus[f][conv1_ch_plus[f] < 0] = 0\n",
    "    conv1_ch_plus[f] = conv1_ch_plus[f].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2_ch_plus = copy.deepcopy(feature_conv2_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv2_ch_plus[f][conv2_ch_plus[f] < 0] = 0\n",
    "    conv2_ch_plus[f] = conv2_ch_plus[f].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3_ch_plus = copy.deepcopy(feature_conv3_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv3_ch_plus[f][conv3_ch_plus[f] < 0] = 0\n",
    "    conv3_ch_plus[f] = conv3_ch_plus[f].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3_sh_plus = {}\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    activ = conv3_ch_plus[f]\n",
    "    shell4 = activ[D > 85, :].mean(0)\n",
    "    shell3 = activ[(D <= 85) & (D > 62), :].mean(0)\n",
    "    shell2 = activ[(D <= 62) & (D > 39), :].mean(0)\n",
    "    shell1 = activ[D <= 39, :].mean(0)\n",
    "    conv3_sh_plus[f] = np.stack([shell1, shell2, shell3, shell4], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_avgs = np.zeros((num_rel_f,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv1_ch_plus[f].mean((0,1,2))\n",
    "    #feature_avgs[i] = conv3_ch_plus[f].mean((0,1,2))\n",
    "    \n",
    "channel_separations = np.empty((num_rel_f,128)) # separation between channel mean activations for the relevant features\n",
    "for i in range(num_rel_f):\n",
    "    channel_separations[i] = (np.amax(feature_avgs, 0) - feature_avgs[i]) / np.mean(feature_avgs, 0)\n",
    "\n",
    "channel_separations *= 10\n",
    "\n",
    "W = np.zeros((num_rel_f,128))\n",
    "for ch_ix in range(128):\n",
    "    #f_ix = list(channel_separations[:,ch_ix]).index(0)\n",
    "    #W[f_ix,ch_ix] = channel_separations[:,ch_ix].mean()\n",
    "    W[:,ch_ix] = np.median(channel_separations[:,ch_ix]) - channel_separations[:,ch_ix]\n",
    "    \n",
    "W[W < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_avgs = np.zeros((4,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_sh_plus[f].mean(0).max(0)\n",
    "    \n",
    "channel_separations = np.empty((4,128))\n",
    "for i in range(4):\n",
    "    channel_separations[i] = np.amax(feature_avgs, 0) - feature_avgs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "active_neuron_ixs = np.where(h_ic_rot[0] > 0)\n",
    "\n",
    "num_active_neurons = active_neuron_ixs[0].size\n",
    "\n",
    "H = h_ic[h_ic > 0]\n",
    "np.matmul(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_spatial_overlap(w, f_c3_ch):\n",
    "    relevant_features = ch_weights.keys()\n",
    "    \n",
    "    ch_weights2 = np.zeros(num_rel_f,128)\n",
    "    for ch in range(128):\n",
    "        f_c3_ch[:,:,:,:,ch] = (f_c3_ch[:,:,:,:,ch] - np.mean(f_c3_ch[:,:,:,:,ch]))# / np.std(f_c3_ch[:,:,:,:,ch])\n",
    "        \n",
    "        if ch_weights[ch] > 0:\n",
    "            w = np.zeros(f_c3_ch.shape[:4])\n",
    "            for i in range(128):\n",
    "                if ch_weights[i] > 0:\n",
    "                    w += ch_weights[i] * f_c3_ch[:,:,:,:,i]\n",
    "            w = w / np.sum(ch_weights)\n",
    "            ch_weights2[ch] = np.sum(f_c3_ch[:,:,:,:,ch] * w)\n",
    "            \n",
    "    return ch_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls = 'colorectal'\n",
    "cls_img_set = orig_data_dict[cls][0]\n",
    "#cls_activ_set = model_conv3_pre.predict(cls_img_set)\n",
    "\n",
    "img_id = 0\n",
    "x = cls_img_set[img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#h_ic = [model_conv1_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "#h_ic = [model_conv2_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "h_ic = [model_conv3_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "\n",
    "h_ic_plus = copy.deepcopy(h_ic)\n",
    "for r in range(4):\n",
    "    h_ic_plus[r][h_ic_plus[r] < 0] = 0\n",
    "\n",
    "h_ic_rot = [np.rot90(h_ic_plus[r], 4-r) for r in range(4)] #rotated back into original frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_ic_rot = np.array(h_ic_rot)\n",
    "test_neurons = h_ic_rot.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = [h_ic_rot[a][active_neuron_ixs] for a in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.sum(3*np.matmul(H[0], W) - np.matmul(H[1], W) - np.matmul(H[2], W) - np.matmul(H[3], W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h_ca = {f_ix: feature_conv3_ch[all_features[f_ix]].mean((0,1,2,3)) for f_ix in relevant_features}\n",
    "h_ca_plus = {f_ix: feature_conv3_ch[all_features[f_ix]][feature_conv3_ch[all_features[f_ix]] > 0].mean((0,1,2,3)) for f_ix in relevant_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = np.tile(h_ca[f_ix], list(h_ic.shape[:3])+[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f_ix in relevant_features:\n",
    "    w_ica[f_ix] = h_ic_plus / (np.abs(h_ic_plus - h_ca[f_ix]) + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = cls_img_set[img_id]\n",
    "test_neurons = model_conv3_pre.predict(np.expand_dims(x,0))[0]\n",
    "test_neurons[test_neurons < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = all_conv2_ch.mean(0)\n",
    "s = all_conv2_ch.std(0)\n",
    "ch_weights = np.empty((num_rel_f, 128))\n",
    "for f_num, f_ix in enumerate(relevant_features):\n",
    "    f_c3_ch = feature_conv2_ch[all_features[f_ix]]\n",
    "    avg_f_conv3_ch = f_c3_ch.mean((1,2,3))\n",
    "    f_m = avg_f_conv3_ch.mean(0)\n",
    "    f_s = avg_f_conv3_ch.std(0)\n",
    "\n",
    "    ch_weights[f_num] = np.log(kl_div(m, s, f_m, f_s, 'less')+1) #kl_div(m, s, f_m, f_s, 'less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_id = 0\n",
    "z = orig_data_dict[cls][1][img_id]\n",
    "\n",
    "ch_weights2 = get_spatial_overlap(ch_weights, feature_conv3_ch, z)\n",
    "ch_weights2[ch_weights2 < np.median(ch_weights2) / 2] = 0 #np.median(ch_weights2) / 2\n",
    "ch_weights[all_features[f_ix]] *= ch_weights2\n",
    "ch_weights[all_features[f_ix]] /= np.mean(ch_weights[all_features[f_ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_saliency_map(W, test_neurons, num_rel_f):\n",
    "    sal_map = np.zeros((num_rel_f, *test_neurons.shape[:3]))\n",
    "    for f_num in range(num_rel_f):\n",
    "        for ch_ix in range(test_neurons.shape[-1]):\n",
    "            sal_map[f_num] += W[f_num, ch_ix] * test_neurons[:,:,:,ch_ix]\n",
    "        sal_map[f_num] /= np.sum(W[f_num])\n",
    "        \n",
    "    #for f_num in range(num_rel_f):\n",
    "    #    for spatial_ix in np.ndindex(test_neurons.shape[:-1]):\n",
    "    #        sal_map[f_num, spatial_ix] = sal_map[f_num, spatial_ix]**2 / sal_map[:, spatial_ix].sum()\n",
    "            \n",
    "    return sal_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neurons = h_ic_rot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = orig_data_dict[cls][1][img_id]\n",
    "layer_type = 'conv1'\n",
    "#layer_type = 'conv3'\n",
    "#for f_num, f_ix in enumerate(relevant_features):\n",
    "sal_map = get_saliency_map(W, test_neurons, num_rel_f)\n",
    "for f_num in range(num_rel_f):\n",
    "    sal_map_f = sal_map[f_num]\n",
    "    if False:\n",
    "        w = np.zeros(test_neurons.shape[:3])\n",
    "        for ch_ix in range(128):\n",
    "            if W[f_num, ch_ix] > 0:\n",
    "                w += W[f_num, ch_ix] * test_neurons[:,:,:,ch_ix]\n",
    "        sal_map_f = w / np.sum(W[f_num])\n",
    "        #sal_map_f0, _ = tr.rescale_img(sal_map_f0, x.shape[:3])\n",
    "        \n",
    "    sal_map_f = tr.scale3d(sal_map_f, (2,2,2))\n",
    "\n",
    "    #for img_id in range(len(cls_img_set)):\n",
    "    alpha = 1\n",
    "    overlaid_img = x - np.amin(x)\n",
    "    overlaid_img = np.stack([((sal_map_f > np.mean(sal_map_f[sal_map_f > 0])*alpha)+.3) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "    hf.draw_slices(overlaid_img[:,::-1,:], save_path=img_dir+\"\\\\%s %s (%s).png\" % (layer_type, z, all_features[relevant_features[f_num]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
