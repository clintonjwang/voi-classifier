{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:10:56.894478Z",
     "start_time": "2018-07-18T16:10:50.950390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import importlib\n",
    "import itertools\n",
    "import operator\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from math import e, exp, log, pi, sqrt\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "import keras.layers as layers\n",
    "import copy\n",
    "import keras.models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from numba import guvectorize, jit, njit, prange, vectorize\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from os.path import *\n",
    "import glob\n",
    "import cnn_builder as cbuild\n",
    "import cnn_runner as crun\n",
    "import config\n",
    "import dr_methods as drm\n",
    "import feature_interpretation as cnna\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.private as prv\n",
    "import niftiutils.transforms as tr\n",
    "import niftiutils.visualization as vis\n",
    "import voi_methods as vm\n",
    "import feature_influence as finf\n",
    "import niftiutils.deep_learning.common as common\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "c = tf.ConfigProto()\n",
    "c.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=c)\n",
    "K.set_session(sess)\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T14:50:22.823125Z",
     "start_time": "2018-07-19T14:50:22.759134Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(drm)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(cnna) \n",
    "importlib.reload(crun)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams(C.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T14:49:42.112672Z",
     "start_time": "2018-07-19T14:49:42.102670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R.pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T15:42:10.218645Z",
     "start_time": "2018-07-19T14:50:24.889501Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = crun.CNNRunner(C,T)\n",
    "R.run_fixed_hyperparams(max_runs=2, Z_test=C.Z_reader, model_name='fixZ_std_', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE for feature identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:10:57.895992Z",
     "start_time": "2018-07-18T16:10:57.024890Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "num_annotations = 10\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"homogeneous texture\")\n",
    "all_features = sorted(list(feat_count.keys()))\n",
    "cls_features = {f: [c for c in C.cls_names if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls, num_annotations)\n",
    "Z_features.pop(\"homogeneous texture\")\n",
    "\n",
    "num_features = len(all_features) # number of features\n",
    "\n",
    "all_imgs = [orig_data_dict[cls][0] for cls in C.cls_names]\n",
    "all_imgs = np.array(hf.flatten(all_imgs))\n",
    "\n",
    "all_lesionids = [orig_data_dict[cls][1] for cls in C.cls_names]\n",
    "all_lesionids = np.array(hf.flatten(all_lesionids))\n",
    "test_indices = np.where(np.isin(all_lesionids, C.Z_reader))[0]\n",
    "\n",
    "x_test = all_imgs[test_indices]\n",
    "z_test = all_lesionids[test_indices]\n",
    "\n",
    "full_dfs = []\n",
    "\n",
    "train_indices = np.where(~np.isin(all_lesionids, C.Z_reader))[0]\n",
    "z_train = all_lesionids[train_indices]\n",
    "x_train = all_imgs[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:10:59.536145Z",
     "start_time": "2018-07-18T16:10:59.532175Z"
    }
   },
   "outputs": [],
   "source": [
    "model_prefix = 'fixZ_std_'\n",
    "model_ix = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T14:32:25.565159Z",
     "start_time": "2018-07-19T14:32:25.561171Z"
    }
   },
   "outputs": [],
   "source": [
    "features_cls_dict = {f:[cls for cls in C.cls_names if f in features_by_cls[cls]] for f in all_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_features = {f:[] for f in all_features}\n",
    "for f in all_features:\n",
    "    for g in all_features:\n",
    "        if len(set(features_cls_dict[g]).intersection(features_cls_dict[f])) == 0:\n",
    "            excl_features[f].append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T04:26:42.320902Z",
     "start_time": "2018-07-13T04:26:27.641384Z"
    }
   },
   "source": [
    "fullM = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "M = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "M = common.pop_n_layers(M, 3)\n",
    "\n",
    "all_dense = cnna.get_overall_activations(M, orig_data_dict)\n",
    "feature_dense = cnna.get_feature_activations(M, Z_features, all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:13:02.290494Z",
     "start_time": "2018-07-18T16:11:01.236973Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnna)\n",
    "fullM = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "model_fc = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "model_fc = common.pop_n_layers(model_fc, 3)\n",
    "model_conv = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "model_conv = common.pop_n_layers(model_conv, 9)\n",
    "\n",
    "all_dense = cnna.get_overall_activations(z_train_cls, model_fc, samples=1000)\n",
    "feature_dense = cnna.get_feature_activations(Z_features, all_features, model_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "importlib.reload(cnna)\n",
    "train_df = cnna.predict_test_features(fullM, model_fc, all_dense, feature_dense, x_train, z_train, Z_features=Z_features, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:59:50.128056Z",
     "start_time": "2018-07-19T03:58:37.643572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................"
     ]
    }
   ],
   "source": [
    "importlib.reload(cnna)\n",
    "test_df = cnna.predict_test_features(fullM, model_fc, all_dense, feature_dense, x_test, z_test, num_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.pickle_dump(train_df, join(C.model_dir, \"train_df_fc_22.bin\"))\n",
    "hf.pickle_dump(test_df, join(C.model_dir, \"test_df_fc_22.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = hf.pickle_load(join(C.model_dir, \"train_df_fc_29.bin\"))\n",
    "test_df = hf.pickle_load(join(C.model_dir, \"test_df_fc_29.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {f:0 for f in all_features}\n",
    "thresh = {f:0 for f in all_features}\n",
    "for f in all_features:\n",
    "    priors[f] = np.max(train_df.loc[:, f].values)\n",
    "    thresh[f] = np.min(train_df.loc[Z_features[f], f].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:25:43.201613Z",
     "start_time": "2018-07-18T21:25:43.148726Z"
    },
    "scrolled": true
   },
   "source": [
    "priors = {f:0 for f in all_features}\n",
    "for cls in C.cls_names:\n",
    "    for f in all_features:\n",
    "        priors[f] += np.mean(np.log(train_df.loc[train_df[\"true_cls\"] == cls, f].values))\n",
    "        \n",
    "for f in all_features:\n",
    "    priors[f] = priors[f] / 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f in all_features:\n",
    "    priors[f] = np.max(np.log(test_df[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arterial phase enhancement 4.0294889885482225e-14\n",
      "central scar 1.0532548125362562e-07\n",
      "enhancing rim/capsule 3.9698073659735594e-10\n",
      "heterogeneous lesion 1.10490546641697e-07\n",
      "hyperenhancing mass on delayed phase 1.3481711915413372e-05\n",
      "hypoenhancing core 1.1569003880719032e-12\n",
      "infiltrative growth 3.007067323688302e-08\n",
      "isointense on venous/delayed phase 1.1505457064119962e-11\n",
      "nodular growth 3.9515623098548316e-08\n",
      "nodular or discontinuous enhancement 1.4324949433455533e-16\n",
      "progressive centripetal filling 5.848811181517043e-08\n",
      "progressive enhancement 7.483692409128709e-11\n",
      "thin-walled 1.2738670117116432e-07\n",
      "washout 1.0503880952957452e-16\n"
     ]
    }
   ],
   "source": [
    "for f in all_features:\n",
    "    print(f, thresh[f]/priors[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:05:23.406849Z",
     "start_time": "2018-07-19T04:05:23.402860Z"
    }
   },
   "outputs": [],
   "source": [
    "df = copy.deepcopy(test_df)\n",
    "for l_id in df.index:\n",
    "    for f in all_features:\n",
    "        df.loc[l_id, f] = df.loc[l_id, f] / priors[f] if df.loc[l_id, f] > thresh[f] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "arank = df.drop(['true_cls','pred_cls'], axis=1).apply(np.argsort, axis=1)\n",
    "ranked_cols = df.columns[2:].to_series()[arank.values[:,::-1]]\n",
    "new_df = pd.DataFrame(ranked_cols, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_f_cols = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "for ix,col in enumerate(pred_f_cols):\n",
    "    df[col] = new_df[ix].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lesion_id, row in df.iterrows():\n",
    "    for col in pred_f_cols[1:]:\n",
    "        f = row[col]\n",
    "        #exc = sum([row[g]>0 for g in excl_features[f]])\n",
    "        if row[f] == 0 or row['feature_1'] in excl_features[f]:#exc >= 1:\n",
    "            df.loc[lesion_id, f] = 0\n",
    "            df.loc[lesion_id, col] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arank = df.drop(['true_cls','pred_cls'] + pred_f_cols, axis=1).apply(np.argsort, axis=1)\n",
    "ranked_cols = df.columns[2:].to_series()[arank.values[:,::-1]]\n",
    "new_df = pd.DataFrame(ranked_cols, index=df.index)\n",
    "pred_f_cols = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "for ix,col in enumerate(pred_f_cols):\n",
    "    df[col] = new_df[ix].values\n",
    "for lesion_id, row in df.iterrows():\n",
    "    for col in pred_f_cols[1:]:\n",
    "        f = row[col]\n",
    "        if row[f] == 0:\n",
    "            df.loc[lesion_id, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753623188405797"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(116-9)/(154-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                      num_correct  pred_freq  true_freq\n",
       " arterial phase enhancement                   18.0       20.0       19.0\n",
       " central scar                                  1.0        3.0        1.0\n",
       " enhancing rim/capsule                         8.0       11.0       15.0\n",
       " heterogeneous lesion                         14.0       18.0       17.0\n",
       " hyperenhancing mass on delayed phase          5.0        5.0        8.0\n",
       " hypoenhancing core                           13.0       15.0       20.0\n",
       " infiltrative growth                           1.0        5.0        4.0\n",
       " isointense on venous/delayed phase            8.0        9.0        9.0\n",
       " nodular growth                                6.0        9.0        6.0\n",
       " nodular or discontinuous enhancement          8.0        8.0       10.0\n",
       " progressive centripetal filling               7.0        7.0        9.0\n",
       " progressive enhancement                      17.0       19.0       19.0\n",
       " thin-walled                                   5.0        5.0        8.0\n",
       " washout                                       8.0        9.0        9.0,\n",
       "             num_correct  pred_freq  true_freq\n",
       " cholangio          26.0       31.0       30.0\n",
       " colorectal         13.0       20.0       27.0\n",
       " cyst               15.0       15.0       18.0\n",
       " fnh                18.0       24.0       20.0\n",
       " hcc                27.0       30.0       32.0\n",
       " hemangioma         20.0       23.0       27.0,\n",
       " array([0.85 , 0.774]),\n",
       " array([ 3.,  6., 10.,  9.]),\n",
       " array([52., 60.]),\n",
       " array([2., 3.]),\n",
       " {'total': [0.8321678321678322],\n",
       "  'arterial phase enhancement': [0.8999955000225],\n",
       "  'central scar': [0.3333222225925802],\n",
       "  'enhancing rim/capsule': [0.727266115762584],\n",
       "  'heterogeneous lesion': [0.7777734568141288],\n",
       "  'hyperenhancing mass on delayed phase': [0.999980000399992],\n",
       "  'hypoenhancing core': [0.8666608889274071],\n",
       "  'infiltrative growth': [0.1999960000799984],\n",
       "  'isointense on venous/delayed phase': [0.8888790124554172],\n",
       "  'nodular growth': [0.6666592593415629],\n",
       "  'nodular or discontinuous enhancement': [0.999987500156248],\n",
       "  'progressive centripetal filling': [0.999985714489793],\n",
       "  'progressive enhancement': [0.8947321329887737],\n",
       "  'thin-walled': [0.999980000399992],\n",
       "  'washout': [0.8888790124554172],\n",
       "  'cholangio': [0.8387069719129938],\n",
       "  'colorectal': [0.6499967500162499],\n",
       "  'cyst': [0.9999933333777775],\n",
       "  'fnh': [0.7499968750130208],\n",
       "  'hcc': [0.8999970000099999],\n",
       "  'hemangioma': [0.8695614366894057]},\n",
       " {'total': [0.7727272727272727],\n",
       "  'arterial phase enhancement': [0.9473684210526315],\n",
       "  'central scar': [1.0],\n",
       "  'enhancing rim/capsule': [0.5333333333333333],\n",
       "  'heterogeneous lesion': [0.8235294117647058],\n",
       "  'hyperenhancing mass on delayed phase': [0.625],\n",
       "  'hypoenhancing core': [0.65],\n",
       "  'infiltrative growth': [0.25],\n",
       "  'isointense on venous/delayed phase': [0.8888888888888888],\n",
       "  'nodular growth': [1.0],\n",
       "  'nodular or discontinuous enhancement': [0.8],\n",
       "  'progressive centripetal filling': [0.7777777777777778],\n",
       "  'progressive enhancement': [0.8947368421052632],\n",
       "  'thin-walled': [0.625],\n",
       "  'washout': [0.8888888888888888],\n",
       "  'cholangio': [0.8666666666666667],\n",
       "  'colorectal': [0.48148148148148145],\n",
       "  'cyst': [0.8333333333333334],\n",
       "  'fnh': [0.9],\n",
       "  'hcc': [0.84375],\n",
       "  'hemangioma': [0.7407407407407407]})"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)\n",
    "cnna.process_feat_id_dfs(all_features, [df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155.0"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7727272727272727*154/0.7677419354838709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T23:12:36.409085Z",
     "start_time": "2018-06-13T23:12:36.406115Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:39:39.833525Z",
     "start_time": "2018-05-16T18:39:34.602623Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_num = 21\n",
    "model_path = join(C.model_dir, \"model_reader_new%d.hdf5\" % model_num)\n",
    "\n",
    "Z_reader = ['E103312835_1','12823036_0','12569915_0','E102093118_0','E102782525_0','12799652_0','E100894274_0','12874178_3','E100314676_0','12842070_0','13092836_2','12239783_0','12783467_0','13092966_0','E100962970_0','E100183257_1','E102634440_0','E106182827_0','12582632_0','E100121654_0','E100407633_0','E105310461_0','12788616_0','E101225606_0','12678910_1','E101083458_1','12324408_0','13031955_0','E101415263_0','E103192914_0','12888679_2','E106096969_0','E100192709_1','13112385_1','E100718398_0','12207268_0','E105244287_0','E102095465_0','E102613189_0','12961059_0','11907521_0','E105311123_0','12552705_0','E100610622_0','12975280_0','E105918926_0','E103020139_1','E101069048_1','E105427046_0','13028374_0','E100262351_0','12302576_0','12451831_0','E102929168_0','E100383453_0','E105344747_0','12569826_0','E100168661_0','12530153_0','E104697262_0']\n",
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"homogeneous texture\")\n",
    "#feat_count.pop(\"central scar\")\n",
    "all_features = sorted(list(feat_count.keys()))\n",
    "cls_features = {f: [c for c in C.cls_names if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"homogeneous texture\")\n",
    "#Z_features.pop(\"central scar\")\n",
    "\n",
    "num_features = len(all_features)\n",
    "\n",
    "voi_df = drm.get_voi_dfs()[0]\n",
    "M = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:41:23.282420Z",
     "start_time": "2018-05-14T16:41:18.726Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "M.layers[5].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:39:40.526930Z",
     "start_time": "2018-05-16T18:39:40.522920Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    print('Memory use:', py.memory_info()[0]/2.**30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T22:53:06.175337Z",
     "start_time": "2018-05-16T22:53:06.168343Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_num = 26\n",
    "model_path = join(C.model_dir, \"model_reader_new%d.hdf5\" % model_num)\n",
    "inf_xls_path = 'D:\\\\feature_analysis\\\\influence%d.xlsx' % model_num\n",
    "\n",
    "df = pd.DataFrame(columns=[\"true_cls\", \"pred_cls\"] + all_features)\n",
    "#df = pd.read_excel(inf_xls_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:40:01.196009Z",
     "start_time": "2018-05-16T18:40:00.906267Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Z_full = np.concatenate([orig_data_dict[cls][-1] for cls in C.cls_names],0)\n",
    "\n",
    "all_imgs = []\n",
    "all_cls = []\n",
    "\n",
    "for lesion_id in Z_full:\n",
    "    cls = voi_df.loc[lesion_id][\"cls\"]\n",
    "    img = np.load(join(C.orig_dir, cls, lesion_id+\".npy\"))\n",
    "    all_imgs.append(np.expand_dims(img,0))\n",
    "    all_cls.append(C.cls_names.index(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T22:53:20.252976Z",
     "start_time": "2018-05-16T22:53:17.016902Z"
    },
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(finf)\n",
    "del M, IA\n",
    "K.clear_session()\n",
    "M = keras.models.load_model(model_path)\n",
    "IA = finf.InfluenceAnalyzer(M, voi_df, all_imgs, all_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:26:17.670024Z",
     "start_time": "2018-05-17T01:11:44.778564Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "for lesion_id in Z_reader:\n",
    "    cls = voi_df.loc[lesion_id][\"cls\"]\n",
    "    img = np.load(join(C.orig_dir, cls, lesion_id+\".npy\"))\n",
    "    img = np.expand_dims(img,0)\n",
    "    pred_cls = M.predict(img)[0]\n",
    "    pred_cls = C.cls_names[list(pred_cls).index(pred_cls.max())]\n",
    "        \n",
    "    print(lesion_id)\n",
    "    \n",
    "    g_test = IA.get_grad(lesion_id, pred_cls=pred_cls)\n",
    "    s_test = IA.get_stest(g_test)\n",
    "\n",
    "    del M, IA\n",
    "    K.clear_session()\n",
    "    M = keras.models.load_model(model_path)\n",
    "    IA = finf.InfluenceAnalyzer(M, voi_df, all_imgs, all_cls)\n",
    "\n",
    "    I = {}\n",
    "    for f in Z_features:\n",
    "        I[f] = IA.get_avg_influence(Z_features[f], s_test)\n",
    "\n",
    "    del M, IA\n",
    "    K.clear_session()\n",
    "    M = keras.models.load_model(model_path)\n",
    "    IA = finf.InfluenceAnalyzer(M, voi_df, all_imgs, all_cls)\n",
    "    \n",
    "    df.loc[lesion_id] = [cls, pred_cls] + list(I[f] for f in df.columns[2:])\n",
    "\n",
    "    print(time.time() - t)\n",
    "    memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:26:50.959760Z",
     "start_time": "2018-05-17T14:26:50.955748Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\feature_analysis\\\\influence26.xlsx'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_xls_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:26:59.477623Z",
     "start_time": "2018-05-17T14:26:59.395197Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_excel(inf_xls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T22:45:33.942966Z",
     "start_time": "2018-05-14T22:45:33.790216Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cls = voi_df.loc[lesion_id][\"cls\"]\n",
    "x_test = np.load(join(C.orig_dir, cls, lesion_id+\".npy\"))\n",
    "vis.draw_slices(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T15:38:55.913414Z",
     "start_time": "2018-05-15T15:38:37.999551Z"
    },
    "hidden": true
   },
   "source": [
    "Memory leak test\n",
    "for _ in range(10):\n",
    "    memory()\n",
    "    g_test = IA.get_grad(lesion_id)\n",
    "memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:41:23.716962Z",
     "start_time": "2018-05-14T16:41:23.709943Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def perturb_weights(W_true, t):\n",
    "    eps = 1e-5\n",
    "    W = copy.deepcopy(W_true)\n",
    "    t_ix = 0\n",
    "    \n",
    "    for w_ix in range(len(W)):\n",
    "        W[w_ix] += eps * np.reshape(t[t_ix:t_ix+W[w_ix].size], W[w_ix].shape)\n",
    "        t_ix += W[w_ix].size\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:41:23.950594Z",
     "start_time": "2018-05-14T16:41:23.903360Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_grad(lesion_id, perturb_W=None):\n",
    "    C = config.Config()\n",
    "    \n",
    "    cls = voi_df.loc[lesion_id][\"cls\"]\n",
    "    img = np.load(join(C.orig_dir, cls, lesion_id+\".npy\"))\n",
    "    img = np.expand_dims(img,0)\n",
    "\n",
    "    y_true = np_utils.to_categorical(C.cls_names.index(cls), 6)\n",
    "    loss = K.categorical_crossentropy(y_true, M.output)\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        g = K.gradients(loss, M.trainable_weights)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        g_i = sess.run(g, feed_dict={M.input:img, K.learning_phase():0})\n",
    "        if perturb_W is not None:\n",
    "            feed_dict_plus = {M.trainable_weights[i]:perturb_W[i] for i in range(len(perturb_W))}\n",
    "            g_i_plus = sess.run(g, feed_dict={**feed_dict_plus, M.input:img, K.learning_phase():0})\n",
    "\n",
    "    g_i = np.concatenate([x.flatten() for x in g_i], 0)\n",
    "    \n",
    "    if perturb_W is not None:\n",
    "        g_i_plus = np.concatenate([x.flatten() for x in g_i_plus], 0)\n",
    "        return g_i, g_i_plus\n",
    "    \n",
    "    return g_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:41:24.068235Z",
     "start_time": "2018-05-14T16:41:24.062220Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_grads(Z_sample):\n",
    "    eps = 1e-5\n",
    "    Ht = np.zeros(g_test.shape)\n",
    "    feed_dict_plus = {M.trainable_weights[i]:perturb_W[i] for i in range(len(perturb_W))}\n",
    "    losses = [K.categorical_crossentropy(y_true, M.output) for y_true in \\\n",
    "              [np_utils.to_categorical(i, 6) for i in range(6)]]\n",
    "        \n",
    "    t = time.time()\n",
    "    with tf.device('/gpu:0'):\n",
    "        g = [K.gradients(loss, M.trainable_weights) for loss in losses]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for ix in range(len(Z_sample)):\n",
    "            g_i = sess.run(g[classes[ix]], feed_dict={M.input:imgs[ix], K.learning_phase():0})\n",
    "            g_i = np.concatenate([x.flatten() for x in g_i], 0)\n",
    "    if verbose:\n",
    "        print(time.time()-t)\n",
    "    \n",
    "    return Ht / len(Z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:47:12.468765Z",
     "start_time": "2018-05-14T16:47:12.429514Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_HVP(perturb_W, Z_sample, verbose=True):\n",
    "    eps = 1e-5\n",
    "    Ht = np.zeros(g_test.shape)\n",
    "    feed_dict_plus = {M.trainable_weights[i]:perturb_W[i] for i in range(len(perturb_W))}\n",
    "    losses = [K.categorical_crossentropy(y_true, M.output) for y_true in \\\n",
    "              [np_utils.to_categorical(i, 6) for i in range(6)]]\n",
    "        \n",
    "    t = time.time()\n",
    "    with tf.device('/gpu:0'):\n",
    "        g = [K.gradients(loss, M.trainable_weights) for loss in losses]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for ix in range(len(Z_sample)):\n",
    "            g_i = sess.run(g[classes[ix]], feed_dict={M.input:imgs[ix], K.learning_phase():0})\n",
    "            g_i_plus = sess.run(g[classes[ix]], feed_dict={**feed_dict_plus, M.input:imgs[ix], K.learning_phase():0})\n",
    "    \n",
    "            g_i = np.concatenate([x.flatten() for x in g_i], 0)\n",
    "            g_i_plus = np.concatenate([x.flatten() for x in g_i_plus], 0)\n",
    "\n",
    "            Ht += (g_i_plus - g_i)/eps\n",
    "    if verbose:\n",
    "        print(time.time()-t)\n",
    "    \n",
    "    return Ht / len(Z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:46:54.464603Z",
     "start_time": "2018-05-14T16:46:54.461595Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t_k = np.zeros(g_test.shape)\n",
    "r_k = g_test#-Ht\n",
    "p_k = r_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:59:44.825692Z",
     "start_time": "2018-05-14T16:47:36.093846Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_iters = 15\n",
    "#phi_hist = []\n",
    "t = time.time()\n",
    "for _ in range(num_iters):\n",
    "    #Z_sample = random.sample(list(Z_full), 15)\n",
    "    W_new = perturb_weights(W, p_k)\n",
    "    Hp = get_HVP(W_new, Z_full)\n",
    "\n",
    "    alpha = np.dot(r_k, r_k) / np.dot(p_k, Hp)\n",
    "    t_k += alpha * p_k\n",
    "    r_k2 = r_k - alpha * Hp\n",
    "    #phi_hist = .5*np.dot(t_k, Ht) - g_test\n",
    "\n",
    "    beta = np.dot(r_k2, r_k2) / np.dot(r_k, r_k)\n",
    "    r_k = r_k2\n",
    "    p_k = r_k + beta*p_k\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T17:02:07.903731Z",
     "start_time": "2018-05-14T17:02:07.899692Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T17:11:21.860049Z",
     "start_time": "2018-05-14T17:11:21.834986Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_grads(imgs, classes, s_test, verbose=True):\n",
    "    eps = 1e-5\n",
    "    Ht = np.zeros(g_test.shape)\n",
    "    losses = [K.categorical_crossentropy(y_true, M.output) for y_true in \\\n",
    "              [np_utils.to_categorical(i, 6) for i in range(6)]]\n",
    "        \n",
    "    I = 0\n",
    "    t = time.time()\n",
    "    with tf.device('/gpu:0'):\n",
    "        g = [K.gradients(loss, M.trainable_weights) for loss in losses]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for ix in range(len(classes)):\n",
    "            g_i = sess.run(g[classes[ix]], feed_dict={M.input:imgs[ix], K.learning_phase():0})\n",
    "            g_i = np.concatenate([x.flatten() for x in g_i], 0)\n",
    "            I -= np.dot(g_i, s_test)\n",
    "    if verbose:\n",
    "        print(time.time()-t)\n",
    "    \n",
    "    return I / len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T20:43:33.458882Z",
     "start_time": "2018-05-14T20:43:33.438831Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_0 = hf.pickle_load(join(C.base_dir, \"data\", \"DFs4.bin\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T20:28:44.605752Z",
     "start_time": "2018-05-14T20:28:44.576671Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\Clinton\\Documents\\voi-classifier\\data\"\n",
    "answer_key = join(data_dir, \"ground_truth.xlsx\")\n",
    "answer_key = pd.read_excel(answer_key, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T20:42:25.459019Z",
     "start_time": "2018-05-14T20:42:25.454004Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['true_cls', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
       "       'ignore_1', 'ignore_2', 'BLANK', 'Unnamed: 9', 'Class', 'Num features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_key.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T20:45:12.644340Z",
     "start_time": "2018-05-14T20:45:12.638323Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for z_test, row in answer_key.iterrows():\n",
    "    cls = df_0.loc[z_test, \"pred_cls\"]\n",
    "    feats = row[[f for f in answer_key.columns if f.startswith('feat')]].dropna().values\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T20:45:36.706311Z",
     "start_time": "2018-05-14T20:45:36.702299Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nodular growth', 'heterogeneous lesion',\n",
       "       'progressive enhancement'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "529px",
    "left": "1032.27px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
