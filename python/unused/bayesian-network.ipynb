{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T22:22:30.978876Z",
     "start_time": "2018-05-10T22:22:28.155613Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "import feature_interpretation as cnna\n",
    "import cnn_builder as cbuild\n",
    "import cnn_runner as crun\n",
    "import config\n",
    "import csv\n",
    "import dr_methods as drm\n",
    "import niftiutils.helper_fxns as hf\n",
    "import importlib\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "import voi_methods as vm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T22:22:31.001755Z",
     "start_time": "2018-05-10T22:22:30.992701Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(crun)\n",
    "importlib.reload(vm)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vm.reset_accnum('E100165687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"prob_model_305.hdf5\")) #models_305\n",
    "model_dense_outputs = cbuild.build_pretrain_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "filter_results = np.concatenate([filters_by_cls[cls] for cls in C.classes_to_include], axis=0)\n",
    "\n",
    "filter_avgs = np.mean(filter_results, axis=0)\n",
    "filter_stds = np.std(filter_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_test = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "num_units = 100 # number of dense units\n",
    "indices = np.array(hf.flatten([orig_data_dict[cls][1] for cls in C.classes_to_include]))\n",
    "test_indices = np.where(np.isin(indices, Z_test))[0]\n",
    "test_names = indices[test_indices]\n",
    "imgs = np.array(hf.flatten([orig_data_dict[cls][0] for cls in C.classes_to_include]))\n",
    "test_imgs = imgs[test_indices]\n",
    "\n",
    "test_size=len(test_names)\n",
    "voi_df = drm.get_voi_dfs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final_outputs = cbuild.build_pretrain_model(model, last_layer=\"pre-softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits, uncertainties = mc_augment(test_names[test_id], model, voi_df)\n",
    "\n",
    "logits = np.empty(aug_factor)\n",
    "uncertainties = np.empty(aug_factor)\n",
    "for aug_id in range(aug_factor):\n",
    "    img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (test_names[test_id], aug_id)))\n",
    "    logits[aug_id], uncertainties[aug_id] = model_dense_outputs.predict(np.expand_dims(img, 0))[0]\n",
    "\n",
    "cls_accuracy[test_id] = sum(classif == C.classes_to_include.index(voi_row['cls']))/aug_factor\n",
    "aug_means[test_id] = np.mean(outputs, 0)\n",
    "aug_stds[test_id] = np.std(outputs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variability in augmentation (epistemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_names[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aug_factor=100\n",
    "\n",
    "aug_means = np.empty((test_size, num_units))\n",
    "aug_stds = np.empty((test_size, num_units))\n",
    "aug_accuracy = np.empty(test_size)\n",
    "\n",
    "for test_id in range(test_size):\n",
    "    voi_row = voi_df.loc[test_names[test_id]]\n",
    "    \n",
    "    outputs = np.empty((aug_factor, num_units))\n",
    "    classif = np.empty(aug_factor)\n",
    "    for aug_id in range(aug_factor):\n",
    "        img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (test_names[test_id], aug_id)))\n",
    "        outputs[aug_id] = model_dense_outputs.predict(np.expand_dims(img, 0))[0]\n",
    "        classif[aug_id], _ = max(enumerate(model.predict(np.expand_dims(img, 0))[0]), key=operator.itemgetter(1))\n",
    "    \n",
    "    aug_accuracy[test_id] = sum(classif == C.classes_to_include.index(voi_row['cls']))/aug_factor\n",
    "    aug_means[test_id] = np.mean(outputs, 0)\n",
    "    aug_stds[test_id] = np.std(outputs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The standard deviation of the dense unit values is very large for the same lesion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variability in VOI selection (epistemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_voi_df = pd.read_csv(C.small_voi_path)\n",
    "dims_df = pd.read_csv(C.dims_df_path)\n",
    "\n",
    "voi_means = np.empty((test_size, num_units))\n",
    "voi_stds = np.empty((test_size, num_units))\n",
    "voi_accuracy = np.empty(test_size)\n",
    "\n",
    "shift_combinations = tuple([seq for seq in itertools.product([-5,0,5], repeat=6) if \\\n",
    "                            seq[1] >= seq[0] and seq[3] >= seq[2] and seq[5] >= seq[4]])\n",
    "voi_factor=len(shift_combinations)\n",
    "\n",
    "for test_id in range(test_size):\n",
    "    lesion_id = test_names[test_id]\n",
    "    coords = vm._get_voi_coords(small_voi_df[small_voi_df[\"id\"] == lesion_id])\n",
    "    voi_row = voi_df.loc[test_names[test_id]]\n",
    "    \n",
    "    outputs = np.empty((voi_factor, num_units))\n",
    "    classif = np.empty(voi_factor)\n",
    "    \n",
    "    dims = dims_df[dims_df[\"AccNum\"] == lesion_id[:lesion_id.rfind('_')]].iloc[0]\n",
    "    shifts = [hf.flatten([x[:2]//dims['x'], x[2:4]//dims['y'], x[4:]//dims['z']]) for x in shift_combinations]\n",
    "    for voi_id in range(voi_factor):\n",
    "        dx = shifts[voi_id]#scipy.random.normal(0, 2, 3)\n",
    "        #voi = list(map(int, hf.flatten([coords[:2]+dx[0], coords[2:4]+dx[1], coords[4:]+dx[2]])))\n",
    "        voi = list(map(int, [coords[i]+dx[i] for i in range(6)]))\n",
    "        img = vm.save_unaugmented_set(cls=voi_row[\"cls\"], lesion_ids=[lesion_id], custom_vois=[voi],\n",
    "                                      return_img_only=True)[0]\n",
    "        img = np.expand_dims(img, 0)\n",
    "        outputs[voi_id] = model_dense_outputs.predict(img)[0]\n",
    "        classif[voi_id], _ = max(enumerate(model.predict(img)[0]), key=operator.itemgetter(1))\n",
    "        \n",
    "    voi_accuracy[test_id] = sum(classif == C.classes_to_include.index(voi_row['cls']))/voi_factor\n",
    "    voi_means[test_id] = np.mean(outputs, 0)\n",
    "    voi_stds[test_id] = np.std(outputs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variability with MC dropout (epistemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dropout = cbuild.build_model_dropout(model, 0.3)\n",
    "mc_model_dense_outputs = cbuild.build_model_dropout(model, 0.3, \"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnts = np.unique(classif, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 50\n",
    "\n",
    "mc_means = np.empty((test_size, num_units))\n",
    "mc_stds = np.empty((test_size, num_units))\n",
    "mc_certainty = np.empty(test_size)\n",
    "mc_precision = np.empty(test_size)\n",
    "\n",
    "for test_id in range(test_size):\n",
    "    voi_row = voi_df.loc[test_names[test_id]]\n",
    "    img = test_imgs[test_id]\n",
    "    \n",
    "    outputs = np.empty((T, num_units))\n",
    "    classif = np.empty(T)\n",
    "    for ix in range(T):\n",
    "        outputs[ix] = mc_model_dense_outputs.predict(np.expand_dims(img, 0))[0]\n",
    "        classif[ix], _ = max(enumerate(model_dropout.predict(np.expand_dims(img, 0))[0]), key=operator.itemgetter(1))\n",
    "    \n",
    "    cnts = np.unique(classif, return_counts=True)\n",
    "    mc_precision[test_id] = C.classes_to_include[int(cnts[0][list(cnts[1]).index(max(cnts[1]))])] == voi_row['cls']\n",
    "    mc_certainty[test_id] = sum(classif == C.classes_to_include.index(voi_row['cls']))/T\n",
    "    mc_means[test_id] = np.mean(outputs, 0)\n",
    "    mc_stds[test_id] = np.std(outputs, 0)\n",
    "\n",
    "mc_accuracy = np.mean(mc_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
