{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import cnn_runner as crun\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.private as prv\n",
    "import importlib\n",
    "import inference_methods_squash as im\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp, e\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "import dr_methods as drm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(crun)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_div(m1, sig1, m2, sig2, one_sided=\"none\"):\n",
    "    #returns kl(p,q) where p~N(m1,s1), q~N(m2,s2)\n",
    "    ret = np.log(sig2/sig1) + (sig1**2+(m1-m2)**2)/(2*sig2**2) - .5\n",
    "    if one_sided==\"less\":\n",
    "        return ret * (m1 < m2)\n",
    "    elif one_sided==\"greater\":\n",
    "        return ret * (m1 > m2)\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305\n",
    "\n",
    "model_conv2 = cbuild.build_pretrain_model(model, last_layer=-5)\n",
    "model_conv3 = cbuild.build_pretrain_model(model, last_layer=-4)\n",
    "model_pre_act = cbuild.build_pretrain_model(model, last_layer=-3)\n",
    "model_act = cbuild.build_pretrain_model(model, last_layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12572068_0', '13092836_1', 'E103354630_0', 'E105921537_0', 'E106010098_0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.empty((8,8,4))\n",
    "for x in range(D.shape[0]):\n",
    "    for y in range(D.shape[1]):\n",
    "        for z in range(D.shape[2]):\n",
    "            D[x,y,z] = (D.shape[0]-.5-x)**2 + (D.shape[1]-.5-y)**2 + 4*(D.shape[2]-.5-z)**2\n",
    "\n",
    "voi_df = drm.get_voi_dfs()[0]\n",
    "Z = np.concatenate([orig_data_dict[cls][1] for cls in C.classes_to_include], 0)\n",
    "\n",
    "all_dense = np.empty([0,100])\n",
    "all_conv3 = np.empty([0,128*4])\n",
    "\n",
    "aug_factor = 10\n",
    "for img_id in range(len(Z)):\n",
    "    voi_row = voi_df.loc[Z[img_id]]\n",
    "    for aug_id in range(aug_factor):\n",
    "        img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "        \n",
    "        activ = model_pre_act.predict(np.expand_dims(img, 0))\n",
    "        all_dense = np.concatenate([all_dense, activ], axis=0)\n",
    "        \n",
    "        activ = model_conv3.predict(np.expand_dims(img, 0))\n",
    "        all_conv3 = np.concatenate([all_conv3, get_shells(activ, D)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_shells(activ, D):\n",
    "    shell4 = activ[0, D > 85, :].mean(axis=0)\n",
    "    shell3 = activ[0, (D <= 85) & (D > 62), :].mean(axis=0)\n",
    "    shell2 = activ[0, (D <= 62) & (D > 39), :].mean(axis=0)\n",
    "    shell1 = activ[0, D <= 39, :].mean(axis=0)\n",
    "    return np.expand_dims(np.concatenate([shell1, shell2, shell3, shell4]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_neurons = all_dense.shape[1] + all_conv3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dense = {f:np.empty([0,100]) for f in all_features}\n",
    "feature_conv3 = {f:np.empty([0,128*4]) for f in all_features}\n",
    "\n",
    "aug_factor = 80\n",
    "for f in all_features:\n",
    "    Z = Z_features[f]\n",
    "    for img_id in range(len(Z)):\n",
    "        voi_row = voi_df.loc[Z[img_id]]\n",
    "        for aug_id in range(aug_factor):\n",
    "            img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "            activ = model_pre_act.predict(np.expand_dims(img, 0))\n",
    "            feature_dense[f] = np.concatenate([feature_dense[f], activ], axis=0)\n",
    "        \n",
    "            activ = model_conv3.predict(np.expand_dims(img, 0))\n",
    "            feature_conv3[f] = np.concatenate([feature_conv3[f], get_shells(activ, D)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(all_features) # number of features\n",
    "num_units = 100 # number of dense units\n",
    "\n",
    "num_annotations = 8\n",
    "\n",
    "indices_f = [orig_data_dict[cls][1] for cls in C.classes_to_include]\n",
    "indices_f = hf.flatten(indices_f)\n",
    "\n",
    "test_indices = np.where(np.isin(indices_f, Z_test))[0]\n",
    "\n",
    "fixed_indices = np.empty([num_features, num_annotations])\n",
    "for f_ix,f in enumerate(all_features):\n",
    "    fixed_indices[f_ix, :] = np.where(np.isin(indices_f, random.sample(set(Z_features[f]), num_annotations)))[0]\n",
    "fixed_indices = fixed_indices.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KL = np.zeros((num_features, num_units)) # information provided by a feature about the possible values of a neuron\n",
    "m = all_pre_act.mean(axis=0)\n",
    "s = all_pre_act.std(axis=0)\n",
    "for f_ix in range(num_features):\n",
    "    F = feature_pre_act[all_features[f_ix]]\n",
    "    KL[f_ix, :] = kl_div(m,s, F.mean(axis=0),F.std(axis=0), one_sided=\"less\")\n",
    "    #KL[f_ix, :] = ttest_ind(F, all_pre_act, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test))] for cls in C.classes_to_include}\n",
    "X = np.concatenate([x_test[cls] for cls in C.classes_to_include], 0)\n",
    "Z = np.concatenate([Z_test[cls] for cls in C.classes_to_include], 0)\n",
    "#filters_test = np.empty([0,100])\n",
    "#for cls in C.classes_to_include:\n",
    "#    if x_test[cls].size > 0:\n",
    "#        filters_test = np.concatenate([filters_test, model_dense_outputs.predict(x_test[cls], verbose=False)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre_act = np.empty([0,100])\n",
    "test_activ = np.empty([0,100])\n",
    "\n",
    "p_f = np.empty(num_features)\n",
    "img_id = 14\n",
    "voi_row = voi_df.loc[Z[img_id]]\n",
    "cls = voi_row['cls']\n",
    "aug_factor = 100\n",
    "for aug_id in range(aug_factor):\n",
    "    img = np.load(os.path.join(C.aug_dir, cls, \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "    activ = model_pre_act.predict(np.expand_dims(img, 0))\n",
    "    test_pre_act = np.concatenate([test_pre_act, activ], axis=0)\n",
    "    activ = model_dense_outputs.predict(np.expand_dims(img, 0))\n",
    "    test_activ = np.concatenate([test_activ, activ], axis=0)\n",
    "\n",
    "m = all_pre_act.mean(axis=0)\n",
    "s = all_pre_act.std(axis=0)\n",
    "m_test = test_pre_act.mean(axis=0)\n",
    "s_test = test_pre_act.std(axis=0)\n",
    "\n",
    "c_ix = C.classes_to_include.index(cls)\n",
    "w_u = np.empty((num_features, num_units))\n",
    "p_fu = np.empty((num_features, num_units))\n",
    "\n",
    "for f_ix in range(num_features):\n",
    "    F = feature_pre_act[all_features[f_ix]]\n",
    "    w_u[f_ix] = np.exp(KL[f_ix, :]) #+ W_eff[:, c_ix])\n",
    "    p_fu[f_ix] = np.exp(-kl_div(m_test, s_test, F.mean(axis=0),F.std(axis=0), one_sided=\"less\"))\n",
    "    #p_f[f_ix] = np.sum(w_u * p_fu) / np.sum(w_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for u_ix in range(num_units):\n",
    "    w_u[:, u_ix] = np.where(w_u[:, u_ix] * p_fu[:, u_ix] >= np.median(w_u[:, u_ix] * p_fu[:, u_ix]),\n",
    "                            w_u[:, u_ix], np.zeros(num_features))\n",
    "    \n",
    "for f_ix in range(num_features):\n",
    "    p_f[f_ix] = np.sum(w_u[f_ix] * p_fu[f_ix]) / np.sum(w_u[f_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cholangio\n",
      "lobulated margins 0.991\n",
      "infiltrative 0.979\n",
      "hypointense without enhancement 0.951\n",
      "continuous enhancing rim 0.916\n",
      "regular spherical hypointense mass 0.909\n",
      "heterogeneous 0.898\n",
      "thin well-defined walls 0.869\n",
      "progressive or concentric enhancement 0.858\n",
      "arterial enhancement 0.815\n",
      "delayed isointensity 0.791\n",
      "nodular or discontinuous enhancement 0.719\n",
      "hyperintense mass on delayed phase 0.601\n",
      "progressive centripetal filling 0.586\n",
      "venous washout 0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dbfe8aeeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cls)\n",
    "for f,strength in sorted(enumerate(p_f), key=lambda x:x[1], reverse=True):\n",
    "    #if strength<0.2:\n",
    "    #    break\n",
    "    print(\"%s %.3f\" % (all_features[f], strength))\n",
    "\n",
    "x_test_quick = X[img_id]#orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == indices_f[test_ix])]\n",
    "hf.draw_slices(x_test_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E100962970_0\n",
      "E103312835_1\n",
      "E101083458_1\n",
      "E100183257_1\n",
      "E105311123_0\n",
      "E104697262_0\n",
      "12961059_0\n",
      "12324408_0\n",
      "12975280_0\n",
      "12888679_2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(os.path.join(C.base_dir, \"data\", \"annotated_features.xlsx\"), 5)\n",
    "\n",
    "for accnum, row in df.iterrows():\n",
    "    df = df.drop(accnum)\n",
    "    accnum = prv.decode(accnum[:accnum.find('_')]) + accnum[accnum.find('_'):accnum.find(' ')]\n",
    "    df.loc[accnum] = row\n",
    "\n",
    "print('\\n'.join([x for x in df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "\n",
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f_ix in range(num_features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements\n",
    "- feature_vectors * unit_relevance should be maximized\n",
    "\n",
    "- np.dot(feature_vectors[i], feature_vectors[j]) should be minimized, OR\n",
    "- vec_distance(feature_vectors[i], feature_vectors[j]) should be maximized for all pairs i,j\n",
    "\n",
    "- features \"turn on / off\" specific units; try to minimize the number of units impacted by a given feature\n",
    "\n",
    "- p(z|x) > .75 for all x manually annotated by z\n",
    "\n",
    "===\n",
    "- show % of evidence explained (fraction of sum of contributing units that are captured by features that turn those units on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = model.layers[-3].get_weights()[0]\n",
    "bias = model.layers[-3].get_weights()[1]\n",
    "\n",
    "#np.dot(filter_results[0], W) * eff_mult + eff_bias\n",
    "\n",
    "gamma, beta, mu, var = model.layers[-2].get_weights()\n",
    "\n",
    "eff_bias = (np.zeros(6) + bias - mu) / var**.5 * gamma + beta\n",
    "eff_mult = (np.ones(6) + bias - mu) / var**.5 * gamma + beta - eff_bias\n",
    "\n",
    "W_eff = W * eff_mult# + eff_bias\n",
    "\n",
    "#(np.dot(filter_results[0], W) + bias - mu) / var**.5 * gamma + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_relevance = np.empty(num_units)\n",
    "discr_power = np.empty((num_units, 6))\n",
    "for u_ix in range(num_units):\n",
    "    unit_relevance[u_ix] = np.amax(W_eff[u_ix]) - np.amin(W_eff[u_ix])\n",
    "    for c_ix in range(6):\n",
    "        if W_eff[u_ix, c_ix] == np.amax(W_eff[u_ix]):\n",
    "            discr_power[u_ix, c_ix] = W_eff[u_ix, c_ix] - sorted(W_eff[u_ix],reverse=True)[1]\n",
    "        else:\n",
    "            discr_power[u_ix, c_ix] = W_eff[u_ix, c_ix] - np.amax(W_eff[u_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_results = filter_results*unit_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_length = np.mean(np.apply_along_axis(get_length, 1, filter_results*unit_relevance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6239091267665856"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(squash(filter_results[2] * unit_relevance * 2/avg_length)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = cnna.get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))\n",
    "\n",
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[cls])):\n",
    "        z = Z_test[cls][img_num]\n",
    "        x = np.expand_dims(x_test[cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        \n",
    "        output[z] = [cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        #for f in all_features:\n",
    "        #    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[cls][img_num])\n",
    "        \n",
    "        for i in range(len(all_features)):\n",
    "            evidence[all_features[i] + \"/\" + str(cls_features[all_features[i]])] = features_test[cls][i, img_num]\n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, strength]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred5.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][3], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:\\\\filters_pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "agree = 0\n",
    "for _,row in df.iterrows():\n",
    "    if row[\"pred_cls1\"] in row[\"feature_1\"]:\n",
    "        agree += 1\n",
    "print(agree/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
