{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import cnn_runner as crun\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.transforms as tr\n",
    "import importlib\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(crun)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()\n",
    "#T.steps_per_epoch = 50\n",
    "#T.epochs= 1\n",
    "#T.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crun.run_fixed_hyperparams([C], hyperparams=T)#C_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = cbuild.build_cnn_hyperparams(T)\n",
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_reader = ['E103312835_1','12823036_0','12569915_0','E102093118_0','E102782525_0','12799652_0','E100894274_0','12874178_3','E100314676_0','12842070_0','13092836_2','12239783_0','12783467_0','13092966_0','E100962970_0','E100183257_1','E102634440_0','E106182827_0','12582632_0','E100121654_0','E100407633_0','E105310461_0','12788616_0','E101225606_0','12678910_1','E101083458_1','12324408_0','13031955_0','E101415263_0','E103192914_0','12888679_2','E106096969_0','E100192709_1','13112385_1','E100718398_0','12207268_0','E105244287_0','E102095465_0','E102613189_0','12961059_0','11907521_0','E105311123_0','12552705_0','E100610622_0','12975280_0','E105918926_0','E103020139_1','E101069048_1','E105427046_0','13028374_0','E100262351_0','12302576_0','12451831_0','E102929168_0','E100383453_0','E105344747_0','12569826_0','E100168661_0','12530153_0','E104697262_0']\n",
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0)#, Z_test_fixed=Z_reader)\n",
    "Z_test, Z_train_orig = Z\n",
    "X_train_orig, Y_train_orig = train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils import multi_gpu_model\n",
    "#model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator, steps_per_epoch=T.steps_per_epoch, epochs=T.epochs, validation_data=[X_test, Y_test])#, callbacks=[T.early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('E:\\\\models\\\\model_reader_rcnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df_art, voi_df_ven, voi_df_eq = drm.get_voi_dfs()\n",
    "small_voi_df = pd.read_csv(C.small_voi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_with_bbox(fn_list[2], cls_mapping[wrong_guesses[2]])\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#save_output(Z_test, y_pred, y_true)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "#y_true_simp, y_pred_simp, _ = cnna.merge_classes(y_true, y_pred)\n",
    "#print(accuracy_score(y_true_simp, y_pred_simp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_frozen = cbuild.build_frozen_model(model, last_layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test=Z_reader)\n",
    "Z_test, Z_train_orig = Z\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = [C.classes_to_include[y] for y in y_pred]\n",
    "Y_true = [C.classes_to_include[y] for y in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame([Z_test,Y_pred,Y_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.to_csv('E:\\\\temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc6cls = []\n",
    "acc3cls = []\n",
    "\n",
    "for i in range(19):\n",
    "    model_num = 306+i\n",
    "    X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test=df[df['model_num'] == model_num][\"z_test\"])\n",
    "    X_train_orig, Y_train_orig = train_orig\n",
    "    model = keras.models.load_model(os.path.join(C.model_dir, \"models_%d.hdf5\" % model_num)) #models_305\n",
    "    \n",
    "    Y_pred = model.predict(X_train_orig)\n",
    "    y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "    y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "    acc6cls.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)\n",
    "\n",
    "    acc3cls.append(accuracy_score(y_true_simp, y_pred_simp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Z:\\\\Inter-reader study\\\\Answer key.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df[\"Class\"].values\n",
    "y_pred = df[\"Model\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=C.classes_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(cm)):\n",
    "    print('\\t'.join(cm[:,i].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_list = fn_list + list(Z_test[~np.equal(y_pred, y_true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_list = fn_list + list(Z_train_orig[~np.equal(y_pred, y_true)])\n",
    "fn_list = fn_list + list(Z_train_orig[~np.equal(y_pred, y_true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_x_list = [x+\"(\"+str(voi_df_art[voi_df_art[\"id\"] == x[:-4]][\"x1\"].values[0])+\")\" for x in fn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(fn_x_list, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_train_orig)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#cbuild.save_output(Z_train_orig, y_pred, y_true)#, save_dir=C.output_img_dir+\"\\\\training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_analyzer' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_analyzer.py'>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model_frozen.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_img = orig_data_dict['hcc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_ixs = list(range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer(model_frozen, 'conv3d_11', \"D:\\\\filters\", channel_ixs)#, init_img=init_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_trunc = cbuild.build_pretrain_model(model, last_layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "fig = cnna.tsne(filters_by_cls)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.flatten([list(feature_sheet[\"evidence1\"+cls].dropna().values) for cls in C.classes_to_include]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv1 = cbuild.build_pretrain_model(model, last_layer=-6, add_activ=True)\n",
    "model_conv2 = cbuild.build_pretrain_model(model, last_layer=-5, add_activ=True)\n",
    "model_conv3 = cbuild.build_pretrain_model(model, last_layer=-4, add_activ=True)\n",
    "model_dense = cbuild.build_pretrain_model(model, last_layer=-3, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = 'cyst'\n",
    "cls_img_set = orig_data_dict[cls][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_activ_set = model_conv3.predict(cls_img_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(4)\n",
    "cls_activ_set_xform = nmf.fit_transform(cls_activ_set.mean((1,2,3)))\n",
    "\n",
    "nmf_comps = [nmf.components_[i] * (nmf.components_[i] > np.median(nmf.components_,0)*2) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_analyzer' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_analyzer.py'>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer_weighted(model_frozen, 'conv3d_11', \"D:\\\\filters\", K.constant(nmf_comps[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activs0 = cls_activ_set[:,:,:,:,nmf_comps[1] > 0]\n",
    "activ_map0 = activs0.mean(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activ_map0, _ = tr.rescale_img(np.transpose(activ_map0, (1,2,3,0)), cls_img_set[img_id].shape[:3])\n",
    "activ_map0 = np.transpose(activ_map0, (3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noxkCAACp0QwBAIDU/hcIDu1BotqjagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177a007b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 1\n",
    "alpha = 1.\n",
    "overlaid_img = cls_img_set[img_id] - np.amin(cls_img_set[img_id])\n",
    "overlaid_img = np.stack([((activ_map0[img_id] > np.mean(activ_map0[img_id])*alpha)+.5) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "hf.draw_slices(overlaid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf.draw_slices(cls_img_set[img_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div(m1, sig1, m2, sig2, one_sided=\"none\"):\n",
    "    #returns kl(p,q) where p~N(m1,s1), q~N(m2,s2)\n",
    "    ret = np.log(sig2/sig1) + (sig1**2+(m1-m2)**2)/(2*sig2**2) - .5\n",
    "    if one_sided==\"less\":\n",
    "        return ret * (m1 < m2)\n",
    "    elif one_sided==\"greater\":\n",
    "        return ret * (m1 > m2)\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv1_pre = cbuild.build_pretrain_model(model, last_layer=-6)#, add_activ=True)\n",
    "model_conv2_pre = cbuild.build_pretrain_model(model, last_layer=-5)#, add_activ=True)\n",
    "model_conv3_pre = cbuild.build_pretrain_model(model, last_layer=-4)#, add_activ=True)\n",
    "model_dense_pre = cbuild.build_pretrain_model(model, last_layer=-3)#, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12572068_0', '13092836_1', 'E103354630_0', 'E105921537_0', 'E106010098_0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df = drm.get_voi_dfs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.concatenate([orig_data_dict[cls][1] for cls in C.classes_to_include], 0)\n",
    "\n",
    "all_conv3_ch = np.empty([0,128])\n",
    "\n",
    "aug_factor = 10\n",
    "for img_id in range(len(Z)):\n",
    "    voi_row = voi_df.loc[Z[img_id]]\n",
    "    for aug_id in range(aug_factor):\n",
    "        img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "        activ = model_conv3.predict(np.expand_dims(img, 0))\n",
    "        all_conv3_ch = np.concatenate([all_conv3_ch, activ.mean(axis=(1,2,3))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = all_conv3_ch.mean(0)\n",
    "s = all_conv3_ch.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.empty((8,8,4))\n",
    "for x in range(D.shape[0]):\n",
    "    for y in range(D.shape[1]):\n",
    "        for z in range(D.shape[2]):\n",
    "            D[x,y,z] = (D.shape[0]-.5-x)**2 + (D.shape[1]-.5-y)**2 + 4*(D.shape[2]-.5-z)**2\n",
    "\n",
    "def get_shells(activ, D):\n",
    "    shell4 = activ[0, D > 85, :].mean(axis=0)\n",
    "    shell3 = activ[0, (D <= 85) & (D > 62), :].mean(axis=0)\n",
    "    shell2 = activ[0, (D <= 62) & (D > 39), :].mean(axis=0)\n",
    "    shell1 = activ[0, D <= 39, :].mean(axis=0)\n",
    "    return np.expand_dims(np.stack([shell1, shell2, shell3, shell4], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conv3_ch = {f:np.empty([0,8,8,4,128]) for f in all_features}\n",
    "#feature_conv3_sh = {f:np.empty([0,4,128]) for f in all_features}\n",
    "aug_factor = 80\n",
    "for f_ix in relevant_features:\n",
    "    f = all_features[f_ix]\n",
    "    Z_f = Z_features[f]\n",
    "    for img_id in range(len(Z_f)):\n",
    "        voi_row = voi_df.loc[Z_f[img_id]]\n",
    "        for aug_id in range(aug_factor):\n",
    "            img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z_f[img_id], aug_id)))\n",
    "            activ = model_conv3_pre.predict(np.expand_dims(img, 0))\n",
    "            feature_conv3_ch[f] = np.concatenate([feature_conv3_ch[f], activ], axis=0)\n",
    "            #feature_conv3_sh[f] = np.concatenate([feature_conv3_sh[f], get_shells(activ, D)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3_ch_plus = copy.deepcopy(feature_conv3_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv3_ch_plus[f][conv3_ch_plus[f] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_sh_plus = {}\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv3_ch_plus[f] = conv3_ch_plus[f].mean(0)\n",
    "    activ = conv3_ch_plus[f]\n",
    "    shell4 = activ[D > 85, :].mean(0)\n",
    "    shell3 = activ[(D <= 85) & (D > 62), :].mean(0)\n",
    "    shell2 = activ[(D <= 62) & (D > 39), :].mean(0)\n",
    "    shell1 = activ[D <= 39, :].mean(0)\n",
    "    conv3_sh_plus[f] = np.stack([shell1, shell2, shell3, shell4], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_avgs = np.zeros((4,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_ch_plus[f].mean((0,1,2))\n",
    "    \n",
    "channel_separations = np.empty((4,128)) # separation between channel mean activations for the 4 features\n",
    "for i in range(4):\n",
    "    channel_separations[i] = (np.amax(feature_avgs, 0) - feature_avgs[i]) / np.mean(feature_avgs, 0)\n",
    "\n",
    "channel_separations *= 10\n",
    "\n",
    "W = np.zeros((4,128))\n",
    "for ch_ix in range(128):\n",
    "    f_ix = list(channel_separations[:,ch_ix]).index(0)\n",
    "    W[f_ix,ch_ix] = channel_separations[:,ch_ix].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_avgs = np.zeros((4,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_sh_plus[f].mean(0).max(0)\n",
    "    \n",
    "channel_separations = np.empty((4,128))\n",
    "for i in range(4):\n",
    "    channel_separations[i] = np.amax(feature_avgs, 0) - feature_avgs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'regular spherical hypointense mass'), (1, 'thin well-defined walls'), (2, 'heterogeneous'), (3, 'venous washout'), (4, 'lobulated margins'), (5, 'progressive centripetal filling'), (6, 'infiltrative'), (7, 'progressive or concentric enhancement'), (8, 'hyperintense mass on delayed phase'), (9, 'arterial enhancement'), (10, 'delayed isointensity'), (11, 'continuous enhancing rim'), (12, 'hypointense without enhancement'), (13, 'nodular or discontinuous enhancement')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(range(len(all_features)), all_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_spatial_overlap(ch_weights, f_c3_ch, z):\n",
    "    relevant_features = ch_weights.keys()\n",
    "    \n",
    "    ch_weights2 = np.zeros(128)\n",
    "    \n",
    "    #f_c3_ch\n",
    "    \n",
    "    for ch in range(128):\n",
    "        f_c3_ch[:,:,:,:,ch] = (f_c3_ch[:,:,:,:,ch] - np.mean(f_c3_ch[:,:,:,:,ch]))# / np.std(f_c3_ch[:,:,:,:,ch])\n",
    "        \n",
    "        if ch_weights[ch] > 0:\n",
    "            w = np.zeros(f_c3_ch.shape[:4])\n",
    "            for i in range(128):\n",
    "                if ch_weights[i] > 0:\n",
    "                    w += ch_weights[i] * f_c3_ch[:,:,:,:,i]\n",
    "            w = w / np.sum(ch_weights)\n",
    "            ch_weights2[ch] = np.sum(f_c3_ch[:,:,:,:,ch] * w)\n",
    "            \n",
    "    return ch_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls = 'hcc'\n",
    "cls_img_set = orig_data_dict[cls][0]\n",
    "cls_activ_set = model_conv3_pre.predict(cls_img_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "x = cls_img_set[img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_neuron_ixs = np.where(h_ic_rot[0] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_active_neurons = active_neuron_ixs[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.ones((128, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = h_ic[h_ic > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1653.50039123, 1653.50039123, 1653.50039123, 1653.50039123])"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ixs = np.where(active_neuron_ixs[3] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = orig_data_dict[cls][0][img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_orientations = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ic = [model_conv3_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "#h_ic_plus = model_conv3.predict(cls_img_set)[img_id]\n",
    "#h_ic = model_conv3_pre.predict(np.expand_dims(x,0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ic_plus = copy.deepcopy(h_ic)\n",
    "for r in range(4):\n",
    "    h_ic_plus[r][h_ic_plus[r] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ic_rot = [np.rot90(h_ic_plus[r], 4-r) for r in range(4)] #rotated back into original frame\n",
    "#h_ic_rot = [np.rot90(h_ic[0], r) for r in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = [h_ic_rot[a][active_neuron_ixs] for a in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15892.943506453186"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(3*np.matmul(H[0], W) - np.matmul(H[1], W) - np.matmul(H[2], W) - np.matmul(H[3], W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_ca = {f_ix: feature_conv3_ch[all_features[f_ix]].mean((0,1,2,3)) for f_ix in relevant_features}\n",
    "h_ca_plus = {f_ix: feature_conv3_ch[all_features[f_ix]][feature_conv3_ch[all_features[f_ix]] > 0].mean((0,1,2,3)) for f_ix in relevant_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.tile(h_ca[f_ix], list(h_ic.shape[:3])+[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f_ix in relevant_features:\n",
    "    w_ica[f_ix] = h_ic_plus / (np.abs(h_ic_plus - h_ca[f_ix]) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218f9fadac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf.draw_slices(cls_img_set[img_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch_weights = {}\n",
    "relevant_features = [2,3,9,11]\n",
    "\n",
    "for f_ix in relevant_features:\n",
    "    img_dir = \"D:\\\\feature_analysis\\\\\"+all_features[f_ix]\n",
    "    if not exists(img_dir):\n",
    "        os.makedirs(img_dir)\n",
    "        \n",
    "    f_c3_ch = feature_conv3_ch[all_features[f_ix]]\n",
    "    avg_f_conv3_ch = f_c3_ch.mean((1,2,3))\n",
    "    f_m = avg_f_conv3_ch.mean(0)\n",
    "    f_s = avg_f_conv3_ch.std(0)\n",
    "\n",
    "    ch_weights[all_features[f_ix]] = np.log(kl_div(m, s, f_m, f_s, 'less')+1) #kl_div(m, s, f_m, f_s, 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "z = orig_data_dict[cls][1][img_id]\n",
    "\n",
    "ch_weights2 = get_spatial_overlap(ch_weights, feature_conv3_ch, z)\n",
    "ch_weights2[ch_weights2 < np.median(ch_weights2) / 2] = 0 #np.median(ch_weights2) / 2\n",
    "ch_weights[all_features[f_ix]] *= ch_weights2\n",
    "ch_weights[all_features[f_ix]] /= np.mean(ch_weights[all_features[f_ix]])\n",
    "\n",
    "for f_ix in relevant_features:\n",
    "    #activs0 = cls_activ_set[:,:,:,:, ch_weights > 0]\n",
    "    #activ_map0 = activs0.mean(4)\n",
    "    w = np.zeros(cls_activ_set.shape[:4])\n",
    "    for i in range(128):\n",
    "        if ch_weights[i] > 0:\n",
    "            w += ch_weights[i] * cls_activ_set[:,:,:,:,i]\n",
    "    activ_map0 = w / np.sum(ch_weights)\n",
    "    activ_map0, _ = tr.rescale_img(np.transpose(activ_map0, (1,2,3,0)), cls_img_set[img_id].shape[:3])\n",
    "    activ_map0 = np.transpose(activ_map0, (3,0,1,2))\n",
    "\n",
    "    #for img_id in range(len(cls_img_set)):\n",
    "    alpha = 1.3\n",
    "    overlaid_img = cls_img_set[img_id] - np.amin(cls_img_set[img_id])\n",
    "    overlaid_img = np.stack([((activ_map0[img_id] > np.median(activ_map0[img_id])*alpha)+.3) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "    hf.draw_slices(overlaid_img[:,::-1,:], save_path=img_dir+\"\\\\\"+z+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cbuild)\n",
    "C=config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305\n",
    "model_dense_outputs = cbuild.build_pretrain_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 24, 12, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([orig_data_dict['cyst'][0][0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "filter_results = np.concatenate([filters_by_cls[cls] for cls in C.classes_to_include], axis=0)\n",
    "\n",
    "filter_avgs = np.mean(filter_results, axis=0)\n",
    "filter_stds = np.std(filter_results, axis=0)\n",
    "\n",
    "#filter_cls_avg_unscaled = {cls: np.mean(filter_results[cls], axis=0) for cls in C.classes_to_include}\n",
    "#filter_cls_avg_scaled = {cls: np.mean(filter_results[cls], axis=0) / filter_avgs for cls in C.classes_to_include}\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = dict(zip(*np.unique(features_by_cls['colorectal'], return_counts=True)))\n",
    "for k in z:\n",
    "    print(k, \" (\",z[k],\")\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash_per_dim(vector, eps = 10**-10):\n",
    "    for i,x in enumerate(vector):\n",
    "        vector[i] *= x / (1 + x**2)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = model.layers[-3].get_weights()[0]\n",
    "bias = model.layers[-3].get_weights()[1]\n",
    "\n",
    "gamma, beta, mu, var = model.layers[-2].get_weights()\n",
    "\n",
    "eff_bias = (np.zeros(6) + bias - mu) / var**.5 * gamma + beta\n",
    "eff_mult = (np.ones(6) + bias - mu) / var**.5 * gamma + beta - eff_bias\n",
    "\n",
    "W_eff = W * eff_mult# + eff_bias\n",
    "\n",
    "unit_relevance = np.empty(num_units)\n",
    "for u_ix in range(num_units):\n",
    "    unit_relevance[u_ix] = np.amax(W_eff[u_ix]) - np.amin(W_eff[u_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_filter_results = np.apply_along_axis(lambda X: squash_per_dim(X), 0, filter_results / (2*filter_avgs) * unit_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")\n",
    "\n",
    "feature_filter_means = {}\n",
    "feature_filter_stds = {}\n",
    "feature_filters_scaled = {}#{cls: {} for cls in features}\n",
    "feature_filters = {f:np.empty([0,100]) for f in all_features}\n",
    "\n",
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs\n",
    "        \n",
    "    feature_filters[f] = (feature_filters[f] - filter_avgs) / filter_stds\n",
    "    \n",
    "    feature_filter_means[f] = np.mean(feature_filters[f], axis=0)\n",
    "    feature_filter_stds[f] = np.std(feature_filters[f], axis=0)\n",
    "\n",
    "    feature_filters_scaled[f] = feature_filter_means[f] / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(all_features) # number of features\n",
    "num_units = 100 # number of dense units\n",
    "\n",
    "num_annotations = 8\n",
    "Z_test = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "indices_f = [orig_data_dict[cls][1] for cls in C.classes_to_include]\n",
    "indices_f = hf.flatten(indices_f)\n",
    "\n",
    "fixed_indices = np.empty([num_features, num_annotations])\n",
    "for f_ix,f in enumerate(all_features):\n",
    "    fixed_indices[f_ix, :] = np.where(np.isin(indices_f, random.sample(set(Z_features[f]), num_annotations)))[0]\n",
    "fixed_indices = fixed_indices.astype(int)\n",
    "\n",
    "test_indices = np.where(np.isin(indices_f, Z_test))[0]\n",
    "\n",
    "z_states = np.array([z for z in itertools.product([0,1], repeat=num_features) if sum(z) <= 4 and sum(z) >= 2])\n",
    "num_states = len(z_states)\n",
    "num_imgs = filter_results.shape[0]\n",
    "z_states_bool = [tuple([bool(x) for x in z]) for z in z_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_theta(k, alpha=.5, beta=.5, **kwargs):\n",
    "    if len(kwargs) == 0:\n",
    "        mu = np.empty([num_features, num_units])\n",
    "        sigma = np.empty([num_features, num_units])\n",
    "        for i in range(num_features):\n",
    "            mu[i] = feature_filter_means[all_features[i]]\n",
    "            sigma[i] = feature_filter_stds[all_features[i]]\n",
    "        sigma[sigma > 1] = 1\n",
    "        m = filter_avgs\n",
    "        s = filter_stds\n",
    "\n",
    "        theta_i = scipy.random.normal(size=num_features)\n",
    "        theta_ij = scipy.random.normal(size=[num_features-1, num_features])\n",
    "    else:\n",
    "        mu = kwargs['mu']\n",
    "        sigma = kwargs['sigma']\n",
    "        m = kwargs['m']\n",
    "        s = kwargs['s']\n",
    "        theta_i = kwargs['theta_i']\n",
    "        theta_ij = kwargs['theta_ij']\n",
    "    \n",
    "    print(\"Initializing probabilities...\")\n",
    "    p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "    p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "    p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "    \n",
    "    print(\"Running EM:\")\n",
    "    for jj in range(k):\n",
    "        print(\"   Iteration\", jj, end=\"...Update thetas...\")\n",
    "        theta_i, theta_ij = im.update_thetas(np.sum(p_z_x, axis=0), z_states_bool, theta_i, theta_ij, alpha)\n",
    "\n",
    "        p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "        p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "\n",
    "        print(\"Update means and stdevs...\", end=\"\")\n",
    "        mu_est = im.update_mus(mu, m, sigma, s, z_states, filter_results, p_z_x, fixed_indices, beta)\n",
    "        m_est = im.update_ms(mu, m, sigma, s, z_states, filter_results, p_z_x, beta)\n",
    "        sigma, s = im.update_stdevs_approx(mu, m, sigma, s, z_states, filter_results, p_z_x, beta)\n",
    "\n",
    "        if jj < k-1:\n",
    "            print(\"Update probabilities...\")\n",
    "            p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "            p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "            \n",
    "    return mu, m, sigma, s, theta_i, theta_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'mu': mu,\n",
    "'sigma': sigma,\n",
    "'m': m,\n",
    "'s': s,\n",
    "'theta_i': theta_i,\n",
    "'theta_ij': theta_ij}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'inference_methods' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\inference_methods.py'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing probabilities...\n",
      "Running EM:\n",
      "   Iteration 0...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 1...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 2...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 3...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 4...Update thetas...Update means and stdevs..."
     ]
    }
   ],
   "source": [
    "mu, m, sigma, s, theta_i, theta_ij = EM_theta(5, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importlib.reload(im)\n",
    "p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "p_z_x = im.get_all_p_z_x(p_x_z, p_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for _ in range(num_states*10):\n",
    "    np.nan_to_num(0)\n",
    "    #pass\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test_ix in test_indices[3:]:\n",
    "    p_zi_x = np.zeros([num_features])\n",
    "    for f_ix in range(num_features):\n",
    "        state_ixs = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "        p_zi_x[f_ix] = sum(p_z_x[test_ix, state_ixs])\n",
    "        #for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "        #    output[z] = output[z] + [f, strength]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arterial enhancement 82%\n",
      "thin well-defined walls 74%\n",
      "heterogeneous 62%\n",
      "continuous enhancing rim 56%\n"
     ]
    }
   ],
   "source": [
    "for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "    if strength<0.3:\n",
    "        break\n",
    "    print(\"%s %d%%\" % (all_features[f], strength*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACFCAYAAABsdIKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQxYRmQQdsojIJOiQRUQm4T+WenD2fSyHOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb084a6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cls in C.classes_to_include:\n",
    "    x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == indices_f[test_ix])]\n",
    "    if len(x_test_quick) > 0:\n",
    "        break\n",
    "hf.draw_slices(x_test_quick[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@njit\n",
    "def update_stdevs(mu, m, sigma, s, z_states, filter_results, p_z_x):\n",
    "    sigma_est = np.empty([num_features, num_units])\n",
    "    s_est = np.empty([num_units])\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "\n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in range(num_states):\n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - \\\n",
    "                       np.dot(mu[:, u_ix], z_states_bool[state_ix]) - m[u_ix])**2 for img_ix in range(num_imgs)]) / 2\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "\n",
    "        temp = scipy.optimize.minimize(\\\n",
    "                    lambda Var: sum([a_i[state_ix] / (sum(np.where(z_states_bool[state_ix],\n",
    "                       Var[:-1], 0))+Var[-1]) + c_i[state_ix] * log(sqrt(sum(np.where(z_states_bool[state_ix],\n",
    "                       Var[:-1], 0))+Var[-1]) * sqrt(2*pi)) for state_ix in range(num_states)]),\n",
    "                      np.concatenate([sigma[:, u_ix]**2, [s[u_ix]**2]]), \n",
    "                      bounds=tuple(itertools.repeat((.001, 1000),num_features+1)))\n",
    "\n",
    "        sigma_est[:, u_ix] = [sqrt(i) for i in temp['x'][:-1]]\n",
    "        s_est[u_ix] = sqrt(temp['x'][-1])\n",
    "    \n",
    "    return sigma_est, s_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "t=time.time()\n",
    "for f_ix in range(num_features):\n",
    "    state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    #p_z_x does not need to be rescaled because the factor cancels out\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "    \n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in state_indices:\n",
    "            z = z_states[state_ix]\n",
    "\n",
    "            mean = np.dot(mu[:, u_ix], z) + m[u_ix]\n",
    "            var_adj[state_ix] = sum(np.where(z==1, sigma[:, u_ix]**2, 0)) + s[u_ix]**2 - sigma[f_ix, u_ix]**2\n",
    "            \n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "        \n",
    "        sigma_est[f_ix, u_ix] = sqrt(scipy.optimize.fsolve(lambda x: sum([a_i[state_ix]/(x+var_adj[state_ix])**2 - \\\n",
    "                                         c_i[state_ix]/(x+var_adj[state_ix]) for state_ix in state_indices]), \\\n",
    "                                          sigma[f_ix, u_ix]))\n",
    "        \n",
    "        if u_ix % 20 == 0:\n",
    "            print(f_ix, u_ix, time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "#state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "#p_z_x does not need to be rescaled because the factor cancels out\n",
    "var_adj = np.zeros([num_states])\n",
    "a_i = np.zeros([num_states])\n",
    "c_i = np.zeros([num_states])\n",
    "\n",
    "for u_ix in range(num_units):\n",
    "    for state_ix in range(num_states):\n",
    "        mean = np.dot(mu[:, u_ix], z_states[state_ix]) + m[u_ix]\n",
    "        a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "        c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "\n",
    "    temp = scipy.optimize.linearmixing(\\\n",
    "                lambda Var: sum([a_i[state_ix]/(sum(np.where(z_states[state_ix]==1, Var[:-1]**2, 0))+Var[-1]**2)**2 - \\\n",
    "                 c_i[state_ix]/(sum(np.where(z_states[state_ix]==1, Var[:-1]**2, 0))+Var[-1]**2) for state_ix in range(num_states)]), \\\n",
    "                  np.concatenate([sigma[:, u_ix], [s[u_ix]]]), verbose=True, maxiter=10000)\n",
    "    \n",
    "    #sigma_est[:, u_ix]\n",
    "    if u_ix % 20 == 0:\n",
    "        print(u_ix, time.time()-t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for f_ix in range(num_features):\n",
    "    state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    #p_z_x does not need to be rescaled because the factor cancels out\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "    \n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in state_indices:\n",
    "            z = z_states[state_ix]\n",
    "\n",
    "            mean = np.dot(mu[:, u_ix], z) + m[u_ix]\n",
    "            var_adj[state_ix] = sum(np.where(z==1, sigma[:, u_ix]**2, 0)) + s[u_ix]**2 - sigma[f_ix, u_ix]**2\n",
    "            \n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "        \n",
    "        sigma_est[f_ix, u_ix] = sqrt(scipy.optimize.fsolve(lambda x: sum([(a_i[state_ix]/(x+var_adj[state_ix]) - \\\n",
    "                                         c_i[state_ix])/(x+var_adj[state_ix]) for state_ix in state_indices]), \\\n",
    "                                          sigma[f_ix, u_ix]))\n",
    "        \n",
    "        if u_ix % 20 == 0:\n",
    "            print(f_ix, u_ix, time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least squares approach\n",
    "Theta = np.array([feature_filter_means[f] for f in all_features])\n",
    "Theta = np.transpose(Theta, (1,0))\n",
    "\n",
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)\n",
    "    filters_test[cls] = (filters_test[cls] - filter_avgs) / filter_stds\n",
    "    features_test[cls] = np.linalg.lstsq(Theta, np.transpose(filters_test[cls], (1,0)))[0]\n",
    "    #filters_test[cls] = np.apply_along_axis(lambda x: x / filter_avgs, 1, filters_test[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covar_to_corr(covar):\n",
    "    A = np.diag(np.diag(covar)**(-0.5))\n",
    "    return np.matmul(np.matmul(A, covar), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = covar_to_corr(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(corr - np.linalg.pinv(np.diag(np.diag(np.linalg.pinv(corr)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cutoff_eigenval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=None,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = np.random.normal(size=filter_results.shape)\n",
    "dummy_fa = FactorAnalysis()\n",
    "dummy_fa.fit(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.linalg.eigvals(fa.get_covariance()) > np.mean(np.linalg.eigvals(dummy_fa.get_covariance())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.fit(filter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89081373261106078"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=3\n",
    "fa.get_covariance()[x,x] - fa.noise_variance_[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = cnna.get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))\n",
    "\n",
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[cls])):\n",
    "        z = Z_test[cls][img_num]\n",
    "        x = np.expand_dims(x_test[cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        \n",
    "        output[z] = [cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        #for f in all_features:\n",
    "        #    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[cls][img_num])\n",
    "        \n",
    "        for i in range(len(all_features)):\n",
    "            evidence[all_features[i] + \"/\" + str(cls_features[all_features[i]])] = features_test[cls][i, img_num]\n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, strength]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred5.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][3], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:\\\\filters_pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "agree = 0\n",
    "for _,row in df.iterrows():\n",
    "    if row[\"pred_cls1\"] in row[\"feature_1\"]:\n",
    "        agree += 1\n",
    "print(agree/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
