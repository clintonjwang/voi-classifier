{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "\n",
    "import argparse\n",
    "import capsulenet as cnet\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()\n",
    "T.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator, (x_test, y_test), _ = cbuild.load_data_capsnet()\n",
    "(x_train, y_train), _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('strings', metavar='STRING', nargs='*', help='String for searching')\n",
    "parser.add_argument('--epochs', default=25, type=int)\n",
    "parser.add_argument('--batch_size', default=2, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float,\n",
    "                    help=\"Initial learning rate\")\n",
    "parser.add_argument('--lr_decay', default=0.9, type=float,\n",
    "                    help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
    "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
    "                    help=\"The coefficient for the loss of decoder\")\n",
    "parser.add_argument('-r', '--routings', default=3, type=int,\n",
    "                    help=\"Number of iterations used in routing algorithm. should > 0\")\n",
    "#parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
    "#                    help=\"Fraction of pixels to shift at most in each direction.\")\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('-t', '--testing', action='store_true',\n",
    "                    help=\"Test the trained model on testing dataset\")\n",
    "parser.add_argument('--digit', default=5, type=int,\n",
    "                    help=\"Digit to manipulate\")\n",
    "parser.add_argument('-w', '--weights', default=None,\n",
    "                    help=\"The path of the saved weights. Should be specified when testing\")\n",
    "args = parser.parse_args('--epochs 25')# --lr 0.002 --lr_decay 0.87')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 24, 24, 12, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv3D)                  (None, 17, 17, 5, 25 393472      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 17, 17, 5, 25 1024        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 17, 17, 5, 25 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv3d (Conv3D)      (None, 7, 7, 1, 128) 4096128     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 784, 8)       0           primarycap_conv3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 784, 8)       0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 6, 8)         301056      primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_4 (Mask)                   (None, 48)           0           digitcaps[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 6)            0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 24, 24, 12, 3 5341696     mask_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,133,376\n",
      "Trainable params: 10,132,864\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cnet)\n",
    "\n",
    "model, eval_model, manipulate_model = cnet.CapsNet(input_shape=x_train.shape[1:],\n",
    "                                              n_class=len(np.unique(np.argmax(y_train, 1))),\n",
    "                                              routings=args.routings)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.7538 - capsnet_loss: 1.6852 - decoder_loss: 0.1750 - capsnet_acc: 0.1607\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.20000, saving model to ./result/weights-01.h5\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 1.7537 - capsnet_loss: 1.6852 - decoder_loss: 0.1749 - capsnet_acc: 0.1610 - val_loss: 1.7218 - val_capsnet_loss: 1.6575 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.2000\n",
      "Epoch 2/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.6616 - capsnet_loss: 1.6039 - decoder_loss: 0.1473 - capsnet_acc: 0.2207\n",
      "Epoch 00002: val_capsnet_acc improved from 0.20000 to 0.28333, saving model to ./result/weights-02.h5\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 1.6617 - capsnet_loss: 1.6039 - decoder_loss: 0.1473 - capsnet_acc: 0.2207 - val_loss: 1.6793 - val_capsnet_loss: 1.6143 - val_decoder_loss: 0.1657 - val_capsnet_acc: 0.2833\n",
      "Epoch 3/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.7163 - capsnet_loss: 1.6573 - decoder_loss: 0.1507 - capsnet_acc: 0.2356\n",
      "Epoch 00003: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 1.7160 - capsnet_loss: 1.6570 - decoder_loss: 0.1507 - capsnet_acc: 0.2355 - val_loss: 1.5588 - val_capsnet_loss: 1.4943 - val_decoder_loss: 0.1644 - val_capsnet_acc: 0.1667\n",
      "Epoch 4/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.5274 - capsnet_loss: 1.4672 - decoder_loss: 0.1536 - capsnet_acc: 0.2928\n",
      "Epoch 00004: val_capsnet_acc improved from 0.28333 to 0.35000, saving model to ./result/weights-04.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 1.5272 - capsnet_loss: 1.4670 - decoder_loss: 0.1536 - capsnet_acc: 0.2928 - val_loss: 1.4307 - val_capsnet_loss: 1.3661 - val_decoder_loss: 0.1649 - val_capsnet_acc: 0.3500\n",
      "Epoch 5/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3560 - capsnet_loss: 1.2926 - decoder_loss: 0.1617 - capsnet_acc: 0.4144\n",
      "Epoch 00005: val_capsnet_acc improved from 0.35000 to 0.55000, saving model to ./result/weights-05.h5\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 1.3559 - capsnet_loss: 1.2925 - decoder_loss: 0.1617 - capsnet_acc: 0.4145 - val_loss: 1.3775 - val_capsnet_loss: 1.3132 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.5500\n",
      "Epoch 6/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2262 - capsnet_loss: 1.1651 - decoder_loss: 0.1558 - capsnet_acc: 0.5325\n",
      "Epoch 00006: val_capsnet_acc improved from 0.55000 to 0.56667, saving model to ./result/weights-06.h5\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 1.2260 - capsnet_loss: 1.1650 - decoder_loss: 0.1558 - capsnet_acc: 0.5325 - val_loss: 1.1584 - val_capsnet_loss: 1.0936 - val_decoder_loss: 0.1652 - val_capsnet_acc: 0.5667\n",
      "Epoch 7/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.0303 - capsnet_loss: 0.9703 - decoder_loss: 0.1530 - capsnet_acc: 0.6400\n",
      "Epoch 00007: val_capsnet_acc improved from 0.56667 to 0.63333, saving model to ./result/weights-07.h5\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 1.0300 - capsnet_loss: 0.9701 - decoder_loss: 0.1530 - capsnet_acc: 0.6402 - val_loss: 0.9126 - val_capsnet_loss: 0.8484 - val_decoder_loss: 0.1638 - val_capsnet_acc: 0.6333\n",
      "Epoch 8/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.9491 - capsnet_loss: 0.8893 - decoder_loss: 0.1528 - capsnet_acc: 0.6823\n",
      "Epoch 00008: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.9488 - capsnet_loss: 0.8890 - decoder_loss: 0.1527 - capsnet_acc: 0.6825 - val_loss: 0.9517 - val_capsnet_loss: 0.8870 - val_decoder_loss: 0.1651 - val_capsnet_acc: 0.5667\n",
      "Epoch 9/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.8594 - capsnet_loss: 0.7980 - decoder_loss: 0.1565 - capsnet_acc: 0.7159\n",
      "Epoch 00009: val_capsnet_acc improved from 0.63333 to 0.68333, saving model to ./result/weights-09.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.8592 - capsnet_loss: 0.7978 - decoder_loss: 0.1566 - capsnet_acc: 0.7158 - val_loss: 0.9118 - val_capsnet_loss: 0.8474 - val_decoder_loss: 0.1644 - val_capsnet_acc: 0.6833\n",
      "Epoch 10/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.8379 - capsnet_loss: 0.7775 - decoder_loss: 0.1539 - capsnet_acc: 0.7284\n",
      "Epoch 00010: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.8384 - capsnet_loss: 0.7781 - decoder_loss: 0.1539 - capsnet_acc: 0.7280 - val_loss: 1.1071 - val_capsnet_loss: 1.0424 - val_decoder_loss: 0.1651 - val_capsnet_acc: 0.6667\n",
      "Epoch 11/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7854 - capsnet_loss: 0.7248 - decoder_loss: 0.1546 - capsnet_acc: 0.7497\n",
      "Epoch 00011: val_capsnet_acc improved from 0.68333 to 0.75000, saving model to ./result/weights-11.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.7856 - capsnet_loss: 0.7250 - decoder_loss: 0.1546 - capsnet_acc: 0.7497 - val_loss: 0.7871 - val_capsnet_loss: 0.7229 - val_decoder_loss: 0.1637 - val_capsnet_acc: 0.7500\n",
      "Epoch 12/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7061 - capsnet_loss: 0.6458 - decoder_loss: 0.1538 - capsnet_acc: 0.7733\n",
      "Epoch 00012: val_capsnet_acc improved from 0.75000 to 0.76667, saving model to ./result/weights-12.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.7060 - capsnet_loss: 0.6457 - decoder_loss: 0.1538 - capsnet_acc: 0.7735 - val_loss: 0.7645 - val_capsnet_loss: 0.7002 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7667\n",
      "Epoch 13/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6703 - capsnet_loss: 0.6122 - decoder_loss: 0.1482 - capsnet_acc: 0.7861\n",
      "Epoch 00013: val_capsnet_acc improved from 0.76667 to 0.78333, saving model to ./result/weights-13.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.6701 - capsnet_loss: 0.6120 - decoder_loss: 0.1482 - capsnet_acc: 0.7863 - val_loss: 0.7115 - val_capsnet_loss: 0.6471 - val_decoder_loss: 0.1643 - val_capsnet_acc: 0.7833\n",
      "Epoch 14/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6692 - capsnet_loss: 0.6113 - decoder_loss: 0.1478 - capsnet_acc: 0.7945\n",
      "Epoch 00014: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.6690 - capsnet_loss: 0.6111 - decoder_loss: 0.1478 - capsnet_acc: 0.7947 - val_loss: 0.8832 - val_capsnet_loss: 0.8189 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7000\n",
      "Epoch 15/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6245 - capsnet_loss: 0.5635 - decoder_loss: 0.1557 - capsnet_acc: 0.8073\n",
      "Epoch 00015: val_capsnet_acc improved from 0.78333 to 0.81667, saving model to ./result/weights-15.h5\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.6246 - capsnet_loss: 0.5636 - decoder_loss: 0.1557 - capsnet_acc: 0.8072 - val_loss: 0.6316 - val_capsnet_loss: 0.5671 - val_decoder_loss: 0.1644 - val_capsnet_acc: 0.8167\n",
      "Epoch 16/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5935 - capsnet_loss: 0.5333 - decoder_loss: 0.1535 - capsnet_acc: 0.8205\n",
      "Epoch 00016: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.5937 - capsnet_loss: 0.5335 - decoder_loss: 0.1535 - capsnet_acc: 0.8205 - val_loss: 0.6806 - val_capsnet_loss: 0.6163 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7833\n",
      "Epoch 17/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5661 - capsnet_loss: 0.5062 - decoder_loss: 0.1529 - capsnet_acc: 0.8273\n",
      "Epoch 00017: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.5670 - capsnet_loss: 0.5071 - decoder_loss: 0.1529 - capsnet_acc: 0.8272 - val_loss: 0.9462 - val_capsnet_loss: 0.8815 - val_decoder_loss: 0.1648 - val_capsnet_acc: 0.7667\n",
      "Epoch 18/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5938 - capsnet_loss: 0.5334 - decoder_loss: 0.1540 - capsnet_acc: 0.8160\n",
      "Epoch 00018: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.5936 - capsnet_loss: 0.5333 - decoder_loss: 0.1539 - capsnet_acc: 0.8162 - val_loss: 0.8292 - val_capsnet_loss: 0.7650 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5500 - capsnet_loss: 0.4906 - decoder_loss: 0.1514 - capsnet_acc: 0.8340\n",
      "Epoch 00019: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.5499 - capsnet_loss: 0.4906 - decoder_loss: 0.1514 - capsnet_acc: 0.8340 - val_loss: 0.7775 - val_capsnet_loss: 0.7131 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7333\n",
      "Epoch 20/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5096 - capsnet_loss: 0.4496 - decoder_loss: 0.1531 - capsnet_acc: 0.8510\n",
      "Epoch 00020: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.5094 - capsnet_loss: 0.4494 - decoder_loss: 0.1531 - capsnet_acc: 0.8512 - val_loss: 0.6543 - val_capsnet_loss: 0.5900 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7667\n",
      "Epoch 21/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4994 - capsnet_loss: 0.4410 - decoder_loss: 0.1488 - capsnet_acc: 0.8545\n",
      "Epoch 00021: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4998 - capsnet_loss: 0.4412 - decoder_loss: 0.1494 - capsnet_acc: 0.8543 - val_loss: 0.7879 - val_capsnet_loss: 0.7236 - val_decoder_loss: 0.1639 - val_capsnet_acc: 0.7000\n",
      "Epoch 22/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5021 - capsnet_loss: 0.4397 - decoder_loss: 0.1592 - capsnet_acc: 0.8522\n",
      "Epoch 00022: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.5018 - capsnet_loss: 0.4394 - decoder_loss: 0.1592 - capsnet_acc: 0.8523 - val_loss: 0.7365 - val_capsnet_loss: 0.6722 - val_decoder_loss: 0.1639 - val_capsnet_acc: 0.7333\n",
      "Epoch 23/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4753 - capsnet_loss: 0.4169 - decoder_loss: 0.1490 - capsnet_acc: 0.8645\n",
      "Epoch 00023: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4759 - capsnet_loss: 0.4175 - decoder_loss: 0.1490 - capsnet_acc: 0.8643 - val_loss: 0.6550 - val_capsnet_loss: 0.5907 - val_decoder_loss: 0.1639 - val_capsnet_acc: 0.8000\n",
      "Epoch 24/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4674 - capsnet_loss: 0.4083 - decoder_loss: 0.1510 - capsnet_acc: 0.8672\n",
      "Epoch 00024: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4672 - capsnet_loss: 0.4080 - decoder_loss: 0.1510 - capsnet_acc: 0.8673 - val_loss: 0.7985 - val_capsnet_loss: 0.7341 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7500\n",
      "Epoch 25/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4598 - capsnet_loss: 0.4012 - decoder_loss: 0.1494 - capsnet_acc: 0.8670\n",
      "Epoch 00025: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4598 - capsnet_loss: 0.4013 - decoder_loss: 0.1493 - capsnet_acc: 0.8670 - val_loss: 0.7076 - val_capsnet_loss: 0.6434 - val_decoder_loss: 0.1639 - val_capsnet_acc: 0.7167\n",
      "Epoch 26/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4447 - capsnet_loss: 0.3853 - decoder_loss: 0.1516 - capsnet_acc: 0.8734\n",
      "Epoch 00026: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4446 - capsnet_loss: 0.3852 - decoder_loss: 0.1516 - capsnet_acc: 0.8735 - val_loss: 0.7384 - val_capsnet_loss: 0.6740 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7667\n",
      "Epoch 27/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4403 - capsnet_loss: 0.3816 - decoder_loss: 0.1498 - capsnet_acc: 0.8739\n",
      "Epoch 00027: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4402 - capsnet_loss: 0.3814 - decoder_loss: 0.1498 - capsnet_acc: 0.8740 - val_loss: 0.6793 - val_capsnet_loss: 0.6149 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7833\n",
      "Epoch 28/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4266 - capsnet_loss: 0.3665 - decoder_loss: 0.1532 - capsnet_acc: 0.8820\n",
      "Epoch 00028: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4266 - capsnet_loss: 0.3664 - decoder_loss: 0.1536 - capsnet_acc: 0.8822 - val_loss: 0.6861 - val_capsnet_loss: 0.6218 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7667\n",
      "Epoch 29/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4162 - capsnet_loss: 0.3577 - decoder_loss: 0.1491 - capsnet_acc: 0.8899\n",
      "Epoch 00029: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4160 - capsnet_loss: 0.3576 - decoder_loss: 0.1492 - capsnet_acc: 0.8900 - val_loss: 0.7248 - val_capsnet_loss: 0.6604 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7667\n",
      "Epoch 30/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4096 - capsnet_loss: 0.3500 - decoder_loss: 0.1522 - capsnet_acc: 0.8882\n",
      "Epoch 00030: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.4095 - capsnet_loss: 0.3498 - decoder_loss: 0.1522 - capsnet_acc: 0.8883 - val_loss: 0.7161 - val_capsnet_loss: 0.6519 - val_decoder_loss: 0.1638 - val_capsnet_acc: 0.7333\n",
      "Epoch 31/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4032 - capsnet_loss: 0.3453 - decoder_loss: 0.1477 - capsnet_acc: 0.8931\n",
      "Epoch 00031: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4034 - capsnet_loss: 0.3455 - decoder_loss: 0.1477 - capsnet_acc: 0.8930 - val_loss: 0.7507 - val_capsnet_loss: 0.6864 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7500\n",
      "Epoch 32/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4008 - capsnet_loss: 0.3408 - decoder_loss: 0.1530 - capsnet_acc: 0.8941\n",
      "Epoch 00032: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4007 - capsnet_loss: 0.3407 - decoder_loss: 0.1530 - capsnet_acc: 0.8942 - val_loss: 0.7059 - val_capsnet_loss: 0.6416 - val_decoder_loss: 0.1639 - val_capsnet_acc: 0.7667\n",
      "Epoch 33/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4075 - capsnet_loss: 0.3464 - decoder_loss: 0.1560 - capsnet_acc: 0.8862\n",
      "Epoch 00033: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4077 - capsnet_loss: 0.3462 - decoder_loss: 0.1569 - capsnet_acc: 0.8863 - val_loss: 0.7723 - val_capsnet_loss: 0.7080 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7500\n",
      "Epoch 34/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3960 - capsnet_loss: 0.3369 - decoder_loss: 0.1507 - capsnet_acc: 0.8941\n",
      "Epoch 00034: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3960 - capsnet_loss: 0.3369 - decoder_loss: 0.1508 - capsnet_acc: 0.8938 - val_loss: 0.6649 - val_capsnet_loss: 0.6005 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7667\n",
      "Epoch 35/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3898 - capsnet_loss: 0.3293 - decoder_loss: 0.1545 - capsnet_acc: 0.8949\n",
      "Epoch 00035: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3897 - capsnet_loss: 0.3292 - decoder_loss: 0.1544 - capsnet_acc: 0.8948 - val_loss: 0.7347 - val_capsnet_loss: 0.6704 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7667\n",
      "Epoch 36/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3842 - capsnet_loss: 0.3235 - decoder_loss: 0.1548 - capsnet_acc: 0.9004\n",
      "Epoch 00036: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3840 - capsnet_loss: 0.3233 - decoder_loss: 0.1548 - capsnet_acc: 0.9005 - val_loss: 0.7193 - val_capsnet_loss: 0.6549 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.8000\n",
      "Epoch 37/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3818 - capsnet_loss: 0.3249 - decoder_loss: 0.1450 - capsnet_acc: 0.8941\n",
      "Epoch 00037: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3822 - capsnet_loss: 0.3253 - decoder_loss: 0.1451 - capsnet_acc: 0.8940 - val_loss: 0.7021 - val_capsnet_loss: 0.6377 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3932 - capsnet_loss: 0.3339 - decoder_loss: 0.1513 - capsnet_acc: 0.8906\n",
      "Epoch 00038: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3930 - capsnet_loss: 0.3337 - decoder_loss: 0.1514 - capsnet_acc: 0.8907 - val_loss: 0.6813 - val_capsnet_loss: 0.6170 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7667\n",
      "Epoch 39/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3651 - capsnet_loss: 0.3057 - decoder_loss: 0.1515 - capsnet_acc: 0.9051\n",
      "Epoch 00039: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3649 - capsnet_loss: 0.3056 - decoder_loss: 0.1515 - capsnet_acc: 0.9052 - val_loss: 0.6832 - val_capsnet_loss: 0.6189 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7667\n",
      "Epoch 40/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3756 - capsnet_loss: 0.3156 - decoder_loss: 0.1532 - capsnet_acc: 0.8991\n",
      "Epoch 00040: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3755 - capsnet_loss: 0.3154 - decoder_loss: 0.1532 - capsnet_acc: 0.8992 - val_loss: 0.7125 - val_capsnet_loss: 0.6482 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7667\n",
      "Epoch 41/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3682 - capsnet_loss: 0.3081 - decoder_loss: 0.1536 - capsnet_acc: 0.9026\n",
      "Epoch 00041: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3681 - capsnet_loss: 0.3080 - decoder_loss: 0.1535 - capsnet_acc: 0.9027 - val_loss: 0.7371 - val_capsnet_loss: 0.6727 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7500\n",
      "Epoch 42/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3706 - capsnet_loss: 0.3104 - decoder_loss: 0.1538 - capsnet_acc: 0.8984\n",
      "Epoch 00042: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3706 - capsnet_loss: 0.3103 - decoder_loss: 0.1538 - capsnet_acc: 0.8985 - val_loss: 0.7127 - val_capsnet_loss: 0.6484 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7667\n",
      "Epoch 43/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3685 - capsnet_loss: 0.3092 - decoder_loss: 0.1512 - capsnet_acc: 0.9021\n",
      "Epoch 00043: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3683 - capsnet_loss: 0.3091 - decoder_loss: 0.1512 - capsnet_acc: 0.9022 - val_loss: 0.6996 - val_capsnet_loss: 0.6353 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7500\n",
      "Epoch 44/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3724 - capsnet_loss: 0.3117 - decoder_loss: 0.1550 - capsnet_acc: 0.8994\n",
      "Epoch 00044: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3723 - capsnet_loss: 0.3115 - decoder_loss: 0.1550 - capsnet_acc: 0.8995 - val_loss: 0.6991 - val_capsnet_loss: 0.6348 - val_decoder_loss: 0.1640 - val_capsnet_acc: 0.7500\n",
      "Epoch 45/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3696 - capsnet_loss: 0.3107 - decoder_loss: 0.1504 - capsnet_acc: 0.9049\n",
      "Epoch 00045: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3695 - capsnet_loss: 0.3106 - decoder_loss: 0.1504 - capsnet_acc: 0.9050 - val_loss: 0.6997 - val_capsnet_loss: 0.6354 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7667\n",
      "Epoch 46/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3592 - capsnet_loss: 0.2994 - decoder_loss: 0.1523 - capsnet_acc: 0.9044\n",
      "Epoch 00046: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3590 - capsnet_loss: 0.2993 - decoder_loss: 0.1523 - capsnet_acc: 0.9045 - val_loss: 0.7169 - val_capsnet_loss: 0.6526 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7500\n",
      "Epoch 47/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3579 - capsnet_loss: 0.2985 - decoder_loss: 0.1516 - capsnet_acc: 0.9099\n",
      "Epoch 00047: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3578 - capsnet_loss: 0.2984 - decoder_loss: 0.1516 - capsnet_acc: 0.9100 - val_loss: 0.7260 - val_capsnet_loss: 0.6616 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7667\n",
      "Epoch 48/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3606 - capsnet_loss: 0.3003 - decoder_loss: 0.1540 - capsnet_acc: 0.9069\n",
      "Epoch 00048: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3606 - capsnet_loss: 0.3003 - decoder_loss: 0.1539 - capsnet_acc: 0.9067 - val_loss: 0.7463 - val_capsnet_loss: 0.6820 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7500\n",
      "Epoch 49/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3636 - capsnet_loss: 0.3044 - decoder_loss: 0.1510 - capsnet_acc: 0.9084\n",
      "Epoch 00049: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3635 - capsnet_loss: 0.3043 - decoder_loss: 0.1510 - capsnet_acc: 0.9085 - val_loss: 0.7456 - val_capsnet_loss: 0.6813 - val_decoder_loss: 0.1642 - val_capsnet_acc: 0.7667\n",
      "Epoch 50/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3600 - capsnet_loss: 0.3005 - decoder_loss: 0.1518 - capsnet_acc: 0.9076\n",
      "Epoch 00050: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3599 - capsnet_loss: 0.3004 - decoder_loss: 0.1517 - capsnet_acc: 0.9077 - val_loss: 0.7131 - val_capsnet_loss: 0.6488 - val_decoder_loss: 0.1641 - val_capsnet_acc: 0.7833\n",
      "Trained model saved to './result/trained_model.h5'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAG0CAYAAAAPefNdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2420fe4f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x242234cd7b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnet.train(model=model, data=(train_generator, (x_test, y_test)), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('E:\\\\trained_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator, (x_test, y_test), Z_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, 24, 24, 12, 3)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 24, 24, 12, 3)     6         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               2654336   \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 128, 1, 1, 1, 1)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 128, 11, 11, 6, 64 46528     \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 128, 24, 24, 12, 6 131136    \n",
      "=================================================================\n",
      "Total params: 2,832,006\n",
      "Trainable params: 2,832,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('E:\\\\trained_model2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('E:\\\\trained_model2.h5')\n",
    "eval_model.load_weights('result2\\\\weights-35.h5')\n",
    "manipulate_model.load_weights('result2\\\\weights-35.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./result/weights-35.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C.classes_to_include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result/manipulate-hcc.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result/manipulate-cholangio.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result/manipulate-colorectal.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result/manipulate-cyst.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result/manipulate-hemangioma.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result/manipulate-fnh.png\n",
      "------------------------------End: manipulate------------------------------\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cnet)\n",
    "for i in range(6):\n",
    "    cnet.manipulate_latent(manipulate_model, (x_test, y_test), args, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "cnet.test(model=eval_model, data=(x_test, y_test), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = layers.Input([28,28,1])\n",
    "x = layers.Conv2D(4,kernel_size=9,strides=1)(a)\n",
    "x = layers.Conv2D(4,kernel_size=9,strides=2)(x)\n",
    "b = x\n",
    "model = Model(a,b)\n",
    "model.summary(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "input_51 (InputLayer)                        (None, 24, 24, 12, 3)                   0              \n",
      "____________________________________________________________________________________________________\n",
      "instance_normalization_3 (InstanceNormalizat (None, 24, 24, 12, 3)                   6              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)                         (None, 20736)                           0              \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                             (None, 128)                             2654336        \n",
      "____________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)                         (None, 128, 1, 1, 1, 1)                 0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistributed)        (None, 128, 11, 11, 6, 64)              46528          \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistributed)        (None, 128, 24, 24, 12, 64)             131136         \n",
      "====================================================================================================\n",
      "Total params: 2,832,006\n",
      "Trainable params: 2,832,006\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a = layers.Input(shape=[24,24,12,3])\n",
    "x = InstanceNormalization(axis=4)(a)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Reshape(target_shape=(128,1,1,1,1))(x)\n",
    "x = layers.TimeDistributed(layers.Conv3DTranspose(filters=64, kernel_size=[11,11,6], strides=1, padding='valid', activation='relu'))(x)\n",
    "x = layers.TimeDistributed(layers.Conv3DTranspose(filters=64, kernel_size=[4,4,2], strides=2, padding='valid', activation='relu'))(x)\n",
    "#x = layers.Reshape((3, 24, 24, 12))(x)\n",
    "#x = layers.Permute((2,3,4,1))(x)\n",
    "b = x\n",
    "model = Model(a,b)\n",
    "\n",
    "model.summary(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C_list = [config.Config(), config.Config()]\n",
    "C_list[0].dims = [36,36,12]\n",
    "C_list[1].dims = [24,24,12]\n",
    "C_list[0].artif_dir = \"E:\\\\imgs\\\\artif_imgs_3612\\\\\"\n",
    "C_list[1].artif_dir = \"E:\\\\imgs\\\\artif_imgs_2412\\\\\"\n",
    "C_list[0].aug_dir = \"E:\\\\imgs\\\\aug_imgs_3612_cropint\\\\\"\n",
    "C_list[1].aug_dir = \"E:\\\\imgs\\\\aug_imgs_2412_cropint\\\\\"\n",
    "C_list[0].orig_dir = \"E:\\\\imgs\\\\orig_imgs_3612_cropint\\\\\"\n",
    "C_list[1].orig_dir = \"E:\\\\imgs\\\\orig_imgs_2412_cropint\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_reader = ['E103312835_1','12823036_0','12569915_0','E102093118_0','E102782525_0','12799652_0','E100894274_0','12874178_3','E100314676_0','12842070_0','13092836_2','12239783_0','12783467_0','13092966_0','E100962970_0','E100183257_1','E102634440_0','E106182827_0','12582632_0','E100121654_0','E100407633_0','E105310461_0','12788616_0','E101225606_0','12678910_1','E101083458_1','12324408_0','13031955_0','E101415263_0','E103192914_0','12888679_2','E106096969_0','E100192709_1','13112385_1','E100718398_0','12207268_0','E105244287_0','E102095465_0','E102613189_0','12961059_0','11907521_0','E105311123_0','12552705_0','E100610622_0','12975280_0','E105918926_0','E103020139_1','E101069048_1','E105427046_0','13028374_0','E100262351_0','12302576_0','12451831_0','E102929168_0','E100383453_0','E105344747_0','12569826_0','E100168661_0','12530153_0','E104697262_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()\n",
    "#T.steps_per_epoch = 50\n",
    "#T.epochs= 1\n",
    "#T.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbuild.run_fixed_hyperparams([C], hyperparams=T)#C_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                       Output Shape                                                Param #                \n",
      "======================================================================================================================================================\n",
      "input_94 (InputLayer)                                              (None, 24, 24, 12, 3)                                       0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)                                               (None, 24, 24, 12, 3, 1)                                    0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNormalization)                       (None, 24, 24, 12, 3, 1)                                    12                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "permute_20 (Permute)                                               (None, 3, 24, 24, 12, 1)                                    0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_210 (TimeDistributed)                             (None, 3, 22, 22, 11, 64)                                   1216                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNormalization)                       (None, 3, 22, 22, 11, 64)                                   256                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_211 (TimeDistributed)                             (None, 3, 22, 22, 11, 64)                                   0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_119 (Activation)                                        (None, 3, 22, 22, 11, 64)                                   0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_212 (TimeDistributed)                             (None, 3, 11, 11, 5, 64)                                    0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_213 (TimeDistributed)                             (None, 3, 9, 9, 4, 64)                                      73792                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNormalization)                       (None, 3, 9, 9, 4, 64)                                      256                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_214 (TimeDistributed)                             (None, 3, 9, 9, 4, 64)                                      0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_120 (Activation)                                        (None, 3, 9, 9, 4, 64)                                      0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_215 (TimeDistributed)                             (None, 3, 7, 7, 3, 128)                                     147584                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNormalization)                       (None, 3, 7, 7, 3, 128)                                     512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_216 (TimeDistributed)                             (None, 3, 7, 7, 3, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_121 (Activation)                                        (None, 3, 7, 7, 3, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_217 (TimeDistributed)                             (None, 3, 5, 5, 2, 128)                                     295040                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNormalization)                       (None, 3, 5, 5, 2, 128)                                     512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_218 (TimeDistributed)                             (None, 3, 5, 5, 2, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_122 (Activation)                                        (None, 3, 5, 5, 2, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_219 (TimeDistributed)                             (None, 3, 2, 2, 2, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_220 (TimeDistributed)                             (None, 3, 1024)                                             0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "simple_rnn_18 (SimpleRNN)                                          (None, 128)                                                 147584                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNormalization)                       (None, 128)                                                 512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_123 (Activation)                                        (None, 128)                                                 0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)                                               (None, 128)                                                 0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_68 (Dense)                                                   (None, 6)                                                   774                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNormalization)                       (None, 6)                                                   24                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_124 (Activation)                                        (None, 6)                                                   0                      \n",
      "======================================================================================================================================================\n",
      "Total params: 668,074\n",
      "Trainable params: 667,032\n",
      "Non-trainable params: 1,042\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cbuild.build_cnn_hyperparams(T)\n",
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0)#, Z_test_fixed=Z_reader)\n",
    "Z_test, Z_train_orig = Z\n",
    "X_train_orig, Y_train_orig = train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils import multi_gpu_model\n",
    "#model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 84s 112ms/step - loss: 0.7299 - acc: 0.7565 - val_loss: 0.4721 - val_acc: 0.8833\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.4405 - acc: 0.8547 - val_loss: 0.4828 - val_acc: 0.8167\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.3328 - acc: 0.8856 - val_loss: 0.3714 - val_acc: 0.8500\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.4052 - val_acc: 0.8667\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.2077 - acc: 0.9304 - val_loss: 0.3070 - val_acc: 0.8833\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 0.1901 - acc: 0.9340 - val_loss: 0.5502 - val_acc: 0.8500\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.1577 - acc: 0.9465 - val_loss: 0.5793 - val_acc: 0.7667\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.1401 - acc: 0.9511 - val_loss: 0.5413 - val_acc: 0.8333\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.1170 - acc: 0.9598 - val_loss: 0.6781 - val_acc: 0.8333\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 79s 105ms/step - loss: 0.1018 - acc: 0.9651 - val_loss: 0.3647 - val_acc: 0.8667\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 80s 106ms/step - loss: 0.1025 - acc: 0.9642 - val_loss: 0.4280 - val_acc: 0.9000\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 0.0954 - acc: 0.9681 - val_loss: 0.3162 - val_acc: 0.9000\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 0.0855 - acc: 0.9712 - val_loss: 0.4631 - val_acc: 0.8833\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 0.0731 - acc: 0.9755 - val_loss: 0.5037 - val_acc: 0.8667\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 0.0659 - acc: 0.9777 - val_loss: 0.5650 - val_acc: 0.8333\n",
      "Epoch 16/20\n",
      "371/750 [=============>................] - ETA: 40s - loss: 0.0695 - acc: 0.9762"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_generator, steps_per_epoch=T.steps_per_epoch, epochs=T.epochs, validation_data=[X_test, Y_test])#, callbacks=[T.early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('E:\\\\models\\\\model_reader_rcnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df_art, voi_df_ven, voi_df_eq = drm.get_voi_dfs()\n",
    "small_voi_df = pd.read_csv(C.small_voi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916666666667\n",
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "#plot_with_bbox(fn_list[2], cls_mapping[wrong_guesses[2]])\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#save_output(Z_test, y_pred, y_true)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)\n",
    "print(accuracy_score(y_true_simp, y_pred_simp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc6cls = []\n",
    "acc3cls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test_fixed=Z_reader)\n",
    "Z_test, Z_train_orig = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E100610622_0', 'E100314676_0', '13112385_1', 'E100718398_0',\n",
       "       '12530153_0', '12451831_0', '12569826_0', '13028374_0',\n",
       "       '12207268_0', '12302576_0', '12324408_0', '12888679_2',\n",
       "       '12961059_0', '12975280_0', 'E100183257_1', 'E100962970_0',\n",
       "       'E101083458_1', 'E103312835_1', 'E104697262_0', 'E105311123_0',\n",
       "       'E102782525_0', 'E101415263_0', 'E100192709_1', 'E103192914_0',\n",
       "       'E100383453_0', '12552705_0', 'E105244287_0', 'E105918926_0',\n",
       "       'E106182827_0', '13092836_2', '12582632_0', 'E103020139_1',\n",
       "       '12569915_0', 'E102093118_0', 'E102929168_0', 'E102634440_0',\n",
       "       'E105310461_0', 'E105427046_0', 'E102613189_0', 'E102095465_0',\n",
       "       'E100262351_0', 'E106096969_0', 'E101225606_0', 'E101069048_1',\n",
       "       'E105344747_0', 'E100407633_0', '13092966_0', '12783467_0',\n",
       "       '13031955_0', 'E100894274_0', '12874178_3', '12239783_0',\n",
       "       '12788616_0', '11907521_0', '12823036_0', '12842070_0',\n",
       "       'E100168661_0', 'E100121654_0', '12678910_1', '12799652_0'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test=Z_reader)\n",
    "Z_test, Z_train_orig = Z\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = [C.classes_to_include[y] for y in y_pred]\n",
    "Y_true = [C.classes_to_include[y] for y in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame([Z_test,Y_pred,Y_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.to_csv('E:\\\\hi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(19):\n",
    "    model_num = 306+i\n",
    "    X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test=df[df['model_num'] == model_num][\"z_test\"])\n",
    "    X_train_orig, Y_train_orig = train_orig\n",
    "    model = keras.models.load_model(os.path.join(C.model_dir, \"models_%d.hdf5\" % model_num)) #models_305\n",
    "    \n",
    "    Y_pred = model.predict(X_train_orig)\n",
    "    y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "    y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "    acc6cls.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)\n",
    "\n",
    "    acc3cls.append(accuracy_score(y_true_simp, y_pred_simp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Z:\\\\Inter-reader study\\\\Answer key.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df[\"Class\"].values\n",
    "y_pred = df[\"Model\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=C.classes_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\t0\t1\t0\t0\t1\n",
      "0\t9\t1\t0\t0\t0\n",
      "0\t1\t8\t0\t0\t0\n",
      "0\t0\t0\t10\t0\t0\n",
      "0\t0\t0\t0\t9\t0\n",
      "0\t0\t0\t0\t1\t9\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cm)):\n",
    "    print('\\t'.join(cm[:,i].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_list = fn_list + list(Z_test[~np.equal(y_pred, y_true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_list = fn_list + list(Z_train_orig[~np.equal(y_pred, y_true)])\n",
    "fn_list = fn_list + list(Z_train_orig[~np.equal(y_pred, y_true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_x_list = [x+\"(\"+str(voi_df_art[voi_df_art[\"id\"] == x[:-4]][\"x1\"].values[0])+\")\" for x in fn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(fn_x_list, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_train_orig)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#cbuild.save_output(Z_train_orig, y_pred, y_true)#, save_dir=C.output_img_dir+\"\\\\training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305\n",
    "#cnna.visualize_layer(model, 'conv3d_148')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filter_outputs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dense_outputs = cbuild.build_pretrain_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_results = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "\n",
    "filter_avgs = np.concatenate([filter_results[cls] for cls in C.classes_to_include], axis=0)\n",
    "filter_avgs = np.mean(filter_avgs, axis=0)\n",
    "\n",
    "filter_cls_avg_unscaled = {cls: np.mean(filter_results[cls], axis=0) for cls in C.classes_to_include}\n",
    "filter_cls_avg_scaled = {cls: np.mean(filter_results[cls], axis=0) / filter_avgs for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters.csv', 'w', newline='') as csvfile:\n",
    "    header = ['filter_num'] + C.classes_to_include\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [filter_cls_avg_scaled[cls][f_num] for cls in C.classes_to_include])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.flatten([list(feature_sheet[\"evidence1\"+cls].dropna().values) for cls in C.classes_to_include]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_sheet = pd.read_excel(C.xls_name, \"Descriptions\")\n",
    "\n",
    "features_by_cls = {}\n",
    "feat_count = {}\n",
    "for cls in C.classes_to_include:\n",
    "    features_by_cls[cls] = list(feature_sheet[\"evidence1\"+cls].dropna().values)\n",
    "    features_by_cls[cls] = features_by_cls[cls] + list(feature_sheet[\"evidence2\"+cls].dropna().values)\n",
    "#all_features = list(set([f for cls in features for f in features[cls]]))\n",
    "\n",
    "feat_count = dict(zip(*np.unique([f for cls in features_by_cls for f in features_by_cls[cls]], return_counts=True)))\n",
    "all_features = list(feat_count.keys())\n",
    "#for cls in C.classes_to_include:\n",
    "#    features_by_cls[cls] = list(set(features_by_cls[cls]))\n",
    "\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous enhancing rim (5)\n",
      "progressive or concentric enhancement (5)\n",
      "regular spherical hypointense mass (5)\n"
     ]
    }
   ],
   "source": [
    "z = dict(zip(*np.unique(features_by_cls['colorectal'], return_counts=True)))\n",
    "for k in z:\n",
    "    print(k, \" (\",z[k],\")\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arterial enhancement': 10,\n",
       " 'central scar': 5,\n",
       " 'continuous enhancing rim': 10,\n",
       " 'delayed isointensity': 10,\n",
       " 'heterogeneous': 10,\n",
       " 'hyperintense mass on delayed phase': 10,\n",
       " 'hypointense without enhancement': 10,\n",
       " 'infiltrative': 10,\n",
       " 'lobulated margins': 10,\n",
       " 'nodular or discontinuous enhancement': 10,\n",
       " 'progressive centripetal filling': 10,\n",
       " 'progressive or concentric enhancement': 10,\n",
       " 'regular spherical hypointense mass': 10,\n",
       " 'thin well-defined walls': 10,\n",
       " 'venous washout': 10}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in [c for c in feature_sheet.columns if c.startswith(\"evidence\")]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_features_by_cls = {cls: {} for cls in features_by_cls}\n",
    "Z_features = {}\n",
    "\n",
    "for cls in C.classes_to_include:\n",
    "    for f in features_by_cls[cls]:\n",
    "        if f not in Z_features:\n",
    "            Z_features[f] = []\n",
    "            \n",
    "        Z_features_by_cls[cls][f] = [x for x in feature_sheet[feature_sheet[\"evidence1\"+cls] == f][cls].values]\n",
    "        Z_features[f] += [x for x in feature_sheet[feature_sheet[\"evidence1\"+cls] == f][cls].values]\n",
    "        if feature_sheet[\"evidence2\"+cls].dropna().size > 0:\n",
    "            Z_features_by_cls[cls][f] = Z_features_by_cls[cls][f] + [x+\".npy\" for x in feature_sheet[feature_sheet[\"evidence2\"+cls] == f][cls].values]\n",
    "            Z_features[f] += [x for x in feature_sheet[feature_sheet[\"evidence2\"+cls] == f][cls].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_filters = {f:np.empty([0,100]) for f in all_features}#{cls: {} for cls in features}\n",
    "feature_filters_scaled = {}#{cls: {} for cls in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs\n",
    "        \n",
    "    feature_filters[f] = np.mean(feature_filters[f], axis=0)# / filter_avgs\n",
    "\n",
    "    ff = feature_filters[f]\n",
    "    feature_filters[f] = np.where(ff > np.mean(ff), ff, 0)\n",
    "\n",
    "    #ff = feature_filters[cls][f]\n",
    "    #feature_filters[cls][f] = np.where(ff > 1*filter_cls_avg_unscaled[cls], ff, 0)\n",
    "\n",
    "    ff = feature_filters[f]\n",
    "    feature_filters[f] = np.where(ff > 1.3*filter_avgs, ff, 0)\n",
    "\n",
    "    feature_filters_scaled[f] = feature_filters[f] / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features_cls = header[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)\n",
    "    #filters_test[cls] = np.apply_along_axis(lambda x: x / filter_avgs, 1, filters_test[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_evidence_strength(feature_filters, pred_filters):\n",
    "    \"\"\"A good pred_filter has high values for all the key (non-zero) features of feature_filter.\n",
    "    These values should be unscaled.\n",
    "    Returns average percentage of the mean value of the key filters (capped at 100%)\"\"\"\n",
    "    \n",
    "    strength = 0\n",
    "    num_key_filters = sum(feature_filters > 0)\n",
    "    \n",
    "    for i in range(len(pred_filters)):\n",
    "        t = feature_filters[i]\n",
    "        p = pred_filters[i]\n",
    "        \n",
    "        if t == 0:\n",
    "            continue\n",
    "            \n",
    "        strength += min(p/t, 1.1)#t*p / filter_avgs[i]**.7\n",
    "    return (strength / num_key_filters / 1.1)**.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "max_strength = 0\n",
    "\n",
    "#cls = true_cls\n",
    "\"\"\"for f in features[cls]:\n",
    "    evidence[f] = get_evidence_strength(feature_filters[cls][f], filters_test[cls][img_num])\n",
    "    max_strength = max(max_strength, evidence[f])\n",
    "\"\"\"\n",
    "#for cls in C.classes_to_include:\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACFCAYAAABsdIKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5ecc3bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['continuous enhancing rim',\n",
       " 'arterial enhancement',\n",
       " 'hypointense without enhancement',\n",
       " 'venous washout',\n",
       " 'nodular or discontinuous enhancement',\n",
       " 'regular spherical hypointense mass',\n",
       " 'hyperintense mass on delayed phase',\n",
       " 'heterogeneous',\n",
       " 'infiltrative',\n",
       " 'central scar',\n",
       " 'progressive centripetal filling',\n",
       " 'thin well-defined walls',\n",
       " 'delayed isointensity',\n",
       " 'lobulated margins',\n",
       " 'progressive or concentric enhancement']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters_test[true_cls][img_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for true_cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[true_cls])):\n",
    "        z = Z_test[true_cls][img_num]\n",
    "        x = np.expand_dims(x_test[true_cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        max_strength = 0\n",
    "        cls = true_cls\n",
    "        \n",
    "        output[z] = [true_cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        for f in all_features:\n",
    "            evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[true_cls][img_num])\n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, int(strength*100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred4.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][7]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
