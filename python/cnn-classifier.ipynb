{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "\n",
    "import argparse\n",
    "import capsulenet as cnet\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import cnn_runner as crun\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "importlib.reload(config)\n",
    "importlib.reload(crun)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()\n",
    "T.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator, (x_test, y_test), _ = cbuild.load_data_capsnet()\n",
    "(x_train, y_train), _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('strings', metavar='STRING', nargs='*', help='String for searching')\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--batch_size', default=2, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float,\n",
    "                    help=\"Initial learning rate\")\n",
    "parser.add_argument('--lr_decay', default=0.9, type=float,\n",
    "                    help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
    "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
    "                    help=\"The coefficient for the loss of decoder\")\n",
    "parser.add_argument('-r', '--routings', default=3, type=int,\n",
    "                    help=\"Number of iterations used in routing algorithm. should > 0\")\n",
    "#parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
    "#                    help=\"Fraction of pixels to shift at most in each direction.\")\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('-t', '--testing', action='store_true',\n",
    "                    help=\"Test the trained model on testing dataset\")\n",
    "parser.add_argument('--digit', default=5, type=int,\n",
    "                    help=\"Digit to manipulate\")\n",
    "parser.add_argument('-w', '--weights', default=None,\n",
    "                    help=\"The path of the saved weights. Should be specified when testing\")\n",
    "args = parser.parse_args('--epochs 50')# --lr 0.002 --lr_decay 0.87')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "\n",
    "model, eval_model, manipulate_model = cnet.CapsNet(input_shape=x_train.shape[1:],\n",
    "                                              n_class=len(np.unique(np.argmax(y_train, 1))),\n",
    "                                              routings=args.routings)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.5805 - capsnet_loss: 1.5294 - decoder_loss: 0.1304 - capsnet_acc: 0.2913\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.51667, saving model to ./result/weights-01.h5\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 1.5804 - capsnet_loss: 1.5293 - decoder_loss: 0.1304 - capsnet_acc: 0.2914 - val_loss: 1.3561 - val_capsnet_loss: 1.3127 - val_decoder_loss: 0.1108 - val_capsnet_acc: 0.5167\n",
      "Epoch 2/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.2966 - capsnet_loss: 1.2451 - decoder_loss: 0.1313 - capsnet_acc: 0.4774\n",
      "Epoch 00002: val_capsnet_acc improved from 0.51667 to 0.60000, saving model to ./result/weights-02.h5\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 1.2964 - capsnet_loss: 1.2449 - decoder_loss: 0.1313 - capsnet_acc: 0.4775 - val_loss: 1.1146 - val_capsnet_loss: 1.0707 - val_decoder_loss: 0.1121 - val_capsnet_acc: 0.6000\n",
      "Epoch 3/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.0669 - capsnet_loss: 1.0184 - decoder_loss: 0.1237 - capsnet_acc: 0.6074\n",
      "Epoch 00003: val_capsnet_acc improved from 0.60000 to 0.68333, saving model to ./result/weights-03.h5\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 1.0667 - capsnet_loss: 1.0183 - decoder_loss: 0.1237 - capsnet_acc: 0.6075 - val_loss: 0.8933 - val_capsnet_loss: 0.8506 - val_decoder_loss: 0.1089 - val_capsnet_acc: 0.6833\n",
      "Epoch 4/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.8702 - capsnet_loss: 0.8255 - decoder_loss: 0.1140 - capsnet_acc: 0.7189\n",
      "Epoch 00004: val_capsnet_acc improved from 0.68333 to 0.73333, saving model to ./result/weights-04.h5\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.8702 - capsnet_loss: 0.8255 - decoder_loss: 0.1140 - capsnet_acc: 0.7190 - val_loss: 0.8597 - val_capsnet_loss: 0.8116 - val_decoder_loss: 0.1227 - val_capsnet_acc: 0.7333\n",
      "Epoch 5/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7722 - capsnet_loss: 0.7297 - decoder_loss: 0.1085 - capsnet_acc: 0.7560\n",
      "Epoch 00005: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.7721 - capsnet_loss: 0.7295 - decoder_loss: 0.1085 - capsnet_acc: 0.7562 - val_loss: 0.8253 - val_capsnet_loss: 0.7856 - val_decoder_loss: 0.1013 - val_capsnet_acc: 0.7333\n",
      "Epoch 6/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6896 - capsnet_loss: 0.6496 - decoder_loss: 0.1019 - capsnet_acc: 0.7916\n",
      "Epoch 00006: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6895 - capsnet_loss: 0.6496 - decoder_loss: 0.1018 - capsnet_acc: 0.7918 - val_loss: 0.8205 - val_capsnet_loss: 0.7819 - val_decoder_loss: 0.0984 - val_capsnet_acc: 0.6500\n",
      "Epoch 7/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6428 - capsnet_loss: 0.6031 - decoder_loss: 0.1013 - capsnet_acc: 0.8123\n",
      "Epoch 00007: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.6431 - capsnet_loss: 0.6034 - decoder_loss: 0.1013 - capsnet_acc: 0.8122 - val_loss: 0.7903 - val_capsnet_loss: 0.7509 - val_decoder_loss: 0.1005 - val_capsnet_acc: 0.7167\n",
      "Epoch 8/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5880 - capsnet_loss: 0.5501 - decoder_loss: 0.0968 - capsnet_acc: 0.8275\n",
      "Epoch 00008: val_capsnet_acc improved from 0.73333 to 0.73333, saving model to ./result/weights-08.h5\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.5882 - capsnet_loss: 0.5502 - decoder_loss: 0.0968 - capsnet_acc: 0.8274 - val_loss: 0.7607 - val_capsnet_loss: 0.7222 - val_decoder_loss: 0.0984 - val_capsnet_acc: 0.7333\n",
      "Epoch 9/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5505 - capsnet_loss: 0.5132 - decoder_loss: 0.0953 - capsnet_acc: 0.8363\n",
      "Epoch 00009: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.5506 - capsnet_loss: 0.5133 - decoder_loss: 0.0952 - capsnet_acc: 0.8362 - val_loss: 0.8345 - val_capsnet_loss: 0.7978 - val_decoder_loss: 0.0938 - val_capsnet_acc: 0.7000\n",
      "Epoch 10/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5101 - capsnet_loss: 0.4744 - decoder_loss: 0.0913 - capsnet_acc: 0.8539\n",
      "Epoch 00010: val_capsnet_acc improved from 0.73333 to 0.78333, saving model to ./result/weights-10.h5\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.5101 - capsnet_loss: 0.4743 - decoder_loss: 0.0912 - capsnet_acc: 0.8540 - val_loss: 0.7265 - val_capsnet_loss: 0.6907 - val_decoder_loss: 0.0912 - val_capsnet_acc: 0.7833\n",
      "Epoch 11/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4867 - capsnet_loss: 0.4510 - decoder_loss: 0.0911 - capsnet_acc: 0.8603\n",
      "Epoch 00011: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.4866 - capsnet_loss: 0.4509 - decoder_loss: 0.0910 - capsnet_acc: 0.8603 - val_loss: 0.6995 - val_capsnet_loss: 0.6640 - val_decoder_loss: 0.0904 - val_capsnet_acc: 0.7667\n",
      "Epoch 12/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4606 - capsnet_loss: 0.4262 - decoder_loss: 0.0876 - capsnet_acc: 0.8657\n",
      "Epoch 00012: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.4605 - capsnet_loss: 0.4262 - decoder_loss: 0.0876 - capsnet_acc: 0.8657 - val_loss: 0.6708 - val_capsnet_loss: 0.6335 - val_decoder_loss: 0.0951 - val_capsnet_acc: 0.7500\n",
      "Epoch 13/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4365 - capsnet_loss: 0.4023 - decoder_loss: 0.0871 - capsnet_acc: 0.8763\n",
      "Epoch 00013: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.4364 - capsnet_loss: 0.4022 - decoder_loss: 0.0871 - capsnet_acc: 0.8763 - val_loss: 0.6816 - val_capsnet_loss: 0.6473 - val_decoder_loss: 0.0875 - val_capsnet_acc: 0.7667\n",
      "Epoch 14/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4119 - capsnet_loss: 0.3781 - decoder_loss: 0.0861 - capsnet_acc: 0.8835\n",
      "Epoch 00014: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.4120 - capsnet_loss: 0.3783 - decoder_loss: 0.0861 - capsnet_acc: 0.8834 - val_loss: 0.7479 - val_capsnet_loss: 0.7134 - val_decoder_loss: 0.0880 - val_capsnet_acc: 0.7667\n",
      "Epoch 15/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3935 - capsnet_loss: 0.3608 - decoder_loss: 0.0834 - capsnet_acc: 0.8919\n",
      "Epoch 00015: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3935 - capsnet_loss: 0.3607 - decoder_loss: 0.0834 - capsnet_acc: 0.8920 - val_loss: 0.6844 - val_capsnet_loss: 0.6497 - val_decoder_loss: 0.0884 - val_capsnet_acc: 0.7833\n",
      "Epoch 16/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3755 - capsnet_loss: 0.3421 - decoder_loss: 0.0853 - capsnet_acc: 0.9030\n",
      "Epoch 00016: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.3756 - capsnet_loss: 0.3422 - decoder_loss: 0.0853 - capsnet_acc: 0.9028 - val_loss: 0.6184 - val_capsnet_loss: 0.5832 - val_decoder_loss: 0.0896 - val_capsnet_acc: 0.7667\n",
      "Epoch 17/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3572 - capsnet_loss: 0.3248 - decoder_loss: 0.0827 - capsnet_acc: 0.9041\n",
      "Epoch 00017: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3572 - capsnet_loss: 0.3248 - decoder_loss: 0.0827 - capsnet_acc: 0.9041 - val_loss: 0.6462 - val_capsnet_loss: 0.6123 - val_decoder_loss: 0.0865 - val_capsnet_acc: 0.7667\n",
      "Epoch 18/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3416 - capsnet_loss: 0.3098 - decoder_loss: 0.0811 - capsnet_acc: 0.9097\n",
      "Epoch 00018: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3415 - capsnet_loss: 0.3098 - decoder_loss: 0.0811 - capsnet_acc: 0.9098 - val_loss: 0.6294 - val_capsnet_loss: 0.5932 - val_decoder_loss: 0.0924 - val_capsnet_acc: 0.7500\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3360 - capsnet_loss: 0.3041 - decoder_loss: 0.0813 - capsnet_acc: 0.9134\n",
      "Epoch 00019: val_capsnet_acc improved from 0.78333 to 0.80000, saving model to ./result/weights-19.h5\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3359 - capsnet_loss: 0.3040 - decoder_loss: 0.0813 - capsnet_acc: 0.9135 - val_loss: 0.5535 - val_capsnet_loss: 0.5203 - val_decoder_loss: 0.0847 - val_capsnet_acc: 0.8000\n",
      "Epoch 20/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3196 - capsnet_loss: 0.2884 - decoder_loss: 0.0796 - capsnet_acc: 0.9163\n",
      "Epoch 00020: val_capsnet_acc improved from 0.80000 to 0.81667, saving model to ./result/weights-20.h5\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3197 - capsnet_loss: 0.2885 - decoder_loss: 0.0796 - capsnet_acc: 0.9162 - val_loss: 0.6139 - val_capsnet_loss: 0.5811 - val_decoder_loss: 0.0837 - val_capsnet_acc: 0.8167\n",
      "Epoch 21/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3080 - capsnet_loss: 0.2771 - decoder_loss: 0.0789 - capsnet_acc: 0.9215\n",
      "Epoch 00021: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3080 - capsnet_loss: 0.2771 - decoder_loss: 0.0789 - capsnet_acc: 0.9215 - val_loss: 0.5814 - val_capsnet_loss: 0.5481 - val_decoder_loss: 0.0851 - val_capsnet_acc: 0.8000\n",
      "Epoch 22/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3035 - capsnet_loss: 0.2729 - decoder_loss: 0.0781 - capsnet_acc: 0.9233\n",
      "Epoch 00022: val_capsnet_acc improved from 0.81667 to 0.83333, saving model to ./result/weights-22.h5\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.3034 - capsnet_loss: 0.2728 - decoder_loss: 0.0781 - capsnet_acc: 0.9233 - val_loss: 0.5698 - val_capsnet_loss: 0.5371 - val_decoder_loss: 0.0835 - val_capsnet_acc: 0.8333\n",
      "Epoch 23/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2887 - capsnet_loss: 0.2586 - decoder_loss: 0.0770 - capsnet_acc: 0.9248\n",
      "Epoch 00023: val_capsnet_acc improved from 0.83333 to 0.85000, saving model to ./result/weights-23.h5\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2887 - capsnet_loss: 0.2585 - decoder_loss: 0.0770 - capsnet_acc: 0.9248 - val_loss: 0.6098 - val_capsnet_loss: 0.5756 - val_decoder_loss: 0.0874 - val_capsnet_acc: 0.8500\n",
      "Epoch 24/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2856 - capsnet_loss: 0.2555 - decoder_loss: 0.0768 - capsnet_acc: 0.9305\n",
      "Epoch 00024: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2857 - capsnet_loss: 0.2555 - decoder_loss: 0.0768 - capsnet_acc: 0.9305 - val_loss: 0.5965 - val_capsnet_loss: 0.5640 - val_decoder_loss: 0.0830 - val_capsnet_acc: 0.7833\n",
      "Epoch 25/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2776 - capsnet_loss: 0.2478 - decoder_loss: 0.0760 - capsnet_acc: 0.9341\n",
      "Epoch 00025: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2777 - capsnet_loss: 0.2479 - decoder_loss: 0.0760 - capsnet_acc: 0.9340 - val_loss: 0.5874 - val_capsnet_loss: 0.5550 - val_decoder_loss: 0.0826 - val_capsnet_acc: 0.8333\n",
      "Epoch 26/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2712 - capsnet_loss: 0.2413 - decoder_loss: 0.0763 - capsnet_acc: 0.9363\n",
      "Epoch 00026: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 165s 165ms/step - loss: 0.2711 - capsnet_loss: 0.2412 - decoder_loss: 0.0763 - capsnet_acc: 0.9363 - val_loss: 0.5668 - val_capsnet_loss: 0.5319 - val_decoder_loss: 0.0891 - val_capsnet_acc: 0.8167\n",
      "Epoch 27/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2693 - capsnet_loss: 0.2396 - decoder_loss: 0.0758 - capsnet_acc: 0.9351\n",
      "Epoch 00027: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2692 - capsnet_loss: 0.2395 - decoder_loss: 0.0758 - capsnet_acc: 0.9352 - val_loss: 0.6128 - val_capsnet_loss: 0.5806 - val_decoder_loss: 0.0822 - val_capsnet_acc: 0.8333\n",
      "Epoch 28/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2584 - capsnet_loss: 0.2288 - decoder_loss: 0.0755 - capsnet_acc: 0.9383\n",
      "Epoch 00028: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.2583 - capsnet_loss: 0.2287 - decoder_loss: 0.0755 - capsnet_acc: 0.9383 - val_loss: 0.6385 - val_capsnet_loss: 0.6058 - val_decoder_loss: 0.0833 - val_capsnet_acc: 0.7833\n",
      "Epoch 29/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2609 - capsnet_loss: 0.2315 - decoder_loss: 0.0750 - capsnet_acc: 0.9389\n",
      "Epoch 00029: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2608 - capsnet_loss: 0.2314 - decoder_loss: 0.0750 - capsnet_acc: 0.9390 - val_loss: 0.6305 - val_capsnet_loss: 0.5982 - val_decoder_loss: 0.0825 - val_capsnet_acc: 0.7667\n",
      "Epoch 30/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2468 - capsnet_loss: 0.2177 - decoder_loss: 0.0743 - capsnet_acc: 0.9436\n",
      "Epoch 00030: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.2470 - capsnet_loss: 0.2179 - decoder_loss: 0.0743 - capsnet_acc: 0.9435 - val_loss: 0.5706 - val_capsnet_loss: 0.5386 - val_decoder_loss: 0.0815 - val_capsnet_acc: 0.8167\n",
      "Epoch 31/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2453 - capsnet_loss: 0.2161 - decoder_loss: 0.0744 - capsnet_acc: 0.9429\n",
      "Epoch 00031: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2452 - capsnet_loss: 0.2160 - decoder_loss: 0.0744 - capsnet_acc: 0.9429 - val_loss: 0.5980 - val_capsnet_loss: 0.5665 - val_decoder_loss: 0.0802 - val_capsnet_acc: 0.8167\n",
      "Epoch 32/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2372 - capsnet_loss: 0.2085 - decoder_loss: 0.0734 - capsnet_acc: 0.9485\n",
      "Epoch 00032: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2374 - capsnet_loss: 0.2086 - decoder_loss: 0.0734 - capsnet_acc: 0.9483 - val_loss: 0.6291 - val_capsnet_loss: 0.5968 - val_decoder_loss: 0.0822 - val_capsnet_acc: 0.7833\n",
      "Epoch 33/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2427 - capsnet_loss: 0.2137 - decoder_loss: 0.0738 - capsnet_acc: 0.9455\n",
      "Epoch 00033: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2426 - capsnet_loss: 0.2137 - decoder_loss: 0.0738 - capsnet_acc: 0.9456 - val_loss: 0.6718 - val_capsnet_loss: 0.6402 - val_decoder_loss: 0.0805 - val_capsnet_acc: 0.7667\n",
      "Epoch 34/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2368 - capsnet_loss: 0.2079 - decoder_loss: 0.0738 - capsnet_acc: 0.9473\n",
      "Epoch 00034: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2369 - capsnet_loss: 0.2079 - decoder_loss: 0.0738 - capsnet_acc: 0.9473 - val_loss: 0.6073 - val_capsnet_loss: 0.5754 - val_decoder_loss: 0.0814 - val_capsnet_acc: 0.8000\n",
      "Epoch 35/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2282 - capsnet_loss: 0.1998 - decoder_loss: 0.0726 - capsnet_acc: 0.9493\n",
      "Epoch 00035: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2282 - capsnet_loss: 0.1997 - decoder_loss: 0.0726 - capsnet_acc: 0.9493 - val_loss: 0.6053 - val_capsnet_loss: 0.5739 - val_decoder_loss: 0.0802 - val_capsnet_acc: 0.8000\n",
      "Epoch 36/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2250 - capsnet_loss: 0.1964 - decoder_loss: 0.0730 - capsnet_acc: 0.9511\n",
      "Epoch 00036: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2249 - capsnet_loss: 0.1963 - decoder_loss: 0.0730 - capsnet_acc: 0.9512 - val_loss: 0.5568 - val_capsnet_loss: 0.5252 - val_decoder_loss: 0.0806 - val_capsnet_acc: 0.8167\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2253 - capsnet_loss: 0.1969 - decoder_loss: 0.0724 - capsnet_acc: 0.9508\n",
      "Epoch 00037: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2252 - capsnet_loss: 0.1968 - decoder_loss: 0.0724 - capsnet_acc: 0.9508 - val_loss: 0.6188 - val_capsnet_loss: 0.5873 - val_decoder_loss: 0.0804 - val_capsnet_acc: 0.8167\n",
      "Epoch 38/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2231 - capsnet_loss: 0.1948 - decoder_loss: 0.0723 - capsnet_acc: 0.9513\n",
      "Epoch 00038: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.2232 - capsnet_loss: 0.1949 - decoder_loss: 0.0723 - capsnet_acc: 0.9513 - val_loss: 0.5908 - val_capsnet_loss: 0.5592 - val_decoder_loss: 0.0807 - val_capsnet_acc: 0.8333\n",
      "Epoch 39/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2314 - capsnet_loss: 0.2029 - decoder_loss: 0.0727 - capsnet_acc: 0.9488\n",
      "Epoch 00039: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2317 - capsnet_loss: 0.2032 - decoder_loss: 0.0727 - capsnet_acc: 0.9486 - val_loss: 0.6051 - val_capsnet_loss: 0.5738 - val_decoder_loss: 0.0798 - val_capsnet_acc: 0.8167\n",
      "Epoch 40/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2237 - capsnet_loss: 0.1951 - decoder_loss: 0.0730 - capsnet_acc: 0.9520\n",
      "Epoch 00040: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2237 - capsnet_loss: 0.1951 - decoder_loss: 0.0730 - capsnet_acc: 0.9520 - val_loss: 0.6420 - val_capsnet_loss: 0.6105 - val_decoder_loss: 0.0802 - val_capsnet_acc: 0.8333\n",
      "Epoch 41/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2193 - capsnet_loss: 0.1908 - decoder_loss: 0.0729 - capsnet_acc: 0.9540\n",
      "Epoch 00041: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2192 - capsnet_loss: 0.1907 - decoder_loss: 0.0729 - capsnet_acc: 0.9541 - val_loss: 0.6175 - val_capsnet_loss: 0.5858 - val_decoder_loss: 0.0808 - val_capsnet_acc: 0.8167\n",
      "Epoch 42/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2191 - capsnet_loss: 0.1911 - decoder_loss: 0.0715 - capsnet_acc: 0.9541\n",
      "Epoch 00042: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.2190 - capsnet_loss: 0.1910 - decoder_loss: 0.0715 - capsnet_acc: 0.9542 - val_loss: 0.5861 - val_capsnet_loss: 0.5548 - val_decoder_loss: 0.0800 - val_capsnet_acc: 0.8500\n",
      "Epoch 43/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2242 - capsnet_loss: 0.1957 - decoder_loss: 0.0727 - capsnet_acc: 0.9511\n",
      "Epoch 00043: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2243 - capsnet_loss: 0.1959 - decoder_loss: 0.0727 - capsnet_acc: 0.9510 - val_loss: 0.6059 - val_capsnet_loss: 0.5745 - val_decoder_loss: 0.0801 - val_capsnet_acc: 0.8000\n",
      "Epoch 44/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2183 - capsnet_loss: 0.1901 - decoder_loss: 0.0720 - capsnet_acc: 0.9543\n",
      "Epoch 00044: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2184 - capsnet_loss: 0.1901 - decoder_loss: 0.0720 - capsnet_acc: 0.9543 - val_loss: 0.6274 - val_capsnet_loss: 0.5958 - val_decoder_loss: 0.0805 - val_capsnet_acc: 0.8167\n",
      "Epoch 45/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2192 - capsnet_loss: 0.1911 - decoder_loss: 0.0718 - capsnet_acc: 0.9555\n",
      "Epoch 00045: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2192 - capsnet_loss: 0.1911 - decoder_loss: 0.0718 - capsnet_acc: 0.9555 - val_loss: 0.5969 - val_capsnet_loss: 0.5651 - val_decoder_loss: 0.0809 - val_capsnet_acc: 0.8333\n",
      "Epoch 46/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2157 - capsnet_loss: 0.1875 - decoder_loss: 0.0718 - capsnet_acc: 0.9540\n",
      "Epoch 00046: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2156 - capsnet_loss: 0.1875 - decoder_loss: 0.0718 - capsnet_acc: 0.9540 - val_loss: 0.6240 - val_capsnet_loss: 0.5925 - val_decoder_loss: 0.0802 - val_capsnet_acc: 0.8167\n",
      "Epoch 47/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2190 - capsnet_loss: 0.1907 - decoder_loss: 0.0720 - capsnet_acc: 0.9535\n",
      "Epoch 00047: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2190 - capsnet_loss: 0.1908 - decoder_loss: 0.0720 - capsnet_acc: 0.9534 - val_loss: 0.6181 - val_capsnet_loss: 0.5867 - val_decoder_loss: 0.0802 - val_capsnet_acc: 0.8167\n",
      "Epoch 48/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2261 - capsnet_loss: 0.1978 - decoder_loss: 0.0721 - capsnet_acc: 0.9484\n",
      "Epoch 00048: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2260 - capsnet_loss: 0.1978 - decoder_loss: 0.0721 - capsnet_acc: 0.9485 - val_loss: 0.6060 - val_capsnet_loss: 0.5747 - val_decoder_loss: 0.0798 - val_capsnet_acc: 0.8167\n",
      "Epoch 49/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2148 - capsnet_loss: 0.1867 - decoder_loss: 0.0716 - capsnet_acc: 0.9561\n",
      "Epoch 00049: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2147 - capsnet_loss: 0.1867 - decoder_loss: 0.0716 - capsnet_acc: 0.9562 - val_loss: 0.6026 - val_capsnet_loss: 0.5713 - val_decoder_loss: 0.0798 - val_capsnet_acc: 0.8167\n",
      "Epoch 50/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2108 - capsnet_loss: 0.1830 - decoder_loss: 0.0710 - capsnet_acc: 0.9577\n",
      "Epoch 00050: val_capsnet_acc did not improve\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2108 - capsnet_loss: 0.1830 - decoder_loss: 0.0710 - capsnet_acc: 0.9577 - val_loss: 0.5975 - val_capsnet_loss: 0.5661 - val_decoder_loss: 0.0801 - val_capsnet_acc: 0.7833\n",
      "Trained model saved to './result/trained_model.h5'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAG0CAYAAADgu5hjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhlYpXuL7EyAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x208495c00b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x20825a227b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnet.train(model=model, data=(train_generator, (x_test, y_test)), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('E:\\\\trained_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 24, 24, 12, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv3D)                  (None, 17, 17, 5, 25 393472      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 5, 25 1024        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 17, 17, 5, 25 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv3d (Conv3D)      (None, 7, 7, 1, 128) 4096128     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 784, 8)       0           primarycap_conv3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 784, 8)       0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 6, 8)         301056      primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_8 (Mask)                   (None, 48)           0           digitcaps[0][0]                  \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 6)            0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 24, 24, 12, 3 12038723    mask_8[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,830,403\n",
      "Trainable params: 16,829,891\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = keras.models.load_model('E:\\\\trained_model2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('E:\\\\trained_model2.h5')\n",
    "eval_model.load_weights('result2\\\\weights-35.h5')\n",
    "manipulate_model.load_weights('result2\\\\weights-35.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./result/weights-35.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C.classes_to_include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "for i in range(6):\n",
    "    cnet.manipulate_latent(manipulate_model, (x_test, y_test), args, i, multislice=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "cnet.test(model=eval_model, data=(x_test, y_test), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = layers.Input([28,28,1])\n",
    "x = layers.Conv2D(4,kernel_size=9,strides=1)(a)\n",
    "x = layers.Conv2D(4,kernel_size=9,strides=2)(x)\n",
    "b = x\n",
    "model = Model(a,b)\n",
    "model.summary(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "input_51 (InputLayer)                        (None, 24, 24, 12, 3)                   0              \n",
      "____________________________________________________________________________________________________\n",
      "instance_normalization_3 (InstanceNormalizat (None, 24, 24, 12, 3)                   6              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)                         (None, 20736)                           0              \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                             (None, 128)                             2654336        \n",
      "____________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)                         (None, 128, 1, 1, 1, 1)                 0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistributed)        (None, 128, 11, 11, 6, 64)              46528          \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistributed)        (None, 128, 24, 24, 12, 64)             131136         \n",
      "====================================================================================================\n",
      "Total params: 2,832,006\n",
      "Trainable params: 2,832,006\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a = layers.Input(shape=[24,24,12,3])\n",
    "x = InstanceNormalization(axis=4)(a)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Reshape(target_shape=(128,1,1,1,1))(x)\n",
    "x = layers.TimeDistributed(layers.Conv3DTranspose(filters=64, kernel_size=[11,11,6], strides=1, padding='valid', activation='relu'))(x)\n",
    "x = layers.TimeDistributed(layers.Conv3DTranspose(filters=64, kernel_size=[4,4,2], strides=2, padding='valid', activation='relu'))(x)\n",
    "#x = layers.Reshape((3, 24, 24, 12))(x)\n",
    "#x = layers.Permute((2,3,4,1))(x)\n",
    "b = x\n",
    "model = Model(a,b)\n",
    "\n",
    "model.summary(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C_list = [config.Config(), config.Config()]\n",
    "C_list[0].dims = [36,36,12]\n",
    "C_list[1].dims = [24,24,12]\n",
    "C_list[0].artif_dir = \"E:\\\\imgs\\\\artif_imgs_3612\\\\\"\n",
    "C_list[1].artif_dir = \"E:\\\\imgs\\\\artif_imgs_2412\\\\\"\n",
    "C_list[0].aug_dir = \"E:\\\\imgs\\\\aug_imgs_3612_cropint\\\\\"\n",
    "C_list[1].aug_dir = \"E:\\\\imgs\\\\aug_imgs_2412_cropint\\\\\"\n",
    "C_list[0].orig_dir = \"E:\\\\imgs\\\\orig_imgs_3612_cropint\\\\\"\n",
    "C_list[1].orig_dir = \"E:\\\\imgs\\\\orig_imgs_2412_cropint\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_reader = ['E103312835_1','12823036_0','12569915_0','E102093118_0','E102782525_0','12799652_0','E100894274_0','12874178_3','E100314676_0','12842070_0','13092836_2','12239783_0','12783467_0','13092966_0','E100962970_0','E100183257_1','E102634440_0','E106182827_0','12582632_0','E100121654_0','E100407633_0','E105310461_0','12788616_0','E101225606_0','12678910_1','E101083458_1','12324408_0','13031955_0','E101415263_0','E103192914_0','12888679_2','E106096969_0','E100192709_1','13112385_1','E100718398_0','12207268_0','E105244287_0','E102095465_0','E102613189_0','12961059_0','11907521_0','E105311123_0','12552705_0','E100610622_0','12975280_0','E105918926_0','E103020139_1','E101069048_1','E105427046_0','13028374_0','E100262351_0','12302576_0','12451831_0','E102929168_0','E100383453_0','E105344747_0','12569826_0','E100168661_0','12530153_0','E104697262_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cnet)\n",
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(crun)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()\n",
    "#T.steps_per_epoch = 50\n",
    "#T.epochs= 1\n",
    "#T.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crun.run_fixed_hyperparams([C], hyperparams=T)#C_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                       Output Shape                                                Param #                \n",
      "======================================================================================================================================================\n",
      "input_46 (InputLayer)                                              (None, 24, 24, 12, 3)                                       0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "reshape_41 (Reshape)                                               (None, 24, 24, 12, 3, 1)                                    0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "permute_41 (Permute)                                               (None, 3, 24, 24, 12, 1)                                    0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_544 (TimeDistributed)                             (None, 3, 24, 24, 12, 128)                                  4224                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_545 (TimeDistributed)                             (None, 3, 24, 24, 12, 128)                                  0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_178 (Activation)                                        (None, 3, 24, 24, 12, 128)                                  0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_546 (TimeDistributed)                             (None, 3, 24, 24, 12, 128)                                  512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_547 (TimeDistributed)                             (None, 3, 12, 12, 6, 128)                                   0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_548 (TimeDistributed)                             (None, 3, 9, 9, 5, 128)                                     524416                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_549 (TimeDistributed)                             (None, 3, 9, 9, 5, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_179 (Activation)                                        (None, 3, 9, 9, 5, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_550 (TimeDistributed)                             (None, 3, 9, 9, 5, 128)                                     512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_551 (TimeDistributed)                             (None, 3, 6, 6, 4, 128)                                     524416                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_552 (TimeDistributed)                             (None, 3, 6, 6, 4, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_180 (Activation)                                        (None, 3, 6, 6, 4, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_553 (TimeDistributed)                             (None, 3, 6, 6, 4, 128)                                     512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_554 (TimeDistributed)                             (None, 3, 3, 3, 3, 128)                                     524416                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_555 (TimeDistributed)                             (None, 3, 3, 3, 3, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_181 (Activation)                                        (None, 3, 3, 3, 3, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_556 (TimeDistributed)                             (None, 3, 3, 3, 3, 128)                                     512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_557 (TimeDistributed)                             (None, 3, 3, 3, 3, 128)                                     0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_558 (TimeDistributed)                             (None, 3, 3456)                                             0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "simple_rnn_41 (SimpleRNN)                                          (None, 128)                                                 458880                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchNormalization)                       (None, 128)                                                 512                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)                                              (None, 128)                                                 0                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_33 (Dense)                                                   (None, 6)                                                   774                    \n",
      "======================================================================================================================================================\n",
      "Total params: 2,039,686\n",
      "Trainable params: 2,038,406\n",
      "Non-trainable params: 1,280\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cbuild.build_cnn_hyperparams(T)\n",
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0)#, Z_test_fixed=Z_reader)\n",
    "Z_test, Z_train_orig = Z\n",
    "X_train_orig, Y_train_orig = train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils import multi_gpu_model\n",
    "#model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator, steps_per_epoch=T.steps_per_epoch, epochs=T.epochs, validation_data=[X_test, Y_test])#, callbacks=[T.early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('E:\\\\models\\\\model_reader_rcnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df_art, voi_df_ven, voi_df_eq = drm.get_voi_dfs()\n",
    "small_voi_df = pd.read_csv(C.small_voi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916666666667\n",
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "#plot_with_bbox(fn_list[2], cls_mapping[wrong_guesses[2]])\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#save_output(Z_test, y_pred, y_true)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)\n",
    "print(accuracy_score(y_true_simp, y_pred_simp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc6cls = []\n",
    "acc3cls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test_fixed=Z_reader)\n",
    "Z_test, Z_train_orig = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E100610622_0', 'E100314676_0', '13112385_1', 'E100718398_0',\n",
       "       '12530153_0', '12451831_0', '12569826_0', '13028374_0',\n",
       "       '12207268_0', '12302576_0', '12324408_0', '12888679_2',\n",
       "       '12961059_0', '12975280_0', 'E100183257_1', 'E100962970_0',\n",
       "       'E101083458_1', 'E103312835_1', 'E104697262_0', 'E105311123_0',\n",
       "       'E102782525_0', 'E101415263_0', 'E100192709_1', 'E103192914_0',\n",
       "       'E100383453_0', '12552705_0', 'E105244287_0', 'E105918926_0',\n",
       "       'E106182827_0', '13092836_2', '12582632_0', 'E103020139_1',\n",
       "       '12569915_0', 'E102093118_0', 'E102929168_0', 'E102634440_0',\n",
       "       'E105310461_0', 'E105427046_0', 'E102613189_0', 'E102095465_0',\n",
       "       'E100262351_0', 'E106096969_0', 'E101225606_0', 'E101069048_1',\n",
       "       'E105344747_0', 'E100407633_0', '13092966_0', '12783467_0',\n",
       "       '13031955_0', 'E100894274_0', '12874178_3', '12239783_0',\n",
       "       '12788616_0', '11907521_0', '12823036_0', '12842070_0',\n",
       "       'E100168661_0', 'E100121654_0', '12678910_1', '12799652_0'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test=Z_reader)\n",
    "Z_test, Z_train_orig = Z\n",
    "Y_pred = model.predict(X_test)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_test])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = [C.classes_to_include[y] for y in y_pred]\n",
    "Y_true = [C.classes_to_include[y] for y in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame([Z_test,Y_pred,Y_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.to_csv('E:\\\\hi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(19):\n",
    "    model_num = 306+i\n",
    "    X_test, Y_test, train_generator, num_samples, train_orig, Z = cbuild.get_cnn_data(n=4, n_art=0, Z_test=df[df['model_num'] == model_num][\"z_test\"])\n",
    "    X_train_orig, Y_train_orig = train_orig\n",
    "    model = keras.models.load_model(os.path.join(C.model_dir, \"models_%d.hdf5\" % model_num)) #models_305\n",
    "    \n",
    "    Y_pred = model.predict(X_train_orig)\n",
    "    y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "    y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "    acc6cls.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    y_true_simp, y_pred_simp, _ = cbuild.merge_classes(y_true, y_pred)\n",
    "\n",
    "    acc3cls.append(accuracy_score(y_true_simp, y_pred_simp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Z:\\\\Inter-reader study\\\\Answer key.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df[\"Class\"].values\n",
    "y_pred = df[\"Model\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=C.classes_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\t0\t1\t0\t0\t1\n",
      "0\t9\t1\t0\t0\t0\n",
      "0\t1\t8\t0\t0\t0\n",
      "0\t0\t0\t10\t0\t0\n",
      "0\t0\t0\t0\t9\t0\n",
      "0\t0\t0\t0\t1\t9\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cm)):\n",
    "    print('\\t'.join(cm[:,i].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_list = fn_list + list(Z_test[~np.equal(y_pred, y_true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_list = fn_list + list(Z_train_orig[~np.equal(y_pred, y_true)])\n",
    "fn_list = fn_list + list(Z_train_orig[~np.equal(y_pred, y_true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_x_list = [x+\"(\"+str(voi_df_art[voi_df_art[\"id\"] == x[:-4]][\"x1\"].values[0])+\")\" for x in fn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(fn_x_list, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_train_orig)\n",
    "y_true = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_train_orig])\n",
    "y_pred = np.array([max(enumerate(x), key=operator.itemgetter(1))[0] for x in Y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "#cbuild.save_output(Z_train_orig, y_pred, y_true)#, save_dir=C.output_img_dir+\"\\\\training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305\n",
    "#cnna.visualize_layer(model, 'conv3d_148')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dense_outputs = cbuild.build_pretrain_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_results = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "\n",
    "filter_avgs = np.concatenate([filter_results[cls] for cls in C.classes_to_include], axis=0)\n",
    "filter_avgs = np.mean(filter_avgs, axis=0)\n",
    "\n",
    "filter_cls_avg_unscaled = {cls: np.mean(filter_results[cls], axis=0) for cls in C.classes_to_include}\n",
    "filter_cls_avg_scaled = {cls: np.mean(filter_results[cls], axis=0) / filter_avgs for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters.csv', 'w', newline='') as csvfile:\n",
    "    header = ['filter_num'] + C.classes_to_include\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [filter_cls_avg_scaled[cls][f_num] for cls in C.classes_to_include])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.flatten([list(feature_sheet[\"evidence1\"+cls].dropna().values) for cls in C.classes_to_include]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_sheet = pd.read_excel(C.xls_name, \"Descriptions\")\n",
    "\n",
    "features_by_cls = {}\n",
    "feat_count = {}\n",
    "for cls in C.classes_to_include:\n",
    "    features_by_cls[cls] = list(feature_sheet[\"evidence1\"+cls].dropna().values)\n",
    "    features_by_cls[cls] = features_by_cls[cls] + list(feature_sheet[\"evidence2\"+cls].dropna().values)\n",
    "#all_features = list(set([f for cls in features for f in features[cls]]))\n",
    "\n",
    "feat_count = dict(zip(*np.unique([f for cls in features_by_cls for f in features_by_cls[cls]], return_counts=True)))\n",
    "all_features = list(feat_count.keys())\n",
    "#for cls in C.classes_to_include:\n",
    "#    features_by_cls[cls] = list(set(features_by_cls[cls]))\n",
    "\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous enhancing rim (5)\n",
      "progressive or concentric enhancement (5)\n",
      "regular spherical hypointense mass (5)\n"
     ]
    }
   ],
   "source": [
    "z = dict(zip(*np.unique(features_by_cls['colorectal'], return_counts=True)))\n",
    "for k in z:\n",
    "    print(k, \" (\",z[k],\")\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arterial enhancement': 10,\n",
       " 'central scar': 5,\n",
       " 'continuous enhancing rim': 10,\n",
       " 'delayed isointensity': 10,\n",
       " 'heterogeneous': 10,\n",
       " 'hyperintense mass on delayed phase': 10,\n",
       " 'hypointense without enhancement': 10,\n",
       " 'infiltrative': 10,\n",
       " 'lobulated margins': 10,\n",
       " 'nodular or discontinuous enhancement': 10,\n",
       " 'progressive centripetal filling': 10,\n",
       " 'progressive or concentric enhancement': 10,\n",
       " 'regular spherical hypointense mass': 10,\n",
       " 'thin well-defined walls': 10,\n",
       " 'venous washout': 10}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in [c for c in feature_sheet.columns if c.startswith(\"evidence\")]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_features_by_cls = {cls: {} for cls in features_by_cls}\n",
    "Z_features = {}\n",
    "\n",
    "for cls in C.classes_to_include:\n",
    "    for f in features_by_cls[cls]:\n",
    "        if f not in Z_features:\n",
    "            Z_features[f] = []\n",
    "            \n",
    "        Z_features_by_cls[cls][f] = [x for x in feature_sheet[feature_sheet[\"evidence1\"+cls] == f][cls].values]\n",
    "        Z_features[f] += [x for x in feature_sheet[feature_sheet[\"evidence1\"+cls] == f][cls].values]\n",
    "        if feature_sheet[\"evidence2\"+cls].dropna().size > 0:\n",
    "            Z_features_by_cls[cls][f] = Z_features_by_cls[cls][f] + [x+\".npy\" for x in feature_sheet[feature_sheet[\"evidence2\"+cls] == f][cls].values]\n",
    "            Z_features[f] += [x for x in feature_sheet[feature_sheet[\"evidence2\"+cls] == f][cls].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_filters = {f:np.empty([0,100]) for f in all_features}#{cls: {} for cls in features}\n",
    "feature_filters_scaled = {}#{cls: {} for cls in features}\n",
    "\n",
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs\n",
    "        \n",
    "    feature_filters[f] = np.mean(feature_filters[f], axis=0)# / filter_avgs\n",
    "\n",
    "    #ff = feature_filters[f]\n",
    "    #feature_filters[f] = np.where(ff > np.mean(ff), ff, 0)\n",
    "\n",
    "    #ff = feature_filters[cls][f]\n",
    "    #feature_filters[cls][f] = np.where(ff > 1*filter_cls_avg_unscaled[cls], ff, 0)\n",
    "\n",
    "    #ff = feature_filters[f]\n",
    "    #feature_filters[f] = np.where(ff > 1.3*filter_avgs, ff, 0)\n",
    "\n",
    "    feature_filters_scaled[f] = feature_filters[f] / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regular spherical hypointense mass',\n",
       " 'hyperintense mass on delayed phase',\n",
       " 'delayed isointensity',\n",
       " 'thin well-defined walls',\n",
       " 'infiltrative',\n",
       " 'nodular or discontinuous enhancement',\n",
       " 'lobulated margins',\n",
       " 'progressive or concentric enhancement',\n",
       " 'arterial enhancement',\n",
       " 'progressive centripetal filling',\n",
       " 'heterogeneous',\n",
       " 'central scar',\n",
       " 'venous washout',\n",
       " 'continuous enhancing rim',\n",
       " 'hypointense without enhancement']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_filters['arterial enhancement'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta = np.array([feature_filters[f] for f in all_features])\n",
    "Theta = np.transpose(Theta, (1,0))\n",
    "Theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features_cls = header[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)\n",
    "    features_test[cls] = np.linalg.lstsq(Theta, np.transpose(filters_test[cls], (1,0)))[0]\n",
    "    #filters_test[cls] = np.apply_along_axis(lambda x: x / filter_avgs, 1, filters_test[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_evidence_strength(feature_filters, pred_filters):\n",
    "    \"\"\"A good pred_filter has high values for all the key (non-zero) features of feature_filter.\n",
    "    These values should be unscaled.\n",
    "    Returns average percentage of the mean value of the key filters (capped at 100%)\"\"\"\n",
    "    \n",
    "    strength = 0\n",
    "    num_key_filters = sum(feature_filters > 0)\n",
    "    \n",
    "    for i in range(len(pred_filters)):\n",
    "        t = feature_filters[i]\n",
    "        p = pred_filters[i]\n",
    "        \n",
    "        if t == 0:\n",
    "            continue\n",
    "            \n",
    "        strength += min(p/t, 1.1)#t*p / filter_avgs[i]**.7\n",
    "    return (strength / num_key_filters / 1.1)**.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "max_strength = 0\n",
    "\n",
    "#cls = true_cls\n",
    "\"\"\"for f in features[cls]:\n",
    "    evidence[f] = get_evidence_strength(feature_filters[cls][f], filters_test[cls][img_num])\n",
    "    max_strength = max(max_strength, evidence[f])\n",
    "\"\"\"\n",
    "#for cls in C.classes_to_include:\n",
    "\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACFCAYAAABsdIKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEWpJREFUeJztnUtzFEcWhW+3HoANQjwkZPMQwYIIb+fXe+lfMDv2dgDm\nIQHmZRts1LNwTITr5GnqVFkEOcz37Sojqyozb9aN7nvyZi5Wq1UBAMDnZ/m5GwAAAH+BQwYA6AQc\nMgBAJ+CQAQA6AYcMANAJOGQAgE7AIQMAdAIOGQCgE3DIAACdgEMGAOiEzSmVl8vlarn8uA9fLBbu\nvqjenDrps7UsefY/IUlJd23Y3Bw3yYcPHya///Xr17PG4DTH8rTuc8wd77nvP835c3Jy8tHrqqr3\n7983c/207JeS2G/ufPmU3+xpvs/NMy1zdV69enW8Wq32xto61SHX+fPnhw8QB7K1tdXcd+bMmfbF\nct/GxoZ939h929vbTZ2kzL3PlalREoNUZU7TOd/d3d3BtRuD169fj77vjz/+GFz/8MMPjW30/a49\nSZkbN3ef1kvqVJ2eQ07nmJKOiz7LOVZX9u7du8H1b7/91tT58ccf6+uvv/7o++a2M/0RldjPff/6\n7Z3mN5vMjbSdybx280y/tffv3zd1vv/++59GG1qELAAAugGHDADQCZNCFltbW3Xz5s3hA4K/ve7v\niP4lcn8P3H0a/nDhkOSvaRqPSuJ7f/75Z1OmIQT3F9D1b2dnZ/Q+93drrJ3b29t1eHj40efM/Uvv\nSMIYznaub+5ZShJKcmGk5D7XJlem96UhC/3L+/vvvzd1Hj58WPv7+4OyueFCnftpyCkJFybffxKK\ndO1Kw4VaNjek5nyEs5+ShCvXwS9kAIBOwCEDAHQCDhkAoBMmxZDPnDlTd+7cGZQlsWAXM9KyNMaq\nZXOXTrm4r4tHacwojStpXNDF8r766quoTNHlT64N2pezZ8/W3bt3B2U6dmlcfe6aX7VLsrTK1UvX\nh+qYuNies10yp928S/QGx9iSxaqqe/fu1fXr1wdl+i2ksW7tT6LVuGed5jK7xH5pTH5uDDnBtXOu\nzuLgFzIAQCfgkAEAOgGHDADQCThkAIBOmCzq3b59+6N10s1+kkXYybNcUD8Rp5yol7QhSVKoaoUZ\nJ9bpviBVrcDi+nf27NnRdiqJIPupN1zSvric/0QwTIQjh3u267OKV04Yc/epzVPhOEko2d7ebpKy\nkj0i3Ljo/ElFvbn7zyT7wbixmivKKsm+FVWt/dL3Jb4shV/IAACdgEMGAOgEHDIAQCfgkAEAOmHy\nbm83btwYlGmAPt3JaW6gX3fC+vXXX5s6iXCSZgaqGJf0paoVBM6dO9fUcaKeChBORHDPGst83N7e\nrlu3bg3K5m7qnogYThDRjdfdRvtupzMdAyc4OdslmWXuPhW90h0F37x5M7jWjeercqHPtVPtl4iP\nrs9J/+Z+s8lJHEl2nauXZuq5ua+4MvUlbi66LMok6ziFX8gAAJ2AQwYA6AQcMgBAJ0yKIW9ubtaV\nK1cGZRrDSU+40BjVmpNamzKNTbr7XOxO25kmF2iscO5udul9Scw6OfnC9Vdtp/ckCTxV2QkQb9++\nbcr0+c5ODu1LuquZxkbdLnkujq9lLhEniSG7w0qd7TSuvC4xRGPISezStVPnmIshu1i39sfZeO6h\nuHNJvqtEX6hq7ez0KbVxVXZqUgq/kAEAOgGHDADQCThkAIBOwCEDAHTCpOjzcrlskhKS41KShedO\nyHCiiNZzi7dfvnzZlOnOYi7Q70QKFRbnCkpOwHJliRDlRCbtnz57c3Ozrl69OihLRL2kv06oShbV\nO9EkSZxwu8S5eafzxy3qd6Kwzo10pz61nWuna0OyS9zW1lZdu3atKf87zn7pEWdjbapqbeq+s2QO\npbsVqm3SI6O0zM1h976LFy8Orp3dk8UAJIYAAHwB4JABADoBhwwA0Ak4ZACATpgk6i0WCyuGDR5o\ngt7J7mRORHBCnwolToh78eJFU6Y7i6WZekmWkRMpVCBIhL+qqgsXLgyuL126NFqnqhVcVFxxot7c\nLEsVW5z46gQtFUifP3/e1HHzQEVDJyImx+Y4gVTtVOUFScXNaZ0Hro4T7HSs3BhsbGzU5cuXB2Vz\n7ZeIq24nvuPj48H106dPmzquf4obF2c/nWfuO0vKdnZ2mjruu9JMVjdf3BirHZLd+9bBL2QAgE7A\nIQMAdAIOGQCgEybHkMd2MkpOYKhq44AubucSJzRmnMS6qtp4ZXpqgeLil65/uojf1XExqr29vcH1\nwcFBU8fFBceOTE9ikGliiMYc3Q5Ybqe+o6OjwfXDhw+bOm4eaFlyZLzDzU2X4KFj7trkxkVt7p6d\nnF6xLoas2oGzseLm3S+//DK4dv1TW1VV3b9/f3D96NGjpo6bCxojTxMn9Ht04+m+IS1z35DunFdV\ntbu7O7h2Wo1re5LYk8IvZACATsAhAwB0Ag4ZAKATcMgAAJ0wWdQbO9LIJTu4MhUS0h3DVMRzSSBO\nWND7XOKCa4OKRelOY7oTlhMINFHD3efGwAlYKsglu2fNPZ5KRb1ERK1qhaIHDx6MPruqFXedDRJB\nNk3O0f64Z7udwNTGro6bY8nuZK4dKga6+5yIqPPHCeOPHz9uylTUc/Zz357O4eTIs6p2PjrR2fVP\nx90lj7n79vf3B9dJQltVO+7/5IgqfiEDAHQCDhkAoBNwyAAAnYBDBgDohEminn2ACBJpRpoKM068\ncgKP7iyWZHZVZdk0SQaYE5ScyKZtcFmHTiDQDDc3Bq4NKng4YUHbqbZz7XFCSiLqOaFIBUt3nxun\nxHZOeNOyVPTSOaZiT5XvX5KhlbRzXSbbWH+cQOnmgc5NJ8A+e/asKVN7ufuS+eralJS578yNlQqL\nSUZsVSv+OXu6MdY2JDsProNfyAAAnYBDBgDoBBwyAEAnnHoM2cVY3AJrjUe53cFcnE7jQ+lpFbog\nPzkdpKqNI7k4pFvsr/e52GgSN09jyDruyeJ0HYMk7lzV2kB3D6vydtH+ugX7bqczjZ0mcdiqtu0u\nXuzuU1s5OyXJKS6WmOx05uaTe57OxeR0l6p2Trl4sZt3Og7Oxon90hhrsoOf619yqlAyZ10M2Wlk\npwm/kAEAOgGHDADQCThkAIBOwCEDAHTCZFFPRQkVwpwwNDe54MmTJ6NlTpDQBISqVpBwO3Elu1Cl\n92mfk6N7qlpBx4kkidjhFqvr+1RsdXZKdu9ydZJF/MnR7+5ZqXilY+kSBJzgrO9Lkivc+9Jdzcbe\nX/XXWGm/te1uXJzwlhyD5gRuFbTcmCe7trl57+aCjoOzlWun3pccu1TVioHJznzufRzhBADwBYBD\nBgDoBBwyAEAn4JABADphkqi3XC4bYUQD/S5g7wLhiRiYHMvj7nNZVCpkuGe7LBzNgHOCy7rMqrF2\nOvT5SRZg1fjxTMvlshEkVSRJd1HTNrk2uv7qWDqRJtntzQlASVZcmiGm96XHi2k73dgl2YLODovF\nopmfOn5zxUdXxwnjKt4mQlzV+NxcVzZ31zTtn/MHSSaps7uzn9or8Qfr4BcyAEAn4JABADoBhwwA\n0AmTYsibm5u1u7s7KEtOLXAxZI1nXrx4cbROVRs3c3VcG9zuVQkaT0xinFVZ/NvFtvT57n3rYox/\nR+2yXC5H4/0uZjc3/u9iiVrvwoULTR0X29MxcGObxBvdWDr0Wc5Oie3mJhasS6pR+7l5rrhkES1L\ndjmsasfdvT/VPMae7UiSOaraWLCbny4ZRnUm975EC0oSt9bBL2QAgE7AIQMAdAIOGQCgE3DIAACd\nMEnU29jYqCtXrgzKkkXfTlhQEe/g4KCpc/ny5aZMj15xAXS30F3blR6vkwg87n0JThSZe0TV2O5y\nbrewRKBwyRsqpLqEmkTo1LlU5cdyriikcyNJBqhqRa4kuaKqtYsbg2S3t3XzUG2q7XRz2s0xFVN3\ndnaaOs7uWpbu9qZiZ3oMmo5fKq4mSWCuzyr0ufni2un6Mxd+IQMAdAIOGQCgE3DIAACdgEMGAOiE\nyaLe+fPnB2UaMHcBdFd29erVwbUTJB4/ftyUqUDgdl9yR/UkAXsn3mg9JzAlYqDLKHSZairUuPc5\nIUNx46Jou53I59qotrt27VpT5+nTp02Z7iDmBBJ9dlUrGrrxdpmY+j43D12fk7Fzx1Y9f/58cP3q\n1aumjhOqEzs4UVbnmLvPiXMqpt64caOp4749/T6cYHjp0qWmTOewim7u2el9TjhNMhEdumDgxYsX\nn/R9Dn4hAwB0Ag4ZAKATcMgAAJ0wP9ixhiSeWtXGn1zc7rvvvmvKNCb26NGjpo6LJyZHn7uYn9Y7\nPj4ereNwyRMuPqsL1pNTTKrGkwRWq1UTs9XEieTo96qqvb29wfWtW7eaOm6cNP7v5oqL/ycnQGj8\ntqrtz7pd1BTts+5wWOU1ASU9gUVtlZ6Uof1JTmmpqtrf3x9c37lzp6nz5MmTpkz7404VcUkS2p9k\np7WqNq7s5mJycovqXuvKdC64eea0A51n/yRRhF/IAACdgEMGAOgEHDIAQCfgkAEAOmGSqLdarezC\n6L/jhAUnFqmI58QHJzZoMN4lEswV9VzAXoU+t2BeF5RXtUKUC/Q7YUj74xIJkoQSFXxWq1Ujyqho\n4cQk125d/O9EvaOjo6ZMx8SJNMkOdM6+bkz0+cmucVWtsKgiWFUrbFa19kz6MgW1j/YnTXLROebE\nKyfK6vNd8o/71rXdyffp6rlvNkkocckx7sg49S1uPN37ku8ohV/IAACdgEMGAOgEHDIAQCfgkAEA\nOmGSqHdyctJkWzUPNEH95NgaJx45wU5FCieMueB/smubC9irsPDzzz83dZ49ezb6PjcGTsjUndO+\n+eabpo7LZlMBwu3CNyZquSwyh475t99+29RxWVza7sROVa1dXB0n6mk7nSDtBBgVA908dEKf7qLm\n7OTel+yYuFgsmjmk9nTPdqKejtXNmzebOk7oU4HZCdxOsFN7OR+SfHtOPE+OT3PiscvUU5sm4nlV\nK1an4rGDX8gAAJ2AQwYA6AQcMgBAJ0ze7U3jJUn8y6ExTxdjdfEvXdDt6ri4si48T48U13iXiz25\nWKjGUNMj2nVnMZcY4vqn4+kSQzSGqtcu9uVO9dB2u34cHh42Zdo3t7ueS87RWKKLUyYL/ceSmv6L\n6hlutzeXGKKxdHd6hkO/GZeQcHJyYmPnWkdxz9L+uW/o4OCgKVM7u7nptIO5p/VoWaLVVLV9dt+L\n7qpY1fbH2d1pXfo+EkMAAL4AcMgAAJ2AQwYA6AQcMgBAJ0ze7W1M1EsTLpzopLgF3bow2y3eTo6y\ncWKAE/W0P04gcEKfikypaKk7UyVj4HDCwpjtnIDnhDCt50Q9NybaFyfEOcFOy9zOYMkxPa4vbt7p\n/HFzzAl2WuZs5+aY2srZ9+TkpPmOdE65viTflZuHbjy1nhPGkmPQ0l3btMwl2rj5kiSPubarnd19\niHoAAP8n4JABADoBhwwA0Ak4ZACATpicqTcmBDnRIjlmxWUZOZFJRS8nKLlgvAolTjhxu1Alx7M4\nEVHb4N7nBIJEEHBjpffptRNkFScAJUKnq+MELe2vs5MT0HT+OFHPHdOjz3f9d2OpYlkq5Lo+K64N\n6VFPY0c2Ofsl2ZeuTUkGrBPZ3LgkRzElu8Q5O7hvNplnif3WiauKjnGarezgFzIAQCfgkAEAOgGH\nDADQCZNiyIvFooktaewnjSFr/MvFa1z8S2NGLj7kYnna7jSWp/elsWdNQnCx4SR5w7UzaXtyHHuS\nWOBskOy+5uyiZWnSi96XLM53ZW7cXJ91XFw81ZVpfNG9L5kHaQxS25nMp6o2Nuu+WReTV73G2cFp\nOjpWrk5yioibU67tOofc+9zcSxKlXAx57DlT4BcyAEAn4JABADoBhwwA0Ak4ZACATlhMCUAvFouj\nqvrp0zUHPiH/qqp/f+5GwGyw3/82h6vVqj33S5jkkAEA4NNByAIAoBNwyAAAnYBDBgDoBBwyAEAn\n4JABADoBhwwA0Ak4ZACATsAhAwB0Ag4ZAKAT/gO7tAR8B/ZhPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5ecc3bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['continuous enhancing rim',\n",
       " 'arterial enhancement',\n",
       " 'hypointense without enhancement',\n",
       " 'venous washout',\n",
       " 'nodular or discontinuous enhancement',\n",
       " 'regular spherical hypointense mass',\n",
       " 'hyperintense mass on delayed phase',\n",
       " 'heterogeneous',\n",
       " 'infiltrative',\n",
       " 'central scar',\n",
       " 'progressive centripetal filling',\n",
       " 'thin well-defined walls',\n",
       " 'delayed isointensity',\n",
       " 'lobulated margins',\n",
       " 'progressive or concentric enhancement']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.33399877,  3.39090518,  5.96065904,  2.79865371,  2.17864888,\n",
       "        5.05574232,  4.75660604,  3.39981215,  2.19565764,  1.99309854])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test['cyst'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters_test[true_cls][img_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features.index('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[cls])):\n",
    "        z = Z_test[cls][img_num]\n",
    "        x = np.expand_dims(x_test[cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        max_strength = 0\n",
    "        \n",
    "        output[z] = [cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        #for f in all_features:\n",
    "        #    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[cls][img_num])\n",
    "        \n",
    "        for i in range(len(all_features)):\n",
    "            evidence[all_features[i] + \"/\" + str(cls_features[all_features[i]])] = features_test[cls][i, img_num]\n",
    "        \n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, int(strength*100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred5.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][7]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
