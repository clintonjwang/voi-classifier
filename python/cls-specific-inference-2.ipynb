{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda,floatX=float32\"\n",
    "import pymc3 as pm\n",
    "from scipy import optimize\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import cnn_runner as crun\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.private as prv\n",
    "import importlib\n",
    "import inference_methods_squash as im\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp, e\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import theano\n",
    "floatX = theano.config.floatX\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "sns.set_style('white')\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(crun)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_pre_act = cbuild.build_pretrain_model(model, last_layer=\"pre-act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dense_outputs = cbuild.build_pretrain_model(model, last_layer=\"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_pre_act.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "filter_pre_act = np.concatenate([filters_by_cls[cls] for cls in C.classes_to_include], axis=0)\n",
    "X = filter_pre_act\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "filter_activ = np.concatenate([filters_by_cls[cls] for cls in C.classes_to_include], axis=0)\n",
    "\n",
    "filter_avgs = np.mean(filter_pre_act, axis=0)\n",
    "filter_stds = np.std(filter_pre_act, axis=0)\n",
    "\n",
    "#filter_cls_avg_unscaled = {cls: np.mean(filter_results[cls], axis=0) for cls in C.classes_to_include}\n",
    "#filter_cls_avg_scaled = {cls: np.mean(filter_results[cls], axis=0) / filter_avgs for cls in C.classes_to_include}\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = dict(zip(*np.unique(features_by_cls['colorectal'], return_counts=True)))\n",
    "for k in z:\n",
    "    print(k, \" (\",z[k],\")\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_features_aug = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df = drm.get_voi_dfs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_pre_act = {f:np.empty([0,100]) for f in all_features}\n",
    "feature_activ = {f:np.empty([0,100]) for f in all_features}\n",
    "\n",
    "aug_factor = 50\n",
    "for f in all_features:\n",
    "    Z = Z_features[f]\n",
    "    for img_id in range(len(Z)):\n",
    "        voi_row = voi_df.loc[Z[img_id]]\n",
    "        for aug_id in range(aug_factor):\n",
    "            img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "            activ = model_pre_act.predict(np.expand_dims(img, 0))\n",
    "            feature_pre_act[f] = np.concatenate([feature_pre_act[f], activ], axis=0)\n",
    "            activ = model_dense_outputs.predict(np.expand_dims(img, 0))\n",
    "            feature_activ[f] = np.concatenate([feature_activ[f], activ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pre_act[f].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(all_features) # number of features\n",
    "num_units = 100 # number of dense units\n",
    "\n",
    "num_annotations = 8\n",
    "Z_test = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "indices_f = [orig_data_dict[cls][1] for cls in C.classes_to_include]\n",
    "indices_f = hf.flatten(indices_f)\n",
    "\n",
    "fixed_indices = np.empty([num_features, num_annotations])\n",
    "for f_ix,f in enumerate(all_features):\n",
    "    fixed_indices[f_ix, :] = np.where(np.isin(indices_f, random.sample(set(Z_features[f]), num_annotations)))[0]\n",
    "fixed_indices = fixed_indices.astype(int)\n",
    "\n",
    "z_states = np.array([z for z in itertools.product([0,1], repeat=num_features) if sum(z) <= 4 and sum(z) >= 2])\n",
    "num_states = len(z_states)\n",
    "num_imgs = filter_results.shape[0]\n",
    "z_states_bool = [tuple([bool(x) for x in z]) for z in z_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_indices = np.where(np.isin(indices_f, Z_test))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test))] for cls in C.classes_to_include}\n",
    "\n",
    "filters_test = np.empty([0,100])\n",
    "for cls in C.classes_to_include:\n",
    "    if x_test[cls].size > 0:\n",
    "        filters_test = np.concatenate([filters_test, model_dense_outputs.predict(x_test[cls], verbose=False)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y, nb_class):\n",
    "    ret = tt.zeros(nb_class)\n",
    "    ret = tt.set_subtensor(ret[y], 1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaled_observations = np.exp(np.log(np.sqrt(filter_results)) - 1)\n",
    "state_shared = theano.shared(obs_state)\n",
    "activ_shared = theano.shared(filter_results)#scaled_observations)\n",
    "\n",
    "Wm0 = np.empty((num_features, num_units))\n",
    "Ws0 = np.empty((num_features, num_units))\n",
    "for f_ix in range(num_features):\n",
    "    Wm0[f_ix] = feature_filter_means[all_features[f_ix]]\n",
    "    Ws0[f_ix] = [max(x, 1) for x in feature_filter_stds[all_features[f_ix]]*sqrt(10/9)]\n",
    "\n",
    "init_1 = np.random.uniform(.4,.6, num_features)\n",
    "init_2 = Wm0 + np.random.normal(size=(num_features, num_units))\n",
    "init_3 = np.random.normal(size=(num_features, num_features))\n",
    "init_4 = np.random.uniform(size=num_states)\n",
    "init_4 = init_4 / np.sum(init_4)\n",
    "z_states = np.array([z for z in itertools.product([0,1], repeat=num_features) if sum(z) <= 4 and sum(z) >= 2])\n",
    "num_states = len(z_states)\n",
    "#a = [3,3]\n",
    "#b = [3,3]\n",
    "\n",
    "basic_model = pm.Model()\n",
    "with basic_model:\n",
    "    #a = pm.Uniform('a', 1,10, testval=3.)\n",
    "    #b = pm.Uniform('b', 2,10, testval=3.)\n",
    "    #c = pm.Uniform('c', 1,10, testval=3.)\n",
    "    W_m = pm.Normal('W_m', mu=Wm0, sd=Ws0, shape=(num_features, num_units), testval=init_2)\n",
    "    #W_s = pm.InverseGamma('W_s')\n",
    "    sigma = pm.InverseGamma('sigma', 1, 1)\n",
    "    W = pm.Normal('W', mu=W_m, sd=sigma, shape=(num_features, num_units))\n",
    "    #z = pm.Bernoulli('z', theta_ij, size=(…))\n",
    "    #theta = pm.Beta('theta', alpha=1, beta=1, shape=num_features, testval=init_1)\n",
    "    #z = pm.Bernoulli('z', p=theta, shape=num_features)#, observed=t)\n",
    "    #theta_ij = pm.Beta('theta_ij', alpha=1, beta=1, shape=(num_features, num_features), testval=init_3)\n",
    "    p_states = pm.Dirichlet('p_states', np.ones(num_states), testval=init_4)\n",
    "    state = pm.Categorical('state', p_states)\n",
    "    z = pm.math.dot(to_one_hot(state, num_states), z_states)\n",
    "    #z = pm.Deterministic('z', pm.math.dot(to_one_hot(state, num_states), z_states))\n",
    "    #u = 1/(1+pm.math.exp(-a*pm.math.dot(z,W)+b))\n",
    "    u = pm.math.dot(z,W)\n",
    "    m = pm.Normal('m', 1, 100, shape=num_units)\n",
    "    s = pm.InverseGamma('s', 1, 1)\n",
    "    #activ = pm.Normal('activ', mu=u+m, sd=sigma, shape=num_units, observed=filter_results)\n",
    "    pre = pm.Normal('pre', mu=u+m, sd=s, shape=num_units, observed=activ_shared)\n",
    "    #obs = pm.Deterministic('obs', lambda value: tt.log(1+tt.exp(c*value))**.5, shape=num_units, observed=filter_results)\n",
    "    \n",
    "    step1 = pm.NUTS(vars=[W_m, sigma, W, p_states, m, s, pre])\n",
    "    step2 = pm.ElemwiseCategorical([state], np.arange(num_states))\n",
    "    \n",
    "    map_estimate = pm.find_MAP(model=basic_model)#, fmin=optimize.fmin_powell)\n",
    "    tr = pm.sample(1e4, [step1, step2], start=map_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr['state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_to_pred = np.exp(np.log(np.sqrt(filters_test)) - 1)\n",
    "obs_shared.set_value(obs_to_pred[0])\n",
    "ppc = pm.sample_ppc(trace, model=basic_model, samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    #prediction = pm.Normal('prediction', mu=u+m, sd=sigma, shape=num_units, observed=obs_to_pred)\n",
    "    pred_only = pm.NUTS(vars=[p_states, prediction])\n",
    "    tr_pred = pm.sample(1000, pred_only, start=map_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_tr = pm.traceplot(tr, ['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 7,567.2: 100%|███████████████████████████████████████████████████| 10000/10000 [00:29<00:00, 342.14it/s]\n",
      "Finished [100%]: Average Loss = 7,473.8\n"
     ]
    }
   ],
   "source": [
    "with basic_model:\n",
    "    mean_field = pm.fit(method='advi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_interval__ -1.7553917\n",
      "b_interval__ -2.212973\n",
      "c_interval__ -1.7553917\n",
      "W_m -1980.5779810460906\n",
      "W -1395.4309\n",
      "m -552.4109\n",
      "sigma_log__ -1.3068528\n",
      "p_states_stickbreaking__ -1927.3654367888248\n",
      "state -6.5867066\n",
      "pre -196039.74128504464\n"
     ]
    }
   ],
   "source": [
    "for RV in basic_model.basic_RVs:\n",
    "    print(RV.name, RV.logp(basic_model.test_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_estimate = pm.find_MAP(model=basic_model, fmin=optimize.fmin_powell)\n",
    "map_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/41553988/how-to-extract-unsupervised-clusters-from-a-dirichlet-process-in-pymc3?noredirect=1&lq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ann_output = theano.shared(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ann_output.set_value(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(C.base_dir, \"data\", \"annotated_features.xlsx\"))\n",
    "\n",
    "for accnum, row in df.iterrows():\n",
    "    df = df.drop(accnum)\n",
    "    accnum = prv.decode(accnum[:accnum.find('_')]) + accnum[accnum.find('_'):accnum.find(' ')]\n",
    "    df.loc[accnum] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homogenous texture', 'hyperintense on AP',\n",
       "       'isointense on VP and/or DP', 'presence of central scar',\n",
       "       'delayed central scar EH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_length(vector):\n",
    "    return sqrt(np.sum(vector**2))\n",
    "\n",
    "def squash_per_dim(vector, eps = 10**-10):\n",
    "    for i,x in enumerate(vector):\n",
    "        vector[i] *= x / (1 + x**2)\n",
    "    return vector\n",
    "\n",
    "def squash(vector, eps = 10**-10):\n",
    "    s_squared_norm = np.sum(vector**2)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / sqrt(s_squared_norm + eps)\n",
    "    return scale * vector\n",
    "\n",
    "def vec_distance(u, v):\n",
    "    return sqrt(np.sum((u - v)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final_outputs = cbuild.build_pretrain_model(model, last_layer=\"pre-softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = model.layers[-3].get_weights()[0]\n",
    "bias = model.layers[-3].get_weights()[1]\n",
    "\n",
    "#np.dot(filter_results[0], W) * eff_mult + eff_bias\n",
    "\n",
    "gamma, beta, mu, var = model.layers[-2].get_weights()\n",
    "\n",
    "eff_bias = (np.zeros(6) + bias - mu) / var**.5 * gamma + beta\n",
    "eff_mult = (np.ones(6) + bias - mu) / var**.5 * gamma + beta - eff_bias\n",
    "\n",
    "W_eff = W * eff_mult# + eff_bias\n",
    "\n",
    "#(np.dot(filter_results[0], W) + bias - mu) / var**.5 * gamma + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_div(m1, sig1, m2, sig2):\n",
    "    #returns kl(p,q) where p~N(m1,s1), q~N(m2,s2)\n",
    "    return log(sig2/sig1) + (sig1**2+(m1-m2)**2)/(2*sig2**2) - .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8780632651228981"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_div(0,5, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = np.zeros((num_features, num_units)) # probability that a feature affects a unit, based on the observed distributions\n",
    "for f_ix in range(num_features):\n",
    "    F = feature_pre_act[all_features[f_ix]]\n",
    "    _, P[f_ix, :] = ttest_ind(F, filter_pre_act, equal_var=False)\n",
    "P = 1-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7955646870257571"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = copy.deepcopy(P)\n",
    "for u_ix in range(num_units):\n",
    "    W[:,u_ix] = W[:,u_ix] * np.sum(W[:,u_ix]**2) / (1+np.sum(W[:,u_ix]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = copy.deepcopy(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99971648, 0.99833682, 0.99018788, 0.99995829, 0.99126291,\n",
       "       0.99926222, 0.99889379, 0.98689441, 0.98627045, 0.99907357,\n",
       "       0.99936655, 0.99899873, 0.99996502, 0.50815441])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,u_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99716842, 0.98349208, 0.90609985, 0.999583  , 0.9159854 ,\n",
       "       0.99264662, 0.98899277, 0.87640916, 0.87088376, 0.99077423,\n",
       "       0.99368352, 0.9900323 , 0.9996503 , 0.00114804])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,u_ix]**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92909077, 0.92780857, 0.92023532, 0.9293155 , 0.9212344 ,\n",
       "       0.9286686 , 0.92832619, 0.91717453, 0.91659464, 0.92849328,\n",
       "       0.92876556, 0.92842372, 0.92932175, 0.47225546])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[:,u_ix] * np.sum(P[:,u_ix]**2) / (1+np.sum(P[:,u_ix]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7956692541031575"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910213"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_pre_act[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KL = np.zeros((num_features, num_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f_ix in range(num_features):\n",
    "    m = feature_filter_means[all_features[f_ix]]\n",
    "    s = feature_filter_stds[all_features[f_ix]]\n",
    "    KL[f_ix, :] = ttest_ind(F, filter_results, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_filter_means = {}\n",
    "feature_filter_stds = {}\n",
    "feature_filters_scaled = {}#{cls: {} for cls in features}\n",
    "feature_filters = {f:np.empty([0,100]) for f in all_features}\n",
    "\n",
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs\n",
    "        \n",
    "    feature_filters[f] = (feature_filters[f] - filter_avgs) / filter_stds\n",
    "    \n",
    "    feature_filter_means[f] = np.mean(feature_filters[f], axis=0)# / filter_avgs\n",
    "    n = feature_filters[f].shape[0]\n",
    "    feature_filter_stds[f] = np.std(feature_filters[f], axis=0) * sqrt(n/(n-1))# / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_f = np.empty(num_features)\n",
    "test_ix = 0\n",
    "cls = 'cyst'\n",
    "for f_ix in range(num_features):\n",
    "    m = feature_filter_means[all_features[f_ix]]\n",
    "    s = feature_filter_stds[all_features[f_ix]]\n",
    "    dx = np.array([min(x,0) for x in m - filters_test[cls][test_ix]])\n",
    "    p_f[f_ix] = np.sum(P[f_ix, :] * e**(-(dx/s)**2 / 2) / sqrt(2*pi) / s) / np.sum(P[f_ix, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delayed isointensity 30%\n",
      "venous washout 18%\n",
      "infiltrative 16%\n",
      "nodular or discontinuous enhancement 15%\n",
      "lobulated margins 15%\n",
      "arterial enhancement 15%\n",
      "hyperintense mass on delayed phase 15%\n",
      "thin well-defined walls 14%\n",
      "progressive centripetal filling 13%\n",
      "regular spherical hypointense mass 13%\n",
      "progressive or concentric enhancement 12%\n",
      "heterogeneous 12%\n",
      "hypointense without enhancement 12%\n",
      "continuous enhancing rim 10%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAADICAYAAADskzu8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141d37be5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for f,strength in sorted(enumerate(p_f), key=lambda x:x[1], reverse=True):\n",
    "    #if strength<0.2:\n",
    "    #    break\n",
    "    print(\"%s %d%%\" % (all_features[f], strength*100))\n",
    "\n",
    "x_test_quick = x_test[cls][test_ix]#orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == indices_f[test_ix])]\n",
    "hf.draw_slices(x_test_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "\n",
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f_ix in range(num_features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_vector(vector, feature_vectors):\n",
    "    best_feature = -1\n",
    "    for f_ix, feature_vec in enumerate(feature_vectors):\n",
    "        if np.dot(vector, feature_vec) < threshold:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_filter_results = (filter_results - filter_avgs) / filter_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.amin(filter_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_vectors = np.empty((num_features, num_units))\n",
    "feature_relevance = np.empty(num_features)\n",
    "for f_ix in range(num_features):\n",
    "    feature_vectors[f_ix, :] = np.mean(feature_filters[all_features[f_ix]], axis=0)\n",
    "    feature_evidence[f_ix] = np.dot(feature_vectors[f_ix], W_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "squashed_filter_results = (filter_results / filter_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements\n",
    "- feature_vectors * unit_relevance should be maximized\n",
    "\n",
    "- np.dot(feature_vectors[i], feature_vectors[j]) should be minimized, OR\n",
    "- vec_distance(feature_vectors[i], feature_vectors[j]) should be maximized for all pairs i,j\n",
    "\n",
    "- features \"turn on / off\" specific units; try to minimize the number of units impacted by a given feature\n",
    "\n",
    "- p(z|x) > .75 for all x manually annotated by z\n",
    "\n",
    "===\n",
    "- show % of evidence explained (fraction of sum of contributing units that are captured by features that turn those units on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_relevance = np.empty(num_units)\n",
    "for u_ix in range(num_units):\n",
    "    unit_relevance[u_ix] = np.amax(W_eff[u_ix]) - np.amin(W_eff[u_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_results = filter_results*unit_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_length = np.mean(np.apply_along_axis(get_length, 1, filter_results*unit_relevance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6239091267665856"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(squash(filter_results[2] * unit_relevance * 2/avg_length)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'inference_methods' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\inference_methods.py'>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_loop(k, alpha=.8, beta=.3, **kwargs):\n",
    "    if len(kwargs) == 0:\n",
    "        W = np.ones((num_features, num_units))\n",
    "        for f_ix in range(num_features):\n",
    "            W[f_ix] = feature_filter_means[all_features[f_ix]]\n",
    "        mu = np.ones(num_units)\n",
    "        sigma = 5\n",
    "        a = 5\n",
    "        b = 3\n",
    "        theta = np.zeros((num_features, num_features))#scipy.random.normal(size=(num_features, num_features))\n",
    "    else:\n",
    "        mu = kwargs['mu']\n",
    "        sigma = kwargs['sigma']\n",
    "        W = kwargs['W']\n",
    "        a = kwargs['a']\n",
    "        b = kwargs['b']\n",
    "        theta = kwargs['theta']\n",
    "    \n",
    "    print(\"Initializing probabilities...\")\n",
    "    U = im.get_squashed_X(X, a, b)\n",
    "    p_z = im.get_p_z(z_states, theta)\n",
    "    s_states = im.get_s_states(z_states, W, p_z)\n",
    "    p_x_z = im.get_all_p_x_z(mu, sigma, s_states, U, fixed_indices, z_states)\n",
    "    p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "    \n",
    "    print(\"Running EM:\")\n",
    "    for jj in range(k):\n",
    "        print(\"   Iteration\", jj, end=\"...\")\n",
    "        print(\"Updating W, theta...\", end=\"\")\n",
    "        W = im.update_W(mu, W, z_states, U, p_z_x, fixed_indices, alpha)\n",
    "        theta = im.update_thetas(np.sum(p_z_x, axis=0), z_states_bool, theta, alpha)\n",
    "\n",
    "        p_z = im.get_p_z(z_states, theta)\n",
    "        s_states = im.get_s_states(z_states, W, p_z)\n",
    "        p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "        \n",
    "        print(\"Updating mu, sigma, a, b...\", end=\"\")\n",
    "        mu = im.update_mus(mu, s_states, U, p_z_x, beta)\n",
    "        sigma = im.update_sigma(mu, sigma, s_states, U, p_z_x)\n",
    "        a, b = im.update_ab(mu, a, b, sigma, s_states, X, p_z_x, beta)\n",
    "\n",
    "        if jj < k-1:\n",
    "            print(\"Updating probabilities...\")\n",
    "            U = im.get_squashed_X(X, a, b)\n",
    "            s_states = im.get_s_states(z_states, W, p_z)\n",
    "            p_x_z = im.get_all_p_x_z(mu, sigma, s_states, U, fixed_indices, z_states)\n",
    "            p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "            \n",
    "    return W, theta, mu, sigma, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6068820855405788 0.4020698107354496\n",
      "-1.2357424596567832 0.8557082098766997\n",
      "-0.0009163150682455879 0.011434793765638829\n",
      "1.9101354005255533\n",
      "2.0048 1.0032\n"
     ]
    }
   ],
   "source": [
    "params = {'mu': mu,\n",
    "'sigma': sigma,\n",
    "'a': a,\n",
    "'b': b,\n",
    "'W': W,\n",
    "'theta': theta}\n",
    "\n",
    "print(np.amin(mu), np.amax(mu))\n",
    "print(np.amin(W), np.amax(W))\n",
    "print(np.amin(theta), np.amax(theta))\n",
    "print(sigma)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'inference_methods' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\inference_methods.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(im)\n",
    "im.W_opt_func(np.ravel(W), a_i, b_i, c_i, z_states, W, fixed_indices, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros((num_features, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing probabilities...\n",
      "Running EM:\n",
      "   Iteration 0...Updating W, theta...Updating mu, sigma, a, b...Updating probabilities...\n",
      "   Iteration 1...Updating W, theta...Updating mu, sigma, a, b..."
     ]
    }
   ],
   "source": [
    "importlib.reload(im)\n",
    "#W = im.update_W(mu, W, z_states, U, p_z_x, fixed_indices, .5, view_weights=True)\n",
    "W, theta, mu, sigma, a, b = EM_loop(2, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_z = np.ones(p_z.shape)\n",
    "p_z_x = im.get_all_p_z_x(p_x_z, p_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U = im.get_squashed_X(X, a, b)\n",
    "p_z = im.get_p_z(z_states, theta)\n",
    "s_states = im.get_s_states(z_states, W, p_z)\n",
    "p_x_z = im.get_all_p_x_z(mu, sigma, s_states, U, fixed_indices, z_states)\n",
    "p_z_x = im.get_all_p_z_x(p_x_z, p_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for _ in range(num_states*10):\n",
    "    np.nan_to_num(0)\n",
    "    #pass\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progressive centripetal filling 25%\n",
      "hyperintense mass on delayed phase 25%\n",
      "venous washout 25%\n",
      "infiltrative 25%\n",
      "lobulated margins 25%\n",
      "heterogeneous 25%\n",
      "regular spherical hypointense mass 25%\n",
      "progressive or concentric enhancement 25%\n",
      "continuous enhancing rim 25%\n",
      "thin well-defined walls 25%\n",
      "arterial enhancement 25%\n",
      "delayed isointensity 25%\n",
      "nodular or discontinuous enhancement 25%\n",
      "hypointense without enhancement 25%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e501e4c3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ix = 0\n",
    "#for test_ix in test_indices[5:]:\n",
    "p_zi_x = np.zeros([num_features])\n",
    "for f_ix in range(num_features):\n",
    "    state_ixs = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    p_zi_x[f_ix] = sum(p_z_x[test_ix, state_ixs])\n",
    "    #for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "    #    output[z] = output[z] + [f, strength]\n",
    "#break\n",
    "\n",
    "for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "    if strength<0.2:\n",
    "        break\n",
    "    print(\"%s %d%%\" % (all_features[f], strength*100))\n",
    "\n",
    "for cls in C.classes_to_include:\n",
    "    x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == indices_f[test_ix])]\n",
    "    if len(x_test_quick) > 0:\n",
    "        break\n",
    "hf.draw_slices(x_test_quick[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "\n",
    "# Least squares approach\n",
    "Theta = np.array([feature_filter_means[f] for f in all_features])\n",
    "Theta = np.transpose(Theta, (1,0))\n",
    "\n",
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)\n",
    "    filters_test[cls] = (filters_test[cls] - filter_avgs) / filter_stds\n",
    "    features_test[cls] = np.linalg.lstsq(Theta, np.transpose(filters_test[cls], (1,0)))[0]\n",
    "    #filters_test[cls] = np.apply_along_axis(lambda x: x / filter_avgs, 1, filters_test[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covar_to_corr(covar):\n",
    "    A = np.diag(np.diag(covar)**(-0.5))\n",
    "    return np.matmul(np.matmul(A, covar), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = covar_to_corr(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(corr - np.linalg.pinv(np.diag(np.diag(np.linalg.pinv(corr)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cutoff_eigenval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=None,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = np.random.normal(size=filter_results.shape)\n",
    "dummy_fa = FactorAnalysis()\n",
    "dummy_fa.fit(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.linalg.eigvals(fa.get_covariance()) > np.mean(np.linalg.eigvals(dummy_fa.get_covariance())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.fit(filter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89081373261106078"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=3\n",
    "fa.get_covariance()[x,x] - fa.noise_variance_[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = cnna.get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))\n",
    "\n",
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[cls])):\n",
    "        z = Z_test[cls][img_num]\n",
    "        x = np.expand_dims(x_test[cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        \n",
    "        output[z] = [cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        #for f in all_features:\n",
    "        #    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[cls][img_num])\n",
    "        \n",
    "        for i in range(len(all_features)):\n",
    "            evidence[all_features[i] + \"/\" + str(cls_features[all_features[i]])] = features_test[cls][i, img_num]\n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, strength]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred5.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][3], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:\\\\filters_pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "agree = 0\n",
    "for _,row in df.iterrows():\n",
    "    if row[\"pred_cls1\"] in row[\"feature_1\"]:\n",
    "        agree += 1\n",
    "print(agree/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
