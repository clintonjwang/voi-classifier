{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import copy\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.transforms as tr\n",
    "import importlib\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "importlib.reload(crun)\n",
    "C = config.Config()\n",
    "T = config.Hyperparams()\n",
    "#T.steps_per_epoch = 50\n",
    "#T.epochs= 1\n",
    "#T.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_analyzer' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_analyzer.py'>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model_frozen.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_img = orig_data_dict['hcc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_ixs = list(range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer(model_frozen, 'conv3d_11', \"D:\\\\filters\", channel_ixs)#, init_img=init_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_trunc = cbuild.build_pretrain_model(model, last_layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "fig = cnna.tsne(filters_by_cls)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.flatten([list(feature_sheet[\"evidence1\"+cls].dropna().values) for cls in C.classes_to_include]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv1 = cbuild.build_pretrain_model(model, last_layer=-6, add_activ=True)\n",
    "model_conv2 = cbuild.build_pretrain_model(model, last_layer=-5, add_activ=True)\n",
    "model_conv3 = cbuild.build_pretrain_model(model, last_layer=-4, add_activ=True)\n",
    "model_dense = cbuild.build_pretrain_model(model, last_layer=-3, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = 'cyst'\n",
    "cls_img_set = orig_data_dict[cls][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_activ_set = model_conv3.predict(cls_img_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(4)\n",
    "cls_activ_set_xform = nmf.fit_transform(cls_activ_set.mean((1,2,3)))\n",
    "\n",
    "nmf_comps = [nmf.components_[i] * (nmf.components_[i] > np.median(nmf.components_,0)*2) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_analyzer' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_analyzer.py'>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer_weighted(model_frozen, 'conv3d_11', \"D:\\\\filters\", K.constant(nmf_comps[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activs0 = cls_activ_set[:,:,:,:,nmf_comps[1] > 0]\n",
    "activ_map0 = activs0.mean(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activ_map0, _ = tr.rescale_img(np.transpose(activ_map0, (1,2,3,0)), cls_img_set[img_id].shape[:3])\n",
    "activ_map0 = np.transpose(activ_map0, (3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noxkCAACp0QwBAIDU/hcIDu1BotqjagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177a007b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 1\n",
    "alpha = 1.\n",
    "overlaid_img = cls_img_set[img_id] - np.amin(cls_img_set[img_id])\n",
    "overlaid_img = np.stack([((activ_map0[img_id] > np.mean(activ_map0[img_id])*alpha)+.5) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "hf.draw_slices(overlaid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf.draw_slices(cls_img_set[img_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div(m1, sig1, m2, sig2, one_sided=\"none\"):\n",
    "    #returns kl(p,q) where p~N(m1,s1), q~N(m2,s2)\n",
    "    ret = np.log(sig2/sig1) + (sig1**2+(m1-m2)**2)/(2*sig2**2) - .5\n",
    "    if one_sided==\"less\":\n",
    "        return ret * (m1 < m2)\n",
    "    elif one_sided==\"greater\":\n",
    "        return ret * (m1 > m2)\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv1_pre = cbuild.build_pretrain_model(model, last_layer=-6)#, add_activ=True)\n",
    "model_conv2_pre = cbuild.build_pretrain_model(model, last_layer=-5)#, add_activ=True)\n",
    "model_conv3_pre = cbuild.build_pretrain_model(model, last_layer=-4)#, add_activ=True)\n",
    "model_dense_pre = cbuild.build_pretrain_model(model, last_layer=-3)#, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12572068_0', '13092836_1', 'E103354630_0', 'E105921537_0', 'E106010098_0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df = drm.get_voi_dfs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.concatenate([orig_data_dict[cls][1] for cls in C.classes_to_include], 0)\n",
    "\n",
    "all_conv3_ch = np.empty([0,128])\n",
    "\n",
    "aug_factor = 10\n",
    "for img_id in range(len(Z)):\n",
    "    voi_row = voi_df.loc[Z[img_id]]\n",
    "    for aug_id in range(aug_factor):\n",
    "        img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "        activ = model_conv3.predict(np.expand_dims(img, 0))\n",
    "        all_conv3_ch = np.concatenate([all_conv3_ch, activ.mean(axis=(1,2,3))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = all_conv3_ch.mean(0)\n",
    "s = all_conv3_ch.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.empty((8,8,4))\n",
    "for x in range(D.shape[0]):\n",
    "    for y in range(D.shape[1]):\n",
    "        for z in range(D.shape[2]):\n",
    "            D[x,y,z] = (D.shape[0]-.5-x)**2 + (D.shape[1]-.5-y)**2 + 4*(D.shape[2]-.5-z)**2\n",
    "\n",
    "def get_shells(activ, D):\n",
    "    shell4 = activ[0, D > 85, :].mean(axis=0)\n",
    "    shell3 = activ[0, (D <= 85) & (D > 62), :].mean(axis=0)\n",
    "    shell2 = activ[0, (D <= 62) & (D > 39), :].mean(axis=0)\n",
    "    shell1 = activ[0, D <= 39, :].mean(axis=0)\n",
    "    return np.expand_dims(np.stack([shell1, shell2, shell3, shell4], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conv3_ch = {f:np.empty([0,8,8,4,128]) for f in all_features}\n",
    "#feature_conv3_sh = {f:np.empty([0,4,128]) for f in all_features}\n",
    "aug_factor = 80\n",
    "for f_ix in relevant_features:\n",
    "    f = all_features[f_ix]\n",
    "    Z_f = Z_features[f]\n",
    "    for img_id in range(len(Z_f)):\n",
    "        voi_row = voi_df.loc[Z_f[img_id]]\n",
    "        for aug_id in range(aug_factor):\n",
    "            img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z_f[img_id], aug_id)))\n",
    "            activ = model_conv3_pre.predict(np.expand_dims(img, 0))\n",
    "            feature_conv3_ch[f] = np.concatenate([feature_conv3_ch[f], activ], axis=0)\n",
    "            #feature_conv3_sh[f] = np.concatenate([feature_conv3_sh[f], get_shells(activ, D)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3_ch_plus = copy.deepcopy(feature_conv3_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv3_ch_plus[f][conv3_ch_plus[f] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_sh_plus = {}\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv3_ch_plus[f] = conv3_ch_plus[f].mean(0)\n",
    "    activ = conv3_ch_plus[f]\n",
    "    shell4 = activ[D > 85, :].mean(0)\n",
    "    shell3 = activ[(D <= 85) & (D > 62), :].mean(0)\n",
    "    shell2 = activ[(D <= 62) & (D > 39), :].mean(0)\n",
    "    shell1 = activ[D <= 39, :].mean(0)\n",
    "    conv3_sh_plus[f] = np.stack([shell1, shell2, shell3, shell4], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avgs = np.zeros((4,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_ch_plus[f].mean((0,1,2))\n",
    "    \n",
    "channel_separations = np.empty((4,128)) # separation between channel mean activations for the 4 features\n",
    "for i in range(4):\n",
    "    channel_separations[i] = (np.amax(feature_avgs, 0) - feature_avgs[i]) / np.mean(feature_avgs, 0)\n",
    "\n",
    "channel_separations *= 10\n",
    "\n",
    "W = np.zeros((4,128))\n",
    "for ch_ix in range(128):\n",
    "    #f_ix = list(channel_separations[:,ch_ix]).index(0)\n",
    "    #W[f_ix,ch_ix] = channel_separations[:,ch_ix].mean()\n",
    "    W[:,ch_ix] = np.median(channel_separations[:,ch_ix]) - channel_separations[:,ch_ix]\n",
    "    \n",
    "W[W < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_avgs = np.zeros((4,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_sh_plus[f].mean(0).max(0)\n",
    "    \n",
    "channel_separations = np.empty((4,128))\n",
    "for i in range(4):\n",
    "    channel_separations[i] = np.amax(feature_avgs, 0) - feature_avgs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'venous washout'), (1, 'progressive or concentric enhancement'), (2, 'thin well-defined walls'), (3, 'regular spherical hypointense mass'), (4, 'delayed isointensity'), (5, 'infiltrative'), (6, 'nodular or discontinuous enhancement'), (7, 'continuous enhancing rim'), (8, 'heterogeneous'), (9, 'arterial enhancement'), (10, 'lobulated margins'), (11, 'progressive centripetal filling'), (12, 'hypointense without enhancement'), (13, 'hyperintense mass on delayed phase')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(range(len(all_features)), all_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_neuron_ixs = np.where(h_ic_rot[0] > 0)\n",
    "\n",
    "num_active_neurons = active_neuron_ixs[0].size\n",
    "\n",
    "H = h_ic[h_ic > 0]\n",
    "np.matmul(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_spatial_overlap(ch_weights, f_c3_ch, z):\n",
    "    relevant_features = ch_weights.keys()\n",
    "    \n",
    "    ch_weights2 = np.zeros(128)\n",
    "    \n",
    "    #f_c3_ch\n",
    "    \n",
    "    for ch in range(128):\n",
    "        f_c3_ch[:,:,:,:,ch] = (f_c3_ch[:,:,:,:,ch] - np.mean(f_c3_ch[:,:,:,:,ch]))# / np.std(f_c3_ch[:,:,:,:,ch])\n",
    "        \n",
    "        if ch_weights[ch] > 0:\n",
    "            w = np.zeros(f_c3_ch.shape[:4])\n",
    "            for i in range(128):\n",
    "                if ch_weights[i] > 0:\n",
    "                    w += ch_weights[i] * f_c3_ch[:,:,:,:,i]\n",
    "            w = w / np.sum(ch_weights)\n",
    "            ch_weights2[ch] = np.sum(f_c3_ch[:,:,:,:,ch] * w)\n",
    "            \n",
    "    return ch_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls = 'hcc'\n",
    "cls_img_set = orig_data_dict[cls][0]\n",
    "cls_activ_set = model_conv3_pre.predict(cls_img_set)\n",
    "\n",
    "img_id = 0\n",
    "x = cls_img_set[img_id]\n",
    "\n",
    "x = orig_data_dict[cls][0][img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ic = [model_conv3_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "#h_ic_plus = model_conv3.predict(cls_img_set)[img_id]\n",
    "#h_ic = model_conv3_pre.predict(np.expand_dims(x,0))[0]\n",
    "\n",
    "h_ic_plus = copy.deepcopy(h_ic)\n",
    "for r in range(4):\n",
    "    h_ic_plus[r][h_ic_plus[r] < 0] = 0\n",
    "\n",
    "h_ic_rot = [np.rot90(h_ic_plus[r], 4-r) for r in range(4)] #rotated back into original frame\n",
    "#h_ic_rot = [np.rot90(h_ic[0], r) for r in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_ic_rot = np.array(h_ic_rot)\n",
    "test_neurons = h_ic_rot.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = [h_ic_rot[a][active_neuron_ixs] for a in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.sum(3*np.matmul(H[0], W) - np.matmul(H[1], W) - np.matmul(H[2], W) - np.matmul(H[3], W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h_ca = {f_ix: feature_conv3_ch[all_features[f_ix]].mean((0,1,2,3)) for f_ix in relevant_features}\n",
    "h_ca_plus = {f_ix: feature_conv3_ch[all_features[f_ix]][feature_conv3_ch[all_features[f_ix]] > 0].mean((0,1,2,3)) for f_ix in relevant_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = np.tile(h_ca[f_ix], list(h_ic.shape[:3])+[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f_ix in relevant_features:\n",
    "    w_ica[f_ix] = h_ic_plus / (np.abs(h_ic_plus - h_ca[f_ix]) + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = cls_img_set[img_id]\n",
    "test_neurons = model_conv3_pre.predict(np.expand_dims(x,0))[0]\n",
    "test_neurons[test_neurons < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'venous washout'), (1, 'progressive or concentric enhancement'), (2, 'thin well-defined walls'), (3, 'regular spherical hypointense mass'), (4, 'delayed isointensity'), (5, 'infiltrative'), (6, 'nodular or discontinuous enhancement'), (7, 'continuous enhancing rim'), (8, 'heterogeneous'), (9, 'arterial enhancement'), (10, 'lobulated margins'), (11, 'progressive centripetal filling'), (12, 'hypointense without enhancement'), (13, 'hyperintense mass on delayed phase')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(range(len(all_features)), all_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = [0,7,8,9]\n",
    "img_dir = \"D:\\\\feature_analysis\\\\samples\"\n",
    "if not exists(img_dir):\n",
    "    os.makedirs(img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f_ix in relevant_features:\n",
    "    img_dir = \"D:\\\\feature_analysis\\\\\"+all_features[f_ix]\n",
    "    if not exists(img_dir):\n",
    "        os.makedirs(img_dir)\n",
    "        \n",
    "    f_c3_ch = feature_conv3_ch[all_features[f_ix]]\n",
    "    avg_f_conv3_ch = f_c3_ch.mean((1,2,3))\n",
    "    f_m = avg_f_conv3_ch.mean(0)\n",
    "    f_s = avg_f_conv3_ch.std(0)\n",
    "\n",
    "    ch_weights[all_features[f_ix]] = np.log(kl_div(m, s, f_m, f_s, 'less')+1) #kl_div(m, s, f_m, f_s, 'less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_id = 0\n",
    "z = orig_data_dict[cls][1][img_id]\n",
    "\n",
    "ch_weights2 = get_spatial_overlap(ch_weights, feature_conv3_ch, z)\n",
    "ch_weights2[ch_weights2 < np.median(ch_weights2) / 2] = 0 #np.median(ch_weights2) / 2\n",
    "ch_weights[all_features[f_ix]] *= ch_weights2\n",
    "ch_weights[all_features[f_ix]] /= np.mean(ch_weights[all_features[f_ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = orig_data_dict[cls][1][img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a642ecda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for f_num, f_ix in enumerate(relevant_features):\n",
    "f_num = 0\n",
    "w = np.zeros(test_neurons.shape[:3])\n",
    "for ch_ix in range(128):\n",
    "    if W[f_num, ch_ix] > 0:\n",
    "        w += W[f_num, ch_ix] * test_neurons[:,:,:,ch_ix]\n",
    "activ_map0 = w / np.sum(W[f_num])\n",
    "#activ_map0, _ = tr.rescale_img(activ_map0, x.shape[:3])\n",
    "activ_map0 = tr.scale3d(activ_map0, (2,2,2))\n",
    "activ_map0 = np.pad(activ_map0, ((4,4),(4,4),(2,2)), 'constant')\n",
    "\n",
    "#for img_id in range(len(cls_img_set)):\n",
    "alpha = 1\n",
    "overlaid_img = x - np.amin(x)\n",
    "overlaid_img = np.stack([((activ_map0 > np.mean(activ_map0[activ_map0 > 0])*alpha)+.3) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "hf.draw_slices(overlaid_img[:,::-1,:], save_path=img_dir+\"\\\\\"+z+\" (%s).png\" % all_features[relevant_features[f_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(cbuild)\n",
    "C=config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305\n",
    "model_dense_outputs = cbuild.build_pretrain_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 24, 12, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([orig_data_dict['cyst'][0][0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "filter_results = np.concatenate([filters_by_cls[cls] for cls in C.classes_to_include], axis=0)\n",
    "\n",
    "filter_avgs = np.mean(filter_results, axis=0)\n",
    "filter_stds = np.std(filter_results, axis=0)\n",
    "\n",
    "#filter_cls_avg_unscaled = {cls: np.mean(filter_results[cls], axis=0) for cls in C.classes_to_include}\n",
    "#filter_cls_avg_scaled = {cls: np.mean(filter_results[cls], axis=0) / filter_avgs for cls in C.classes_to_include}\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = dict(zip(*np.unique(features_by_cls['colorectal'], return_counts=True)))\n",
    "for k in z:\n",
    "    print(k, \" (\",z[k],\")\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash_per_dim(vector, eps = 10**-10):\n",
    "    for i,x in enumerate(vector):\n",
    "        vector[i] *= x / (1 + x**2)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = model.layers[-3].get_weights()[0]\n",
    "bias = model.layers[-3].get_weights()[1]\n",
    "\n",
    "gamma, beta, mu, var = model.layers[-2].get_weights()\n",
    "\n",
    "eff_bias = (np.zeros(6) + bias - mu) / var**.5 * gamma + beta\n",
    "eff_mult = (np.ones(6) + bias - mu) / var**.5 * gamma + beta - eff_bias\n",
    "\n",
    "W_eff = W * eff_mult# + eff_bias\n",
    "\n",
    "unit_relevance = np.empty(num_units)\n",
    "for u_ix in range(num_units):\n",
    "    unit_relevance[u_ix] = np.amax(W_eff[u_ix]) - np.amin(W_eff[u_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_filter_results = np.apply_along_axis(lambda X: squash_per_dim(X), 0, filter_results / (2*filter_avgs) * unit_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")\n",
    "\n",
    "feature_filter_means = {}\n",
    "feature_filter_stds = {}\n",
    "feature_filters_scaled = {}#{cls: {} for cls in features}\n",
    "feature_filters = {f:np.empty([0,100]) for f in all_features}\n",
    "\n",
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs\n",
    "        \n",
    "    feature_filters[f] = (feature_filters[f] - filter_avgs) / filter_stds\n",
    "    \n",
    "    feature_filter_means[f] = np.mean(feature_filters[f], axis=0)\n",
    "    feature_filter_stds[f] = np.std(feature_filters[f], axis=0)\n",
    "\n",
    "    feature_filters_scaled[f] = feature_filter_means[f] / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(all_features) # number of features\n",
    "num_units = 100 # number of dense units\n",
    "\n",
    "num_annotations = 8\n",
    "Z_test = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "indices_f = [orig_data_dict[cls][1] for cls in C.classes_to_include]\n",
    "indices_f = hf.flatten(indices_f)\n",
    "\n",
    "fixed_indices = np.empty([num_features, num_annotations])\n",
    "for f_ix,f in enumerate(all_features):\n",
    "    fixed_indices[f_ix, :] = np.where(np.isin(indices_f, random.sample(set(Z_features[f]), num_annotations)))[0]\n",
    "fixed_indices = fixed_indices.astype(int)\n",
    "\n",
    "test_indices = np.where(np.isin(indices_f, Z_test))[0]\n",
    "\n",
    "z_states = np.array([z for z in itertools.product([0,1], repeat=num_features) if sum(z) <= 4 and sum(z) >= 2])\n",
    "num_states = len(z_states)\n",
    "num_imgs = filter_results.shape[0]\n",
    "z_states_bool = [tuple([bool(x) for x in z]) for z in z_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_theta(k, alpha=.5, beta=.5, **kwargs):\n",
    "    if len(kwargs) == 0:\n",
    "        mu = np.empty([num_features, num_units])\n",
    "        sigma = np.empty([num_features, num_units])\n",
    "        for i in range(num_features):\n",
    "            mu[i] = feature_filter_means[all_features[i]]\n",
    "            sigma[i] = feature_filter_stds[all_features[i]]\n",
    "        sigma[sigma > 1] = 1\n",
    "        m = filter_avgs\n",
    "        s = filter_stds\n",
    "\n",
    "        theta_i = scipy.random.normal(size=num_features)\n",
    "        theta_ij = scipy.random.normal(size=[num_features-1, num_features])\n",
    "    else:\n",
    "        mu = kwargs['mu']\n",
    "        sigma = kwargs['sigma']\n",
    "        m = kwargs['m']\n",
    "        s = kwargs['s']\n",
    "        theta_i = kwargs['theta_i']\n",
    "        theta_ij = kwargs['theta_ij']\n",
    "    \n",
    "    print(\"Initializing probabilities...\")\n",
    "    p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "    p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "    p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "    \n",
    "    print(\"Running EM:\")\n",
    "    for jj in range(k):\n",
    "        print(\"   Iteration\", jj, end=\"...Update thetas...\")\n",
    "        theta_i, theta_ij = im.update_thetas(np.sum(p_z_x, axis=0), z_states_bool, theta_i, theta_ij, alpha)\n",
    "\n",
    "        p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "        p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "\n",
    "        print(\"Update means and stdevs...\", end=\"\")\n",
    "        mu_est = im.update_mus(mu, m, sigma, s, z_states, filter_results, p_z_x, fixed_indices, beta)\n",
    "        m_est = im.update_ms(mu, m, sigma, s, z_states, filter_results, p_z_x, beta)\n",
    "        sigma, s = im.update_stdevs_approx(mu, m, sigma, s, z_states, filter_results, p_z_x, beta)\n",
    "\n",
    "        if jj < k-1:\n",
    "            print(\"Update probabilities...\")\n",
    "            p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "            p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "            \n",
    "    return mu, m, sigma, s, theta_i, theta_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'mu': mu,\n",
    "'sigma': sigma,\n",
    "'m': m,\n",
    "'s': s,\n",
    "'theta_i': theta_i,\n",
    "'theta_ij': theta_ij}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'inference_methods' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\inference_methods.py'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing probabilities...\n",
      "Running EM:\n",
      "   Iteration 0...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 1...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 2...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 3...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 4...Update thetas...Update means and stdevs..."
     ]
    }
   ],
   "source": [
    "mu, m, sigma, s, theta_i, theta_ij = EM_theta(5, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importlib.reload(im)\n",
    "p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "p_z_x = im.get_all_p_z_x(p_x_z, p_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for _ in range(num_states*10):\n",
    "    np.nan_to_num(0)\n",
    "    #pass\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test_ix in test_indices[3:]:\n",
    "    p_zi_x = np.zeros([num_features])\n",
    "    for f_ix in range(num_features):\n",
    "        state_ixs = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "        p_zi_x[f_ix] = sum(p_z_x[test_ix, state_ixs])\n",
    "        #for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "        #    output[z] = output[z] + [f, strength]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arterial enhancement 82%\n",
      "thin well-defined walls 74%\n",
      "heterogeneous 62%\n",
      "continuous enhancing rim 56%\n"
     ]
    }
   ],
   "source": [
    "for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "    if strength<0.3:\n",
    "        break\n",
    "    print(\"%s %d%%\" % (all_features[f], strength*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACFCAYAAABsdIKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQxYRmQQdsojIJOiQRUQm4T+WenD2fSyHOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb084a6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cls in C.classes_to_include:\n",
    "    x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == indices_f[test_ix])]\n",
    "    if len(x_test_quick) > 0:\n",
    "        break\n",
    "hf.draw_slices(x_test_quick[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@njit\n",
    "def update_stdevs(mu, m, sigma, s, z_states, filter_results, p_z_x):\n",
    "    sigma_est = np.empty([num_features, num_units])\n",
    "    s_est = np.empty([num_units])\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "\n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in range(num_states):\n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - \\\n",
    "                       np.dot(mu[:, u_ix], z_states_bool[state_ix]) - m[u_ix])**2 for img_ix in range(num_imgs)]) / 2\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "\n",
    "        temp = scipy.optimize.minimize(\\\n",
    "                    lambda Var: sum([a_i[state_ix] / (sum(np.where(z_states_bool[state_ix],\n",
    "                       Var[:-1], 0))+Var[-1]) + c_i[state_ix] * log(sqrt(sum(np.where(z_states_bool[state_ix],\n",
    "                       Var[:-1], 0))+Var[-1]) * sqrt(2*pi)) for state_ix in range(num_states)]),\n",
    "                      np.concatenate([sigma[:, u_ix]**2, [s[u_ix]**2]]), \n",
    "                      bounds=tuple(itertools.repeat((.001, 1000),num_features+1)))\n",
    "\n",
    "        sigma_est[:, u_ix] = [sqrt(i) for i in temp['x'][:-1]]\n",
    "        s_est[u_ix] = sqrt(temp['x'][-1])\n",
    "    \n",
    "    return sigma_est, s_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "t=time.time()\n",
    "for f_ix in range(num_features):\n",
    "    state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    #p_z_x does not need to be rescaled because the factor cancels out\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "    \n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in state_indices:\n",
    "            z = z_states[state_ix]\n",
    "\n",
    "            mean = np.dot(mu[:, u_ix], z) + m[u_ix]\n",
    "            var_adj[state_ix] = sum(np.where(z==1, sigma[:, u_ix]**2, 0)) + s[u_ix]**2 - sigma[f_ix, u_ix]**2\n",
    "            \n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "        \n",
    "        sigma_est[f_ix, u_ix] = sqrt(scipy.optimize.fsolve(lambda x: sum([a_i[state_ix]/(x+var_adj[state_ix])**2 - \\\n",
    "                                         c_i[state_ix]/(x+var_adj[state_ix]) for state_ix in state_indices]), \\\n",
    "                                          sigma[f_ix, u_ix]))\n",
    "        \n",
    "        if u_ix % 20 == 0:\n",
    "            print(f_ix, u_ix, time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "#state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "#p_z_x does not need to be rescaled because the factor cancels out\n",
    "var_adj = np.zeros([num_states])\n",
    "a_i = np.zeros([num_states])\n",
    "c_i = np.zeros([num_states])\n",
    "\n",
    "for u_ix in range(num_units):\n",
    "    for state_ix in range(num_states):\n",
    "        mean = np.dot(mu[:, u_ix], z_states[state_ix]) + m[u_ix]\n",
    "        a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "        c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "\n",
    "    temp = scipy.optimize.linearmixing(\\\n",
    "                lambda Var: sum([a_i[state_ix]/(sum(np.where(z_states[state_ix]==1, Var[:-1]**2, 0))+Var[-1]**2)**2 - \\\n",
    "                 c_i[state_ix]/(sum(np.where(z_states[state_ix]==1, Var[:-1]**2, 0))+Var[-1]**2) for state_ix in range(num_states)]), \\\n",
    "                  np.concatenate([sigma[:, u_ix], [s[u_ix]]]), verbose=True, maxiter=10000)\n",
    "    \n",
    "    #sigma_est[:, u_ix]\n",
    "    if u_ix % 20 == 0:\n",
    "        print(u_ix, time.time()-t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for f_ix in range(num_features):\n",
    "    state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    #p_z_x does not need to be rescaled because the factor cancels out\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "    \n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in state_indices:\n",
    "            z = z_states[state_ix]\n",
    "\n",
    "            mean = np.dot(mu[:, u_ix], z) + m[u_ix]\n",
    "            var_adj[state_ix] = sum(np.where(z==1, sigma[:, u_ix]**2, 0)) + s[u_ix]**2 - sigma[f_ix, u_ix]**2\n",
    "            \n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "        \n",
    "        sigma_est[f_ix, u_ix] = sqrt(scipy.optimize.fsolve(lambda x: sum([(a_i[state_ix]/(x+var_adj[state_ix]) - \\\n",
    "                                         c_i[state_ix])/(x+var_adj[state_ix]) for state_ix in state_indices]), \\\n",
    "                                          sigma[f_ix, u_ix]))\n",
    "        \n",
    "        if u_ix % 20 == 0:\n",
    "            print(f_ix, u_ix, time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least squares approach\n",
    "Theta = np.array([feature_filter_means[f] for f in all_features])\n",
    "Theta = np.transpose(Theta, (1,0))\n",
    "\n",
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)\n",
    "    filters_test[cls] = (filters_test[cls] - filter_avgs) / filter_stds\n",
    "    features_test[cls] = np.linalg.lstsq(Theta, np.transpose(filters_test[cls], (1,0)))[0]\n",
    "    #filters_test[cls] = np.apply_along_axis(lambda x: x / filter_avgs, 1, filters_test[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covar_to_corr(covar):\n",
    "    A = np.diag(np.diag(covar)**(-0.5))\n",
    "    return np.matmul(np.matmul(A, covar), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = covar_to_corr(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(corr - np.linalg.pinv(np.diag(np.diag(np.linalg.pinv(corr)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cutoff_eigenval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=None,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = np.random.normal(size=filter_results.shape)\n",
    "dummy_fa = FactorAnalysis()\n",
    "dummy_fa.fit(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.linalg.eigvals(fa.get_covariance()) > np.mean(np.linalg.eigvals(dummy_fa.get_covariance())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.fit(filter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89081373261106078"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=3\n",
    "fa.get_covariance()[x,x] - fa.noise_variance_[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = cnna.get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))\n",
    "\n",
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[cls])):\n",
    "        z = Z_test[cls][img_num]\n",
    "        x = np.expand_dims(x_test[cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        \n",
    "        output[z] = [cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        #for f in all_features:\n",
    "        #    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[cls][img_num])\n",
    "        \n",
    "        for i in range(len(all_features)):\n",
    "            evidence[all_features[i] + \"/\" + str(cls_features[all_features[i]])] = features_test[cls][i, img_num]\n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, strength]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred5.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][3], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:\\\\filters_pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "agree = 0\n",
    "for _,row in df.iterrows():\n",
    "    if row[\"pred_cls1\"] in row[\"feature_1\"]:\n",
    "        agree += 1\n",
    "print(agree/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
