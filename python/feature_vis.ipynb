{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clinton\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.models\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "import copy\n",
    "import cnn_analyzer as cnna\n",
    "import cnn_builder as cbuild\n",
    "import config\n",
    "import csv\n",
    "import niftiutils.helper_fxns as hf\n",
    "import niftiutils.transforms as tr\n",
    "import importlib\n",
    "import itertools\n",
    "from math import sqrt, log, pi, exp\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange, vectorize, guvectorize\n",
    "from numpy import matmul, diag\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(cbuild)\n",
    "C = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"model_no_pad.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model_frozen.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_img = orig_data_dict['hcc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_ixs = list(range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer(model_frozen, 'conv3d_11', \"D:\\\\filters\", channel_ixs)#, init_img=init_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_trunc = cbuild.build_pretrain_model(model, last_layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "fig = cnna.tsne(filters_by_cls)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.flatten([list(feature_sheet[\"evidence1\"+cls].dropna().values) for cls in C.classes_to_include]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model_conv1 = cbuild.build_pretrain_model(model, last_layer=-6, add_activ=True)\n",
    "model_conv2 = cbuild.build_pretrain_model(model, last_layer=-5, add_activ=True)\n",
    "model_conv3 = cbuild.build_pretrain_model(model, last_layer=-4, add_activ=True)\n",
    "model_dense = cbuild.build_pretrain_model(model, last_layer=-3, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = 'cyst'\n",
    "cls_img_set = orig_data_dict[cls][0]\n",
    "cls_activ_set = model_conv3.predict(cls_img_set)\n",
    "\n",
    "nmf = NMF(4)\n",
    "cls_activ_set_xform = nmf.fit_transform(cls_activ_set.mean((1,2,3)))\n",
    "\n",
    "nmf_comps = [nmf.components_[i] * (nmf.components_[i] > np.median(nmf.components_,0)*2) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_analyzer' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_analyzer.py'>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnna.visualize_layer_weighted(model_frozen, 'conv3d_11', \"D:\\\\filters\", K.constant(nmf_comps[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activs0 = cls_activ_set[:,:,:,:,nmf_comps[1] > 0]\n",
    "activ_map0 = activs0.mean(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activ_map0, _ = tr.rescale_img(np.transpose(activ_map0, (1,2,3,0)), cls_img_set[img_id].shape[:3])\n",
    "activ_map0 = np.transpose(activ_map0, (3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noxkCAACp0QwBAIDU/hcIDu1BotqjagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177a007b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 1\n",
    "alpha = 1.\n",
    "overlaid_img = cls_img_set[img_id] - np.amin(cls_img_set[img_id])\n",
    "overlaid_img = np.stack([((activ_map0[img_id] > np.mean(activ_map0[img_id])*alpha)+.5) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "hf.draw_slices(overlaid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf.draw_slices(cls_img_set[img_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_div(m1, sig1, m2, sig2, one_sided=\"none\"):\n",
    "    #returns kl(p,q) where p~N(m1,s1), q~N(m2,s2)\n",
    "    ret = np.log(sig2/sig1) + (sig1**2+(m1-m2)**2)/(2*sig2**2) - .5\n",
    "    if one_sided==\"less\":\n",
    "        return ret * (m1 < m2)\n",
    "    elif one_sided==\"greater\":\n",
    "        return ret * (m1 > m2)\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_builder' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\cnn_builder.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-6)#, add_activ=True)\n",
    "model_conv2_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-5)#, add_activ=True)\n",
    "model_conv3_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-4)#, add_activ=True)\n",
    "model_dense_pre = cbuild.build_pretrain_model(model, padding=['same','same'], last_layer=-3)#, add_activ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12572068_0', '13092836_1', 'E103354630_0', 'E105921537_0', 'E106010098_0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = sorted(list(feat_count.keys()))\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dr_methods as drm\n",
    "voi_df = drm.get_voi_dfs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = np.concatenate([orig_data_dict[cls][1] for cls in C.classes_to_include], 0)\n",
    "\n",
    "all_conv3_ch = np.empty([0,128])\n",
    "\n",
    "aug_factor = 10\n",
    "for img_id in range(len(Z)):\n",
    "    voi_row = voi_df.loc[Z[img_id]]\n",
    "    for aug_id in range(aug_factor):\n",
    "        img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z[img_id], aug_id)))\n",
    "        activ = model_conv3.predict(np.expand_dims(img, 0))\n",
    "        all_conv3_ch = np.concatenate([all_conv3_ch, activ.mean(axis=(1,2,3))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = all_conv3_ch.mean(0)\n",
    "s = all_conv3_ch.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'arterial enhancement'), (1, 'continuous enhancing rim'), (2, 'delayed isointensity'), (3, 'heterogeneous'), (4, 'hyperintense mass on delayed phase'), (5, 'hypointense without enhancement'), (6, 'infiltrative'), (7, 'lobulated margins'), (8, 'nodular or discontinuous enhancement'), (9, 'progressive centripetal filling'), (10, 'progressive or concentric enhancement'), (11, 'regular spherical hypointense mass'), (12, 'thin well-defined walls'), (13, 'venous washout')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(range(len(all_features)), all_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevant_features = [3,7,10]#[0,1,3,13] hcc\n",
    "img_dir = \"D:\\\\feature_analysis\\\\cholangio\"\n",
    "if not exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "num_rel_f = len(relevant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D = np.empty((8,8,4))\n",
    "for x in range(D.shape[0]):\n",
    "    for y in range(D.shape[1]):\n",
    "        for z in range(D.shape[2]):\n",
    "            D[x,y,z] = (D.shape[0]-.5-x)**2 + (D.shape[1]-.5-y)**2 + 4*(D.shape[2]-.5-z)**2\n",
    "\n",
    "def get_shells(activ, D):\n",
    "    shell4 = activ[0, D > 85, :].mean(axis=0)\n",
    "    shell3 = activ[0, (D <= 85) & (D > 62), :].mean(axis=0)\n",
    "    shell2 = activ[0, (D <= 62) & (D > 39), :].mean(axis=0)\n",
    "    shell1 = activ[0, D <= 39, :].mean(axis=0)\n",
    "    return np.expand_dims(np.stack([shell1, shell2, shell3, shell4], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_conv3_ch = {f:np.empty([0,12,12,6,128]) for f in all_features}\n",
    "feature_conv2_ch = {f:np.empty([0,12,12,6,128]) for f in all_features}\n",
    "#feature_conv3_sh = {f:np.empty([0,4,128]) for f in all_features}\n",
    "aug_factor = 80\n",
    "for f_ix in relevant_features:\n",
    "    f = all_features[f_ix]\n",
    "    Z_f = Z_features[f]\n",
    "    for img_id in range(len(Z_f)):\n",
    "        voi_row = voi_df.loc[Z_f[img_id]]\n",
    "        for aug_id in range(aug_factor):\n",
    "            img = np.load(os.path.join(C.aug_dir, voi_row['cls'], \"%s_%d.npy\" % (Z_f[img_id], aug_id)))\n",
    "            activ = model_conv2_pre.predict(np.expand_dims(img, 0))\n",
    "            feature_conv2_ch[f] = np.concatenate([feature_conv2_ch[f], activ], axis=0)\n",
    "            #activ = model_conv3_pre.predict(np.expand_dims(img, 0))\n",
    "            #feature_conv3_ch[f] = np.concatenate([feature_conv3_ch[f], activ], axis=0)\n",
    "            #feature_conv3_sh[f] = np.concatenate([feature_conv3_sh[f], get_shells(activ, D)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2_ch_plus = copy.deepcopy(feature_conv2_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv2_ch_plus[f][conv2_ch_plus[f] < 0] = 0\n",
    "    conv2_ch_plus[f] = conv2_ch_plus[f].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3_ch_plus = copy.deepcopy(feature_conv3_ch)\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    conv3_ch_plus[f][conv3_ch_plus[f] < 0] = 0\n",
    "    conv3_ch_plus[f] = conv3_ch_plus[f].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3_sh_plus = {}\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    activ = conv3_ch_plus[f]\n",
    "    shell4 = activ[D > 85, :].mean(0)\n",
    "    shell3 = activ[(D <= 85) & (D > 62), :].mean(0)\n",
    "    shell2 = activ[(D <= 62) & (D > 39), :].mean(0)\n",
    "    shell1 = activ[D <= 39, :].mean(0)\n",
    "    conv3_sh_plus[f] = np.stack([shell1, shell2, shell3, shell4], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_avgs = np.zeros((num_rel_f,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv2_ch_plus[f].mean((0,1,2))\n",
    "    \n",
    "channel_separations = np.empty((num_rel_f,128)) # separation between channel mean activations for the relevant features\n",
    "for i in range(num_rel_f):\n",
    "    channel_separations[i] = (np.amax(feature_avgs, 0) - feature_avgs[i]) / np.mean(feature_avgs, 0)\n",
    "\n",
    "channel_separations *= 10\n",
    "\n",
    "W = np.zeros((num_rel_f,128))\n",
    "for ch_ix in range(128):\n",
    "    #f_ix = list(channel_separations[:,ch_ix]).index(0)\n",
    "    #W[f_ix,ch_ix] = channel_separations[:,ch_ix].mean()\n",
    "    W[:,ch_ix] = np.median(channel_separations[:,ch_ix]) - channel_separations[:,ch_ix]\n",
    "    \n",
    "W[W < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avgs = np.zeros((num_rel_f,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_ch_plus[f].mean((0,1,2))\n",
    "    \n",
    "channel_separations = np.empty((num_rel_f,128)) # separation between channel mean activations for the relevant features\n",
    "for i in range(num_rel_f):\n",
    "    channel_separations[i] = (np.amax(feature_avgs, 0) - feature_avgs[i]) / np.mean(feature_avgs, 0)\n",
    "\n",
    "channel_separations *= 10\n",
    "\n",
    "W = np.zeros((num_rel_f,128))\n",
    "for ch_ix in range(128):\n",
    "    #f_ix = list(channel_separations[:,ch_ix]).index(0)\n",
    "    #W[f_ix,ch_ix] = channel_separations[:,ch_ix].mean()\n",
    "    W[:,ch_ix] = np.median(channel_separations[:,ch_ix]) - channel_separations[:,ch_ix]\n",
    "    \n",
    "W[W < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_avgs = np.zeros((4,128))\n",
    "for i, f_ix in enumerate(relevant_features):\n",
    "    f = all_features[f_ix]\n",
    "    feature_avgs[i] = conv3_sh_plus[f].mean(0).max(0)\n",
    "    \n",
    "channel_separations = np.empty((4,128))\n",
    "for i in range(4):\n",
    "    channel_separations[i] = np.amax(feature_avgs, 0) - feature_avgs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "active_neuron_ixs = np.where(h_ic_rot[0] > 0)\n",
    "\n",
    "num_active_neurons = active_neuron_ixs[0].size\n",
    "\n",
    "H = h_ic[h_ic > 0]\n",
    "np.matmul(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_spatial_overlap(w, f_c3_ch):\n",
    "    relevant_features = ch_weights.keys()\n",
    "    \n",
    "    ch_weights2 = np.zeros(num_rel_f,128)\n",
    "    for ch in range(128):\n",
    "        f_c3_ch[:,:,:,:,ch] = (f_c3_ch[:,:,:,:,ch] - np.mean(f_c3_ch[:,:,:,:,ch]))# / np.std(f_c3_ch[:,:,:,:,ch])\n",
    "        \n",
    "        if ch_weights[ch] > 0:\n",
    "            w = np.zeros(f_c3_ch.shape[:4])\n",
    "            for i in range(128):\n",
    "                if ch_weights[i] > 0:\n",
    "                    w += ch_weights[i] * f_c3_ch[:,:,:,:,i]\n",
    "            w = w / np.sum(ch_weights)\n",
    "            ch_weights2[ch] = np.sum(f_c3_ch[:,:,:,:,ch] * w)\n",
    "            \n",
    "    return ch_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls = 'cholangio'\n",
    "cls_img_set = orig_data_dict[cls][0]\n",
    "#cls_activ_set = model_conv3_pre.predict(cls_img_set)\n",
    "\n",
    "img_id = 0\n",
    "x = cls_img_set[img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_ic = [model_conv3_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "h_ic = [model_conv2_pre.predict(np.expand_dims(np.rot90(x,r),0))[0] for r in range(4)]\n",
    "#h_ic_plus = model_conv3.predict(cls_img_set)[img_id]\n",
    "#h_ic = model_conv3_pre.predict(np.expand_dims(x,0))[0]\n",
    "\n",
    "h_ic_plus = copy.deepcopy(h_ic)\n",
    "for r in range(4):\n",
    "    h_ic_plus[r][h_ic_plus[r] < 0] = 0\n",
    "\n",
    "h_ic_rot = [np.rot90(h_ic_plus[r], 4-r) for r in range(4)] #rotated back into original frame\n",
    "#h_ic_rot = [np.rot90(h_ic[0], r) for r in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_ic_rot = np.array(h_ic_rot)\n",
    "test_neurons = h_ic_rot.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = [h_ic_rot[a][active_neuron_ixs] for a in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.sum(3*np.matmul(H[0], W) - np.matmul(H[1], W) - np.matmul(H[2], W) - np.matmul(H[3], W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h_ca = {f_ix: feature_conv3_ch[all_features[f_ix]].mean((0,1,2,3)) for f_ix in relevant_features}\n",
    "h_ca_plus = {f_ix: feature_conv3_ch[all_features[f_ix]][feature_conv3_ch[all_features[f_ix]] > 0].mean((0,1,2,3)) for f_ix in relevant_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = np.tile(h_ca[f_ix], list(h_ic.shape[:3])+[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f_ix in relevant_features:\n",
    "    w_ica[f_ix] = h_ic_plus / (np.abs(h_ic_plus - h_ca[f_ix]) + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = cls_img_set[img_id]\n",
    "test_neurons = model_conv3_pre.predict(np.expand_dims(x,0))[0]\n",
    "test_neurons[test_neurons < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f_ix in relevant_features:\n",
    "    img_dir = \"D:\\\\feature_analysis\\\\\"+all_features[f_ix]\n",
    "    if not exists(img_dir):\n",
    "        os.makedirs(img_dir)\n",
    "        \n",
    "    f_c3_ch = feature_conv3_ch[all_features[f_ix]]\n",
    "    avg_f_conv3_ch = f_c3_ch.mean((1,2,3))\n",
    "    f_m = avg_f_conv3_ch.mean(0)\n",
    "    f_s = avg_f_conv3_ch.std(0)\n",
    "\n",
    "    ch_weights[all_features[f_ix]] = np.log(kl_div(m, s, f_m, f_s, 'less')+1) #kl_div(m, s, f_m, f_s, 'less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_id = 0\n",
    "z = orig_data_dict[cls][1][img_id]\n",
    "\n",
    "ch_weights2 = get_spatial_overlap(ch_weights, feature_conv3_ch, z)\n",
    "ch_weights2[ch_weights2 < np.median(ch_weights2) / 2] = 0 #np.median(ch_weights2) / 2\n",
    "ch_weights[all_features[f_ix]] *= ch_weights2\n",
    "ch_weights[all_features[f_ix]] /= np.mean(ch_weights[all_features[f_ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_saliency_map(W, test_neurons, num_rel_f):\n",
    "    sal_map = np.zeros((num_rel_f, *test_neurons.shape[:3]))\n",
    "    for f_num in range(num_rel_f):\n",
    "        for ch_ix in range(test_neurons.shape[-1]):\n",
    "            sal_map[f_num] += W[f_num, ch_ix] * test_neurons[:,:,:,ch_ix]\n",
    "        sal_map[f_num] /= np.sum(W[f_num])\n",
    "        \n",
    "    #for f_num in range(num_rel_f):\n",
    "    #    for spatial_ix in np.ndindex(test_neurons.shape[:-1]):\n",
    "    #        sal_map[f_num, spatial_ix] = sal_map[f_num, spatial_ix]**2 / sal_map[:, spatial_ix].sum()\n",
    "            \n",
    "    return sal_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neurons = h_ic_rot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADPCAYAAAD21NURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGnZJREFUeJzt3VuIndX9xvHfnskke87HHDQHowkxQaH1rzdeaKkXFhHx\nQr0IpYjWJgSRlIriqfSqVm1RJLEWWvBC1F60MaAgaGiRtigVeuOxYiRjUjOZZDLn7Dlm/y9KoP3T\n9Tyz90L80/X93D6ud7/7fdf77tUp60mlXq8HAABAqVq+7hMAAAD4OrEYAgAARWMxBAAAisZiCAAA\nFI3FEAAAKBqLIQAAUDQWQwAAoGgshgAAQNFYDAEAgKKtauQ/rlar9a6urmReqVSaPpGWlrx1mfrs\n3GO78efPn09m7pq4POezZ2dn5dhNmzbJ/NixYzJX5z4zMyPHdnR0yHz9+vUy/8c//pHMXKu6y9es\nWRNDQ0PJvL293Y5PmZqakmNz50Nra6vMFxYWmj62O7ec6+4+u1qtyvzs2bMyHxwclPnnn38uc8U9\nZ9u2bZO5++7Dw8MNn9NKrFq1KgYGBpJ5T0+PHK/mmpvnTu5cXF5ebnqsy9U713Hfq6+vT+anTp2S\nuZvnR48elbkyNzcn8y1btsjcffcTJ04ks5x/KWNpaSmWl5ft4qTSyIcMDQ3Vb7755mSufgTcBHMv\nO0d9tju2u0nq2BERtVotma1apdeb7tidnZ1Nf/Y777wjx/7iF7+Q+V133SXz1atXJ7O//OUvcuxV\nV10l8/3798v8xz/+cTJbWlqSY9WCIOKf9+wnP/lJMr/yyivlePXj9+abb8qxbq66hZj7AVOLSHU/\nI/y5ueu+uLiYzNz32rVrl8xfeeUVmX/ve9+T+R133JHM3Pvh3Xfflfnhw4dl7q77vffeK3NFvd9r\ntVo8+OCDyfzGG2+Ux+7u7k5mb731VtPnFeHnQ1tbm8zVYsxdb3ds9c6N0Isl9z8Cb7nlFpkfOHBA\n5m6e33bbbTJXPvnkE5kfPHhQ5u6ePvDAA8nMLUBV/uWXX8b8/LxdDPF/kwEAgKKxGAIAAEVjMQQA\nAIrGYggAABSNxRAAACgaiyEAAFC0hnqGlpeXZafG6dOnk5nrIFDbbiP8lmG1ZdFt+XXb3x11bjk9\nQSuxe/fuZHbkyBE51m0xffvtt2Wuujw2btwox953330yd90qanuru6au5mHNmjWxY8eOZH7NNdfI\n8WqrtatKcNt6XY+Q6yHJ6QJzPSPz8/MyV8+J2678hz/8Qeau68cd/09/+lNTWUTE008/LfNLL71U\n5h9++KHMlZzup2q1Gtu3b0/mrivs/fffT2auMsS979W7JcLfb/W93TzOOXZEyO4mVW0REfHCCy/I\nXN2vCP/u++Mf/5jM/v73v8uxqs4kIqK3t1fm7rsr7ndU5St95/GXIQAAUDQWQwAAoGgshgAAQNFY\nDAEAgKKxGAIAAEVjMQQAAIrW0J7y8+fPy+2Want77r9C7LbWqe3xbmud20rpxqvtjO57ue3tZ86c\nkfnPf/7zZPbtb39bjlX/6nSE36b52GOPJbO9e/fKsZOTkzJ391ttMXdjnaWlpRgdHU3mv/vd7+T4\nwcHBZOb+1epz587J3G1Jdsd324oVt915aGhI5idPnkxmqpYjIuI73/mOzL/1rW/JPKeSQG1Hjoh4\n4oknZO62FKv5EqG3crt3k3ovzs7OynP77LPP5LG3bt2azNzW+unpaZm7ueaqVlSdysLCghzr5op7\nvxw7diyZuXfunj17ZO6qM9y2/y+//DKZHT58WI595plnZO4qIvr7+2WurmtuBc1K8JchAABQNBZD\nAACgaCyGAABA0VgMAQCAorEYAgAARWMxBAAAisZiCAAAFK2hnqHW1lbZFbBhw4ZktnnzZntsxXV1\nzM/PJzPXvaC6OFYyXnVquN6Yo0ePynzTpk0yv+eee5KZ6335/PPPZb527VqZq86p6667To7t6+uT\n+dTUlMxV74TrXllJruaE6/JR88H1Tl166aUyd90vrgNF9Vq5ee46jg4dOiTzL774IpndfPPNcqzr\npXF9XevWrZN5rVZLZq4b5ve//73Md+7cKXPXv6LmoutfUX07LS0tcq6uX79eHlvNZXc/XLfSiRMn\nmv7sCP0Muveaux+//e1vZT42NpbMfvjDH8qxr7/+usy3bdsm88svv1zmqmfMzdMjR47I3D1j7v2h\nuqVyuv7ce+0C/jIEAACKxmIIAAAUjcUQAAAoGoshAABQNBZDAACgaCyGAABA0VgMAQCAojXUM1St\nVmP79u3JXHVHuC4f14kzOzsrc9UN8eSTT8qxuT1Eqj9B9ZdE+H4l1d0UEfHaa68lM3fNOjs7Ze46\nayYnJ5PZq6++Kse67+0+W1H9RxER7e3tMm9ra5M9Je7cVI+J60/69NNPZe46b/bu3Stzdd3dc+A6\nbRzVefPee+/Jsa6Xyj2j7p6p6+Lm00p7TFLcdVW56maJ0HO9UqnIvp6enh55bDUXJyYm5Njx8XGZ\nb926VeZ33XWXzBV3zdz9dB1Hyk033STzjRs3Nn3sCN/Ho7gur9zr5sarc3fPr3r+V/pbwl+GAABA\n0VgMAQCAorEYAgAARWMxBAAAisZiCAAAFI3FEAAAKBqLIQAAULRKIx0Z1Wq1vnnz5mSu+nw++ugj\neez169fL/IknnpB5Ti+Nk9MzVK1W5VjXefPhhx/KXF03d00WFhZk7s793LlzTX+2u6aOmreua2N+\nfl7m4+PjsW3btmT+3HPPyfGqF8b1qzz88MMyd9dt9erVMlfXTc3jCN+309XVJXPVW3PixAk51vVt\nubnsunzUuY+MjMix7jlR/Urusx33nJ09ezaZjYyMyD4f18+m3l2qcy4i4vvf/77M3Vx0z7jqjXLH\nVu+1CH+/VO66fNx1c/PczQeVu24oN49zPjsiZLeb6yiam5tLZseOHYtarWYLmPjLEAAAKBqLIQAA\nUDQWQwAAoGgshgAAQNFYDAEAgKKxGAIAAEVraH/z+vXr4/7770/maktiZ2enPPbjjz8uc7VVMkJv\nl3af7bYMTk1NyXx2djaZua3zfX19Mh8aGmp6vNpWuxJuG7fapu3GutxdF7VNU22zjIj47LPPZL5l\ny5Y4cOBAMnfbtNUW9EcffVSOdVvj3Vx1VRm1Wi2ZqXkc4a+ruy7q3N125dyaCDff1Ll3dHTIse6e\nqS3DEX6rd05tiHonb9q0KZ566qlk7t656prdeeed/uQEt3Xe3U8119w8d8+Ym+fqOcn9LXKfncM9\ng26euvniqO/m7vfk5GQyc9vyL+AvQwAAoGgshgAAQNFYDAEAgKKxGAIAAEVjMQQAAIrGYggAABSN\nxRAAAChaQz1DEc33u7gOgpxOG8f1I0xPT8tcdbNE6G4I13Gg+pEiIrq7u2WurstX2dURoftTXDeK\n67RwnTaq28V1cbhOmnq9Lr97TkdSbheH+2zXoaLmmxvrrqubb+q79/f3y7Hu3HJ7rVQ3lOsRUmMj\n/HPk5oTqCnLHVmN7e3vld3Pn5e634s47t29L3RP3znWf7d4fary7Zu7cXGeV+71R1829s3PPLefd\n5zrzJiYmkpmbKxfwlyEAAFA0FkMAAKBoLIYAAEDRWAwBAICisRgCAABFYzEEAACKxmIIAAAUraGe\nofPnz8tOHtWv8Oyzz8pju/4F15+gOgxcj5DrtHE9RTm9Ei7v6emRuep+cP0K7e3tMnfXpbe3N5m5\nXpipqSmZu2uuctcp4/o0KpVKVv/Kvn375LEVd83dZ7t7rvo4XI/QwMCAzJ22trZkpuZSRMTY2FjW\nZzvqvrhOLHfNXS/N+Pi4zNW1cXNZ9e24ee6Ofe+99yYz1wuX273knhP1vd2xh4aGZO6ek2q1mszc\nu8lx98Tl6rq7niB3z1x+8uRJmXd0dCSzlbyzm8n+7TNW9F8BAAD8l2IxBAAAisZiCAAAFI3FEAAA\nKBqLIQAAUDQWQwAAoGgshgAAQNEaKj1wvRSup0DJ6RGKiJicnExmuZ0X6jtH6O/tztt1mKjOioiI\nWq2WzHI6JyJ8P4P6bq6L49y5czJ3vTLr1q1reqybp5VKRX43d09drrgeEtffpOZDhJ5Pqucjwj9H\nrhMrpwvMPSeqVybCz3U1J9xcdZ037rq5767OzY1VHUVunjvq/eDmsXs/uPvl7veGDRuSWe655fzO\n5fTlRPi5ltNjlNsj5M7N9Wmp31l3v1Vnnuri+1f8ZQgAABSNxRAAACgaiyEAAFA0FkMAAKBoLIYA\nAEDRWAwBAICiNby1vq2tLZmrbb0//elP5bEfeughmbvtjGpL4dTUVNNjI/zWerV1b2BgQI512zhP\nnjwpc7U11m3pdVsO1b2OiJiYmGj62IuLizJ390Rt83Sf7baA1+t1WfXgrstvfvObZPaDH/xAjnXz\n3G1vPX36tMzVluPceguXq+O7e+a21roty+66qu3z7jnKrZHo7OxsOnfvh7Vr1yazer0u55ObawcP\nHkxm+/fvl2Pd872wsCBzd27qnrljuzoTN8/VfHBzwV0XV3/hrov67rnb9t13GxwcbPr47jdcVa24\nsRfwlyEAAFA0FkMAAKBoLIYAAEDRWAwBAICisRgCAABFYzEEAACKxmIIAAAUraGeIddL0d3dncxc\nz4fjun5UR0GlUml6bITvX1Hn5robXGeN68RQfT051yzC96uoc+vr65NjVUdRhD831QXirqnrhYnQ\n99zNJ5cr7pq7Pp2uri6Zu34nxfXhTE5Oylx1CblrljuXXU+R6imZnZ2VY12XmDu36elpmat75uaD\n68RR3DXP4eah+179/f0yV79T7v3gvrd7p6u+Hfe92tvbZe56hNy7zX33nGO7DiT3zlfvPvcbnPPO\nvYC/DAEAgKKxGAIAAEVjMQQAAIrGYggAABSNxRAAACgaiyEAAFA0FkMAAKBoDfUMVSoV2cGg+hVc\n/8kjjzwi8wMHDshc9WmoTpoI3/2Q0yvj+jRcN4vrhejp6Ulmri/DdRi5bijVC+H6TVQnVUTE2NiY\nzNVcc10cLq9UKnLOuO+mrsvLL78sx+7evVvmruvDdQGp+ajmUoSfL6pHyOVuPrguH8e9f9S5uWua\n2/3iOlTUOyLns+v1urynrvNGPQfPP/+8HLtnzx6Zu++V04Hk+nDcO9v1DCnut8h1UuVS89xdF/f8\nu+uS837I+Y1eaQcRfxkCAABFYzEEAACKxmIIAAAUjcUQAAAoGoshAABQNBZDAACgaCyGAABA0Rou\nNVAdKoODg8msVqvJ47reiOnpaZmrPh7X1eN6Plz3g+qlyD2261dQ412vgzM7Oytz9b1z+zJcN4Tq\nGXJcj0i9XpedGe6eqn4md09ch5HLHdW3o57tlXB9Omouu+syMjLS1Dld4O6Zuq7u3aTeexF+rub0\nDLnnRM31SqUi56rrjVHPuOsoc307MzMzMnfvRXU/XV+OO7b7PRkfH09m7nu7frXc7jgl9509MTEh\nczef1Lm7e6KeoZW+1/jLEAAAKBqLIQAAUDQWQwAAoGgshgAAQNFYDAEAgKKxGAIAAEVraC9dS0tL\n01sx3bbb9vZ2mT/88MMyf/rpp5OZ2+bptiO6ra9ue6virovLz5w5k8zcebntiu6e5GzzVtuFI/wW\nVLWN031vt427UqnYLayKGuvO7Ve/+pXM9+3bJ3P33dQz6uoruru7s/LR0dFk5uoOcusx3Ll1dHQk\ns6WlpazPVs9ohH+O1PHdWLWtv7+/3269V9T7w707XnrpJZnv3r1b5u6drbbmu2dk06ZNMnfzQVWS\nrOTdo7j3Ym9vr8zVfHHfy+Xu/ZFTveGo68rWegAAgBVgMQQAAIrGYggAABSNxRAAACgaiyEAAFA0\nFkMAAKBoLIYAAEDRGuoZitBdAKoPo7OzUx7XdRi4nhA13n226wlx/Qmqx8h1J7h8pR0J/4nrpHAG\nBgZkrro8HNUTFOHvmbouq1bpae26ONzxXYeKui6qzyZC98JERNRqNZm7nhI13nX9uGfUjVfz0X0v\n1xXm7rm7Zz09PcnMdcO4uew6cdw7QPVWuf6ldevWJbN6vS7Pzc1V1RszPj4uxzruOXDvRfVOd/PU\nfba7n+r9ojqIIvT9isj/PVHzxT3fw8PDMne/o26uqjz3+V8J/jIEAACKxmIIAAAUjcUQAAAoGosh\nAABQNBZDAACgaCyGAABA0VgMAQCAojW0OX9hYUF2DezatSuZuS4O16/guiFU54XrCXI9IurYEbpf\nwfU+uH4E192g+jbcWNWtEuHPTX23s2fPyrHO3NyczFX3iutXcp02ra2tsivEdaiofhbXA+S6OFwX\nSE7PiHtO3DOYM9fdXHT3zPWQuTmhzt197y+++ELmTs49c/NFPSfnz5+X1829s1X3i7veY2NjMnfc\nc5TTsebe9466JxdddJEc657Brq4umbu5pK7b6OioHOv6l9zvhbtnKnc9Q+r9sdLOK/4yBAAAisZi\nCAAAFI3FEAAAKBqLIQAAUDQWQwAAoGgshgAAQNFYDAEAgKI11DO0evXquOSSS5K52uvvOgpUX06E\n7zB4/PHHk9kjjzwix3Z2dsrc9U6oHhLX++ConhB3fHdNVR9OxD97pRT1vV1fhutHyeG+t+u7WF5e\nlh0rbrz6fNdZ4zz//PMy/9GPfiRzNZdd10/uM6zmcl9fnxzr5ot7P7ieEtXfdOzYMTk2993lumPU\nPXNdYidOnEhmGzZskM+pe/eovLW1VY51PUAHDx6UuZvnqjvOffbU1JTM3e+Beo7c2P7+fpm7ueZ+\nb9R3O3nypBzrzt3NF/cMqudgZmZGjlW/Va6b7QL+MgQAAIrGYggAABSNxRAAACgaiyEAAFA0FkMA\nAKBoLIYAAEDRKm6r3r+qVqv1zZs3J/Of/exnyWx0dFQe+5vf/KbM3bY/tfXWbaXcu3evzN2WQrXl\n2G1Pd1sh3ZZjdW5u67zbCum2mKptu729vXJszjbLiIiRkZFk5u6Xu+aLi4uxY8eOZP7LX/5Sjm9v\nb28qi/BbZycnJ2W+du1amd9+++3JbG5uTo51W1RdrraBu/N2W8jd9nW3Nf/48ePJ7NSpU3Jsd3e3\nzC+//HKZu8qC4eHhZOaeYbXFfGFhIS677LJk7ua5eo7c8+2qN9zWfPe977vvvmTm5rl7P6x0q/Z/\n4uap+61yn+2u20cffdT0sd08HhgYkPnGjRtl/sYbb8hcUe/8mZmZWF5e1n0owV+GAABA4VgMAQCA\norEYAgAARWMxBAAAisZiCAAAFI3FEAAAKBqLIQAAULSGeoZaW1vrnZ2dyfyiiy5KZg899JA8tuov\nivDdMT09PcnM9UosLi7KfM+ePTJ33RCK69twvTSK67RwvRLj4+MyVz1ErlPC9S+53hnVl+GumZtL\nc3Nzst/JfbcXX3wxmbl+FDcXXQdKpaLrNNSzcPfdd8uxub1U6l2TM88j/HVx9/yDDz5o+thXXXWV\nzGu1msx37twp8yNHjiQz972UmZmZGBoaSuauN+bXv/510+flesTcezGnd2r//v1yrHuG3DOqup1c\nb5w7tju3M2fOyFz1/bmOoq1bt8r86quvlrn7PTp06FAyc79Val1y5syZWFxcpGcIAABAYTEEAACK\nxmIIAAAUjcUQAAAoGoshAABQNBZDAACgaCyGAABA0fTG//+jUqnIzo2RkZFkdvHFF8tjuy6gtrY2\nmU9OTiYz14/iOi9cj5A6d9etkNuvovo8XDeDyycmJmSu5sKpU6fk2CuuuELmZ8+elbnq61BzIcLf\nk3q9Lvs+jh8/Lsere9LR0SHHqo4Sd+wI/5yo+ZbbS5XTt+W6fHLHHz16VObqHeHeTTt27JC569RS\nHUcREZdddlkye//99+VYN99UX4/rrFHPqHvfu3nu+njcNVV9PO4Zct177jlRuXuG3Dx2nVWnT5+W\nufru7rO/+93vyvyTTz6R+ccffyxz1VP05z//WY5113Ul+MsQAAAoGoshAABQNBZDAACgaCyGAABA\n0VgMAQCAorEYAgAARWMxBAAAilZxnQr/9h9XKnXV39DZ2ZnMvvGNb8hjP/bYYzJfs2aNzFW3g+rS\niPBdHHfeeafMVXdDbqeFut65nz02Nibz6elpmateGdef5HqGXF/G8PBwMnO9MCuh5pP7btdee20y\n27Nnjxx7ww03yNx1KLmuH9XHceutt8qxbi62trbKXHG9MY7rtRodHZV5f39/MnPfy537tm3bZO56\na/76178mM3dP1Dt5enpavldd/9pNN92UzK6//no59pprrpG5641xvwfqnrm+HHc/crh38rlz52Su\n3nsR+n5H6HeXe2+6e9Lb2yvzjRs3ylzNc/cMqvkwMzMTS0tL+kEJ/jIEAAAKx2IIAAAUjcUQAAAo\nGoshAABQNBZDAACgaCyGAABA0RraWt/a2lpXW/Pm5+eTmdsK6c5jaGhI5jlbY1ta9JrQbSlcXFxs\neqzjagHU8cfHx5seGxGxevVqmavv7baQui3BjczLRo+9kq333d3dycxtpVbPiLpmEf45GRwclLmr\niVD31D0HjptP6v2gsghf8+Cuq6PuqZtP7hnNnetqq/fs7Kwcq+bxxMRE9PX1JXM3z9U2bnc/3bvF\nzWNXb6GeIzfP3bvLXRf1fnHHdvPYzaWcigo3j908dd/NVRao409NTcmxbp4vLi6ytR4AAEBhMQQA\nAIrGYggAABSNxRAAACgaiyEAAFA0FkMAAKBoLIYAAEDRGuoZamlpqauuANUd4bpdcnuIVP+C66Rw\nnRc55+Z6H1wfR07PkOOuqetnUtc8535F+M6KHO6a1mo12UWiOi0i9D1x19Tl7rq4666+V7VabXps\nhO9IUefuvpeb57ldPm1tbU2PdZ+d22ujPt9dc/VuGx8fl90vXV1d8tiK65RxcueDumbqXkf45yCn\nx8ydt3s3ud8iN17Nh5xut4ivtjuuVqvJXM23qampWFpaomcIAABAYTEEAACKxmIIAAAUjcUQAAAo\nGoshAABQNBZDAACgaCyGAABA0RrqGapUKqcjYvirOx3g/4X/iYi/fd0nAXzFmOcowSX1en2t+48a\nWgwBAAD8t+H/JgMAAEVjMQQAAIrGYggAABSNxRAAACgaiyEAAFA0FkMAAKBoLIYAAEDRWAwBAICi\nsRgCAABF+18F+FCQ88z7+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223869580f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = orig_data_dict[cls][1][img_id]\n",
    "\n",
    "#for f_num, f_ix in enumerate(relevant_features):\n",
    "sal_map = get_saliency_map(W, test_neurons, num_rel_f)\n",
    "for f_num in range(num_rel_f):\n",
    "    sal_map_f = sal_map[f_num]\n",
    "    if False:\n",
    "        w = np.zeros(test_neurons.shape[:3])\n",
    "        for ch_ix in range(128):\n",
    "            if W[f_num, ch_ix] > 0:\n",
    "                w += W[f_num, ch_ix] * test_neurons[:,:,:,ch_ix]\n",
    "        sal_map_f = w / np.sum(W[f_num])\n",
    "        #sal_map_f0, _ = tr.rescale_img(sal_map_f0, x.shape[:3])\n",
    "        \n",
    "    sal_map_f = tr.scale3d(sal_map_f, (2,2,2))\n",
    "\n",
    "    #for img_id in range(len(cls_img_set)):\n",
    "    alpha = 1.5\n",
    "    overlaid_img = x - np.amin(x)\n",
    "    overlaid_img = np.stack([((sal_map_f > np.mean(sal_map_f[sal_map_f > 0])*alpha)+.3) * overlaid_img[:,:,:,i] for i in range(3)], 3)\n",
    "    hf.draw_slices(overlaid_img[:,::-1,:], save_path=img_dir+\"\\\\%s (%s).png\" % (z, all_features[relevant_features[f_num]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(C.model_dir, \"models_305.hdf5\")) #models_305\n",
    "model_dense_outputs = cbuild.build_pretrain_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 24, 12, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([orig_data_dict['cyst'][0][0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "filters_by_cls = {cls: model_dense_outputs.predict(orig_data_dict[cls][0], verbose=False) for cls in C.classes_to_include}\n",
    "filter_results = np.concatenate([filters_by_cls[cls] for cls in C.classes_to_include], axis=0)\n",
    "\n",
    "filter_avgs = np.mean(filter_results, axis=0)\n",
    "filter_stds = np.std(filter_results, axis=0)\n",
    "\n",
    "#filter_cls_avg_unscaled = {cls: np.mean(filter_results[cls], axis=0) for cls in C.classes_to_include}\n",
    "#filter_cls_avg_scaled = {cls: np.mean(filter_results[cls], axis=0) / filter_avgs for cls in C.classes_to_include}\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"central scar\")\n",
    "all_features = list(feat_count.keys())\n",
    "cls_features = {f: [c for c in C.classes_to_include if f in features_by_cls[c]] for f in all_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = dict(zip(*np.unique(features_by_cls['colorectal'], return_counts=True)))\n",
    "for k in z:\n",
    "    print(k, \" (\",z[k],\")\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash_per_dim(vector, eps = 10**-10):\n",
    "    for i,x in enumerate(vector):\n",
    "        vector[i] *= x / (1 + x**2)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = model.layers[-3].get_weights()[0]\n",
    "bias = model.layers[-3].get_weights()[1]\n",
    "\n",
    "gamma, beta, mu, var = model.layers[-2].get_weights()\n",
    "\n",
    "eff_bias = (np.zeros(6) + bias - mu) / var**.5 * gamma + beta\n",
    "eff_mult = (np.ones(6) + bias - mu) / var**.5 * gamma + beta - eff_bias\n",
    "\n",
    "W_eff = W * eff_mult# + eff_bias\n",
    "\n",
    "unit_relevance = np.empty(num_units)\n",
    "for u_ix in range(num_units):\n",
    "    unit_relevance[u_ix] = np.amax(W_eff[u_ix]) - np.amin(W_eff[u_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_filter_results = np.apply_along_axis(lambda X: squash_per_dim(X), 0, filter_results / (2*filter_avgs) * unit_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"central scar\")\n",
    "\n",
    "feature_filter_means = {}\n",
    "feature_filter_stds = {}\n",
    "feature_filters_scaled = {}#{cls: {} for cls in features}\n",
    "feature_filters = {f:np.empty([0,100]) for f in all_features}\n",
    "\n",
    "for f in all_features:\n",
    "    for cls in C.classes_to_include:\n",
    "        x_features = orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_features[f]))]\n",
    "        if x_features.size > 0:\n",
    "            feature_filters[f] = np.concatenate([feature_filters[f], model_dense_outputs.predict(x_features, verbose=False)], axis=0)# / filter_avgs\n",
    "        \n",
    "    feature_filters[f] = (feature_filters[f] - filter_avgs) / filter_stds\n",
    "    \n",
    "    feature_filter_means[f] = np.mean(feature_filters[f], axis=0)\n",
    "    feature_filter_stds[f] = np.std(feature_filters[f], axis=0)\n",
    "\n",
    "    feature_filters_scaled[f] = feature_filter_means[f] / filter_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(all_features) # number of features\n",
    "num_units = 100 # number of dense units\n",
    "\n",
    "num_annotations = 8\n",
    "Z_test = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "indices_f = [orig_data_dict[cls][1] for cls in C.classes_to_include]\n",
    "indices_f = hf.flatten(indices_f)\n",
    "\n",
    "fixed_indices = np.empty([num_features, num_annotations])\n",
    "for f_ix,f in enumerate(all_features):\n",
    "    fixed_indices[f_ix, :] = np.where(np.isin(indices_f, random.sample(set(Z_features[f]), num_annotations)))[0]\n",
    "fixed_indices = fixed_indices.astype(int)\n",
    "\n",
    "test_indices = np.where(np.isin(indices_f, Z_test))[0]\n",
    "\n",
    "z_states = np.array([z for z in itertools.product([0,1], repeat=num_features) if sum(z) <= 4 and sum(z) >= 2])\n",
    "num_states = len(z_states)\n",
    "num_imgs = filter_results.shape[0]\n",
    "z_states_bool = [tuple([bool(x) for x in z]) for z in z_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_theta(k, alpha=.5, beta=.5, **kwargs):\n",
    "    if len(kwargs) == 0:\n",
    "        mu = np.empty([num_features, num_units])\n",
    "        sigma = np.empty([num_features, num_units])\n",
    "        for i in range(num_features):\n",
    "            mu[i] = feature_filter_means[all_features[i]]\n",
    "            sigma[i] = feature_filter_stds[all_features[i]]\n",
    "        sigma[sigma > 1] = 1\n",
    "        m = filter_avgs\n",
    "        s = filter_stds\n",
    "\n",
    "        theta_i = scipy.random.normal(size=num_features)\n",
    "        theta_ij = scipy.random.normal(size=[num_features-1, num_features])\n",
    "    else:\n",
    "        mu = kwargs['mu']\n",
    "        sigma = kwargs['sigma']\n",
    "        m = kwargs['m']\n",
    "        s = kwargs['s']\n",
    "        theta_i = kwargs['theta_i']\n",
    "        theta_ij = kwargs['theta_ij']\n",
    "    \n",
    "    print(\"Initializing probabilities...\")\n",
    "    p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "    p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "    p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "    \n",
    "    print(\"Running EM:\")\n",
    "    for jj in range(k):\n",
    "        print(\"   Iteration\", jj, end=\"...Update thetas...\")\n",
    "        theta_i, theta_ij = im.update_thetas(np.sum(p_z_x, axis=0), z_states_bool, theta_i, theta_ij, alpha)\n",
    "\n",
    "        p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "        p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "\n",
    "        print(\"Update means and stdevs...\", end=\"\")\n",
    "        mu_est = im.update_mus(mu, m, sigma, s, z_states, filter_results, p_z_x, fixed_indices, beta)\n",
    "        m_est = im.update_ms(mu, m, sigma, s, z_states, filter_results, p_z_x, beta)\n",
    "        sigma, s = im.update_stdevs_approx(mu, m, sigma, s, z_states, filter_results, p_z_x, beta)\n",
    "\n",
    "        if jj < k-1:\n",
    "            print(\"Update probabilities...\")\n",
    "            p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "            p_z_x = im.get_all_p_z_x(p_x_z, p_z)\n",
    "            \n",
    "    return mu, m, sigma, s, theta_i, theta_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'mu': mu,\n",
    "'sigma': sigma,\n",
    "'m': m,\n",
    "'s': s,\n",
    "'theta_i': theta_i,\n",
    "'theta_ij': theta_ij}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'inference_methods' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\python\\\\inference_methods.py'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing probabilities...\n",
      "Running EM:\n",
      "   Iteration 0...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 1...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 2...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 3...Update thetas...Update means and stdevs...Update probabilities...\n",
      "   Iteration 4...Update thetas...Update means and stdevs..."
     ]
    }
   ],
   "source": [
    "mu, m, sigma, s, theta_i, theta_ij = EM_theta(5, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importlib.reload(im)\n",
    "p_x_z = im.get_all_p_x_z(mu, m, sigma, s, z_states, filter_results, fixed_indices)\n",
    "p_z = im.get_p_z(z_states, theta_i, theta_ij)\n",
    "p_z_x = im.get_all_p_z_x(p_x_z, p_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for _ in range(num_states*10):\n",
    "    np.nan_to_num(0)\n",
    "    #pass\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test_ix in test_indices[3:]:\n",
    "    p_zi_x = np.zeros([num_features])\n",
    "    for f_ix in range(num_features):\n",
    "        state_ixs = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "        p_zi_x[f_ix] = sum(p_z_x[test_ix, state_ixs])\n",
    "        #for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "        #    output[z] = output[z] + [f, strength]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arterial enhancement 82%\n",
      "thin well-defined walls 74%\n",
      "heterogeneous 62%\n",
      "continuous enhancing rim 56%\n"
     ]
    }
   ],
   "source": [
    "for f,strength in sorted(enumerate(p_zi_x), key=lambda x:x[1], reverse=True):\n",
    "    if strength<0.3:\n",
    "        break\n",
    "    print(\"%s %d%%\" % (all_features[f], strength*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACFCAYAAABsdIKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQxYRmQQdsojIJOiQRUQm4T+WenD2fSyHOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb084a6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cls in C.classes_to_include:\n",
    "    x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == indices_f[test_ix])]\n",
    "    if len(x_test_quick) > 0:\n",
    "        break\n",
    "hf.draw_slices(x_test_quick[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@njit\n",
    "def update_stdevs(mu, m, sigma, s, z_states, filter_results, p_z_x):\n",
    "    sigma_est = np.empty([num_features, num_units])\n",
    "    s_est = np.empty([num_units])\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "\n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in range(num_states):\n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - \\\n",
    "                       np.dot(mu[:, u_ix], z_states_bool[state_ix]) - m[u_ix])**2 for img_ix in range(num_imgs)]) / 2\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "\n",
    "        temp = scipy.optimize.minimize(\\\n",
    "                    lambda Var: sum([a_i[state_ix] / (sum(np.where(z_states_bool[state_ix],\n",
    "                       Var[:-1], 0))+Var[-1]) + c_i[state_ix] * log(sqrt(sum(np.where(z_states_bool[state_ix],\n",
    "                       Var[:-1], 0))+Var[-1]) * sqrt(2*pi)) for state_ix in range(num_states)]),\n",
    "                      np.concatenate([sigma[:, u_ix]**2, [s[u_ix]**2]]), \n",
    "                      bounds=tuple(itertools.repeat((.001, 1000),num_features+1)))\n",
    "\n",
    "        sigma_est[:, u_ix] = [sqrt(i) for i in temp['x'][:-1]]\n",
    "        s_est[u_ix] = sqrt(temp['x'][-1])\n",
    "    \n",
    "    return sigma_est, s_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "t=time.time()\n",
    "for f_ix in range(num_features):\n",
    "    state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    #p_z_x does not need to be rescaled because the factor cancels out\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "    \n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in state_indices:\n",
    "            z = z_states[state_ix]\n",
    "\n",
    "            mean = np.dot(mu[:, u_ix], z) + m[u_ix]\n",
    "            var_adj[state_ix] = sum(np.where(z==1, sigma[:, u_ix]**2, 0)) + s[u_ix]**2 - sigma[f_ix, u_ix]**2\n",
    "            \n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "        \n",
    "        sigma_est[f_ix, u_ix] = sqrt(scipy.optimize.fsolve(lambda x: sum([a_i[state_ix]/(x+var_adj[state_ix])**2 - \\\n",
    "                                         c_i[state_ix]/(x+var_adj[state_ix]) for state_ix in state_indices]), \\\n",
    "                                          sigma[f_ix, u_ix]))\n",
    "        \n",
    "        if u_ix % 20 == 0:\n",
    "            print(f_ix, u_ix, time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "#state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "#p_z_x does not need to be rescaled because the factor cancels out\n",
    "var_adj = np.zeros([num_states])\n",
    "a_i = np.zeros([num_states])\n",
    "c_i = np.zeros([num_states])\n",
    "\n",
    "for u_ix in range(num_units):\n",
    "    for state_ix in range(num_states):\n",
    "        mean = np.dot(mu[:, u_ix], z_states[state_ix]) + m[u_ix]\n",
    "        a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "        c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "\n",
    "    temp = scipy.optimize.linearmixing(\\\n",
    "                lambda Var: sum([a_i[state_ix]/(sum(np.where(z_states[state_ix]==1, Var[:-1]**2, 0))+Var[-1]**2)**2 - \\\n",
    "                 c_i[state_ix]/(sum(np.where(z_states[state_ix]==1, Var[:-1]**2, 0))+Var[-1]**2) for state_ix in range(num_states)]), \\\n",
    "                  np.concatenate([sigma[:, u_ix], [s[u_ix]]]), verbose=True, maxiter=10000)\n",
    "    \n",
    "    #sigma_est[:, u_ix]\n",
    "    if u_ix % 20 == 0:\n",
    "        print(u_ix, time.time()-t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t=time.time()\n",
    "for f_ix in range(num_features):\n",
    "    state_indices = [state_ix for state_ix in range(num_states) if z_states_bool[state_ix][f_ix]]\n",
    "    #p_z_x does not need to be rescaled because the factor cancels out\n",
    "    var_adj = np.zeros([num_states])\n",
    "    a_i = np.zeros([num_states])\n",
    "    c_i = np.zeros([num_states])\n",
    "    \n",
    "    for u_ix in range(num_units):\n",
    "        for state_ix in state_indices:\n",
    "            z = z_states[state_ix]\n",
    "\n",
    "            mean = np.dot(mu[:, u_ix], z) + m[u_ix]\n",
    "            var_adj[state_ix] = sum(np.where(z==1, sigma[:, u_ix]**2, 0)) + s[u_ix]**2 - sigma[f_ix, u_ix]**2\n",
    "            \n",
    "            a_i[state_ix] = sum([p_z_x[img_ix, state_ix] * (filter_results[img_ix, u_ix] - mean)**2 for img_ix in range(num_imgs)])\n",
    "            c_i[state_ix] = sum(p_z_x[:, state_ix])\n",
    "        \n",
    "        sigma_est[f_ix, u_ix] = sqrt(scipy.optimize.fsolve(lambda x: sum([(a_i[state_ix]/(x+var_adj[state_ix]) - \\\n",
    "                                         c_i[state_ix])/(x+var_adj[state_ix]) for state_ix in state_indices]), \\\n",
    "                                          sigma[f_ix, u_ix]))\n",
    "        \n",
    "        if u_ix % 20 == 0:\n",
    "            print(f_ix, u_ix, time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "header = ['filter_num']\n",
    "for cls in C.classes_to_include:\n",
    "    header += [f+\"_\"+cls for f in features_by_cls[cls]]\n",
    "\n",
    "with open('E:\\\\feature_filters.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for f_num in range(100):\n",
    "        writer.writerow([f_num] + [feature_filters[f][f_num] for cls in features for f in features_by_cls[cls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_test_features = ['E106097391_0', 'E104978772_1', '12900535_0', 'E100150242_0', 'E105490014_0', 'E103147618_0', 'E103510187_0', 'E104657225_0', 'E100551966_0', 'E101388602_0', 'E100215900_8', 'E100215900_7', 'E104045692_0', '13104521_0', 'E100383453_0', '12943286_0', '12271995_0', 'E102315724_0', 'E104949189_0', 'E100511083_1', 'E101579471_0', '13018986_1', '13203550_8', '13112385_0', '12712463_0', '12361082_0', '13028374_0', 'E103985934_1', 'E100529980_0', '12042703_3', '12961059_0', 'E105724706_2', 'E100592424_2', 'E103104254_0', 'E104546069_0', 'E101665217_1', '12090000_0', 'E100592424_1', '12961059_1', 'E105474285_0', '12502068_1', 'E100814791_0', 'E102613189_0', 'E105427046_0', 'E102881031_1', 'E102929168_0', 'E102310482_0', 'E102095465_0', 'E101811299_0', 'E104737273_0', '12890053_0', 'E100168661_1', '12637865_0', 'E100168661_2', '12239783_0', '12707781_0', '12706568_1', '12823036_0', '12404081_0', '12365693_1']\n",
    "\n",
    "x_test = {cls: orig_data_dict[cls][0][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}\n",
    "Z_test = {cls: orig_data_dict[cls][1][np.where(np.isin(orig_data_dict[cls][1], Z_test_features))] for cls in C.classes_to_include}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least squares approach\n",
    "Theta = np.array([feature_filter_means[f] for f in all_features])\n",
    "Theta = np.transpose(Theta, (1,0))\n",
    "\n",
    "filters_test = {}\n",
    "features_test = {}\n",
    "for cls in C.classes_to_include:\n",
    "    filters_test[cls] = model_dense_outputs.predict(x_test[cls], verbose=False)\n",
    "    filters_test[cls] = (filters_test[cls] - filter_avgs) / filter_stds\n",
    "    features_test[cls] = np.linalg.lstsq(Theta, np.transpose(filters_test[cls], (1,0)))[0]\n",
    "    #filters_test[cls] = np.apply_along_axis(lambda x: x / filter_avgs, 1, filters_test[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covar_to_corr(covar):\n",
    "    A = np.diag(np.diag(covar)**(-0.5))\n",
    "    return np.matmul(np.matmul(A, covar), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = covar_to_corr(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(corr - np.linalg.pinv(np.diag(np.diag(np.linalg.pinv(corr)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cutoff_eigenval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=None,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = np.random.normal(size=filter_results.shape)\n",
    "dummy_fa = FactorAnalysis()\n",
    "dummy_fa.fit(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals(dummy_fa.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.linalg.eigvals(fa.get_covariance()) > np.mean(np.linalg.eigvals(dummy_fa.get_covariance())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.fit(filter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.eigvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89081373261106078"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=3\n",
    "fa.get_covariance()[x,x] - fa.noise_variance_[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cls = \"colorectal\"\n",
    "x_test_quick = orig_data_dict[cls][0][np.where(orig_data_dict[cls][1] == \"E105724706_2.npy\")]\n",
    "x_test_quick = orig_data_dict[\"fnh\"][0][np.where(orig_data_dict[\"fnh\"][1] == \"E104189184_0.npy\")]\n",
    "filters_quick = model_dense_outputs.predict(x_test_quick, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "evidence = {}\n",
    "\n",
    "for f in all_features:\n",
    "    evidence[f + \"/\" + str(cls_features[f])] = cnna.get_evidence_strength(feature_filters[f], filters_quick[0])#filters_test[true_cls][img_num])\n",
    "    #max_strength = max(max_strength, evidence[f + \"/\" + str(cls_features[f])])\n",
    "\n",
    "#for f in evidence:\n",
    "#    evidence[f] /= max_strength\n",
    "print(\"Detected features:\")\n",
    "for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True)[:5]:\n",
    "    #if strength > 1:\n",
    "    print(\"- \" + f, \"- %d%%\" % (strength*100))\n",
    "\n",
    "hf.plot_section_auto(x_test_quick[0])#[true_cls][img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for cls in C.classes_to_include:\n",
    "    for img_num in range(len(filters_test[cls])):\n",
    "        z = Z_test[cls][img_num]\n",
    "        x = np.expand_dims(x_test[cls][img_num], axis=0)\n",
    "        evidence = {}\n",
    "        \n",
    "        output[z] = [cls]\n",
    "        \n",
    "        preds = model.predict(x, verbose=False)[0]\n",
    "        for pred_cls, pred_conf in sorted(zip(C.classes_to_include, preds), key=lambda x:x[1], reverse=True)[:2]:\n",
    "            output[z] = output[z] + [pred_cls]\n",
    "        \n",
    "        #for f in all_features:\n",
    "        #    evidence[f + \"/\" + str(cls_features[f])] = get_evidence_strength(feature_filters[f], filters_test[cls][img_num])\n",
    "        \n",
    "        for i in range(len(all_features)):\n",
    "            evidence[all_features[i] + \"/\" + str(cls_features[all_features[i]])] = features_test[cls][i, img_num]\n",
    "        \n",
    "        f1='infiltrative'\n",
    "        f2='lobulated margins'\n",
    "        if evidence[f1 + \"/\" + str(cls_features[f1])] < evidence[f2 + \"/\" + str(cls_features[f2])]:\n",
    "            evidence.pop(f1 + \"/\" + str(cls_features[f1]))\n",
    "        else:\n",
    "            evidence.pop(f2 + \"/\" + str(cls_features[f2]))\n",
    "        \n",
    "        for f,strength in sorted(evidence.items(), key=lambda x:x[1], reverse=True):\n",
    "            output[z] = output[z] + [f, strength]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('E:\\\\filters_pred5.csv', 'w', newline='') as csvfile:\n",
    "    header = ['img_fn', 'agreement1', 'agreement2', 'true_cls', 'pred_cls1', 'pred_cls2'] + \\\n",
    "            [s for i in range(len(all_features)) for s in ['feature_%d' % i,'strength_%d' % i]]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for z_num in range(len(Z_test_features)):\n",
    "        writer.writerow([Z_test_features[z_num]] + [output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][3], \\\n",
    "                        output[Z_test_features[z_num]][0] in output[Z_test_features[z_num]][5]] + output[Z_test_features[z_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:\\\\filters_pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "agree = 0\n",
    "for _,row in df.iterrows():\n",
    "    if row[\"pred_cls1\"] in row[\"feature_1\"]:\n",
    "        agree += 1\n",
    "print(agree/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
