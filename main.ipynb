{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img=np.zeros((100,100,100,3))\n",
    "img[20:80,20:80,20:80,2] = 255\n",
    "np.save('img3', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import importlib\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.layers import Input, Add, Dense, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D, \\\n",
    "    AveragePooling2D, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn import config, data_generators, FixedBatchNormalization, RoiPoolingConv, simple_parser, losses as klosses\n",
    "from keras_frcnn import resnet as nn\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "import pickle\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras_frcnn.RoiPoolingConv' from 'C:\\\\Users\\\\Clinton Wang\\\\Documents\\\\new-voi\\\\keras_frcnn\\\\RoiPoolingConv.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(simple_parser)\n",
    "importlib.reload(RoiPoolingConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "Training images per class:\n",
      "{'bg': 0, 'cyst': 1, 'hcc': 2}\n",
      "Num classes (including bg) = 3\n",
      "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n",
      "Num train samples 2\n",
      "Num val samples 1\n"
     ]
    }
   ],
   "source": [
    "C = config.Config()\n",
    "\n",
    "C.use_horizontal_flips = False\n",
    "C.use_vertical_flips = False\n",
    "C.rot_90 = False\n",
    "\n",
    "C.model_path = None\n",
    "C.num_rois = 4\n",
    "\n",
    "from keras_frcnn import resnet as nn\n",
    "C.network = 'resnet50'\n",
    "C.base_net_weights = nn.get_weight_path()\n",
    "\n",
    "all_imgs, classes_count, class_mapping = simple_parser.get_data('train_list.txt')\n",
    "\n",
    "if 'bg' not in classes_count:\n",
    "    classes_count['bg'] = 0\n",
    "    class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "C.class_mapping = class_mapping\n",
    "\n",
    "inv_map = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
    "\n",
    "config_output_filename = 'config.pickle'\n",
    "\n",
    "with open(config_output_filename, 'wb') as config_f:\n",
    "    pickle.dump(C,config_f)\n",
    "    print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n",
    "\n",
    "random.shuffle(all_imgs)\n",
    "\n",
    "num_imgs = len(all_imgs)\n",
    "\n",
    "train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "\n",
    "print('Num train samples {}'.format(len(train_imgs)))\n",
    "print('Num val samples {}'.format(len(val_imgs)))\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (None, None, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(None, 4))\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
    "\n",
    "model_rpn = Model(img_input, rpn[:2])\n",
    "model_classifier = Model([img_input, roi_input], classifier)\n",
    "\n",
    "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\tprint('loading weights from {}'.format(C.base_net_weights))\n",
    "\tmodel_rpn.load_weights(C.base_net_weights, by_name=True)\n",
    "\tmodel_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, nn.get_img_output_length, K.image_dim_ordering(), mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_frcnn import data_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras_frcnn.data_augment' from 'C:\\\\Users\\\\Clinton Wang\\\\Documents\\\\new-voi\\\\keras_frcnn\\\\data_augment.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(data_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_data, x_img = data_augment.augment(img_data, C, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/5\n",
      "4/5 [=======================>......] - ETA: 3s - rpn_cls: 4.6591 - rpn_regr: 0.8898 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00Average number of overlapping bounding boxes from RPN = 0.0 for 5 previous iterations\n",
      "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
      "5/5 [==============================] - 14s - rpn_cls: 4.5504 - rpn_regr: 0.8736 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00    \n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.0\n",
      "Classifier accuracy for bounding boxes from RPN: 1.0\n",
      "Loss RPN classifier: 4.115565586090088\n",
      "Loss RPN regression: 0.8089004278182983\n",
      "Loss Detector classifier: 1.1920930376163597e-07\n",
      "Loss Detector regression: 0.0\n",
      "Elapsed time: 14.610959529876709\n",
      "Total loss decreased from inf to 4.92446613311769, saving weights\n",
      "Epoch 2/5\n",
      "2/5 [===========>..................] - ETA: 2s - rpn_cls: 2.9303 - rpn_regr: 0.6286 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00Average number of overlapping bounding boxes from RPN = 0.0 for 5 previous iterations\n",
      "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
      "5/5 [==============================] - 3s - rpn_cls: 2.0599 - rpn_regr: 0.5876 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00     \n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.0\n",
      "Classifier accuracy for bounding boxes from RPN: 1.0\n",
      "Loss RPN classifier: 1.1332849033721915\n",
      "Loss RPN regression: 0.5291378974914551\n",
      "Loss Detector classifier: 1.1920930376163597e-07\n",
      "Loss Detector regression: 0.0\n",
      "Elapsed time: 7.829965591430664\n",
      "Total loss decreased from 4.92446613311769 to 1.6624229200729503, saving weights\n",
      "Epoch 3/5\n",
      "Average number of overlapping bounding boxes from RPN = 0.0 for 5 previous iterations\n",
      "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
      "5/5 [==============================] - 2s - rpn_cls: 3.4465 - rpn_regr: 0.3437 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00     \n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.0\n",
      "Classifier accuracy for bounding boxes from RPN: 1.0\n",
      "Loss RPN classifier: 1.932643930241926\n",
      "Loss RPN regression: 0.30894210040569303\n",
      "Loss Detector classifier: 1.1920930376163597e-07\n",
      "Loss Detector regression: 0.0\n",
      "Elapsed time: 2.8714489936828613\n",
      "Epoch 4/5\n",
      "Average number of overlapping bounding boxes from RPN = 0.0 for 5 previous iterations\n",
      "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
      "4/5 [=======================>......] - ETA: 0s - rpn_cls: 0.7046 - rpn_regr: 0.1787 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00  Average number of overlapping bounding boxes from RPN = 0.0 for 5 previous iterations\n",
      "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
      "5/5 [==============================] - 2s - rpn_cls: 0.7570 - rpn_regr: 0.1690 - detector_cls: 1.1921e-07 - detector_regr: 0.0000e+00     \n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.0\n",
      "Classifier accuracy for bounding boxes from RPN: 1.0\n",
      "Loss RPN classifier: 0.9663240387241843\n",
      "Loss RPN regression: 0.12997233420610427\n",
      "Loss Detector classifier: 1.1920930376163597e-07\n",
      "Loss Detector regression: 0.0\n",
      "Elapsed time: 2.930159091949463\n",
      "Total loss decreased from 1.6624229200729503 to 1.0962964921395923, saving weights\n",
      "Epoch 5/5\n",
      "3/5 [=================>............] - ETA: 1s - rpn_cls: 1.3421 - rpn_regr: 0.0160 - detector_cls: 3.5818 - detector_regr: 0.0000e+00  Average number of overlapping bounding boxes from RPN = 0.4 for 5 previous iterations\n",
      "5/5 [==============================] - 4s - rpn_cls: 1.2401 - rpn_regr: 0.0137 - detector_cls: 3.2371 - detector_regr: 0.0000e+00     \n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.3333333333333333\n",
      "Classifier accuracy for bounding boxes from RPN: 0.85\n",
      "Loss RPN classifier: 0.9663222425448155\n",
      "Loss RPN regression: 0.01225750703488302\n",
      "Loss Detector classifier: 2.4177143573761044\n",
      "Loss Detector regression: 0.0\n",
      "Elapsed time: 4.368427753448486\n",
      "Training complete, exiting.\n"
     ]
    }
   ],
   "source": [
    "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, nn.get_img_output_length, K.image_dim_ordering(), mode='train')\n",
    "data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, nn.get_img_output_length,K.image_dim_ordering(), mode='val')\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=optimizer, loss=[klosses.rpn_loss_cls(num_anchors), klosses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss=[klosses.class_loss_cls, klosses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')\n",
    "\n",
    "epoch_length = 5#1000\n",
    "num_epochs = 5\n",
    "iter_num = 0\n",
    "\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "start_time = time.time()\n",
    "\n",
    "best_loss = np.Inf\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in class_mapping.items()}\n",
    "print('Starting training')\n",
    "\n",
    "vis = True\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    progbar = generic_utils.Progbar(epoch_length)\n",
    "    print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "\n",
    "    while True:\n",
    "        if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
    "            mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "            rpn_accuracy_rpn_monitor = []\n",
    "            print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
    "            if mean_overlapping_bboxes == 0:\n",
    "                print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "\n",
    "        X, Y, img_data = next(data_gen_train)\n",
    "\n",
    "        loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "        P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "        R = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
    "        # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "        X2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n",
    "\n",
    "        if X2 is None:\n",
    "            rpn_accuracy_rpn_monitor.append(0)\n",
    "            rpn_accuracy_for_epoch.append(0)\n",
    "            continue\n",
    "\n",
    "        neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "        pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "        if len(neg_samples) > 0:\n",
    "            neg_samples = neg_samples[0]\n",
    "        else:\n",
    "            neg_samples = []\n",
    "\n",
    "        if len(pos_samples) > 0:\n",
    "            pos_samples = pos_samples[0]\n",
    "        else:\n",
    "            pos_samples = []\n",
    "\n",
    "        rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "        rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "        if C.num_rois > 1:\n",
    "            if len(pos_samples) < C.num_rois//2:\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "            else:\n",
    "                selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
    "            try:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "            except:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "\n",
    "            sel_samples = selected_pos_samples + selected_neg_samples\n",
    "        else:\n",
    "            # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "            selected_pos_samples = pos_samples.tolist()\n",
    "            selected_neg_samples = neg_samples.tolist()\n",
    "            if np.random.randint(0, 2):\n",
    "                sel_samples = random.choice(neg_samples)\n",
    "            else:\n",
    "                sel_samples = random.choice(pos_samples)\n",
    "\n",
    "        loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "        losses[iter_num, 0] = loss_rpn[1]\n",
    "        losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "        losses[iter_num, 2] = loss_class[1]\n",
    "        losses[iter_num, 3] = loss_class[2]\n",
    "        losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "        iter_num += 1\n",
    "\n",
    "        progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                                  ('detector_cls', np.mean(losses[:iter_num, 2])), ('detector_regr', np.mean(losses[:iter_num, 3]))])\n",
    "\n",
    "        if iter_num == epoch_length:\n",
    "            loss_rpn_cls = np.mean(losses[:, 0])\n",
    "            loss_rpn_regr = np.mean(losses[:, 1])\n",
    "            loss_class_cls = np.mean(losses[:, 2])\n",
    "            loss_class_regr = np.mean(losses[:, 3])\n",
    "            class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "            mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "            rpn_accuracy_for_epoch = []\n",
    "\n",
    "            if C.verbose:\n",
    "                print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "                print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "                print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "                print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "            curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "            iter_num = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "            if curr_loss < best_loss:\n",
    "                if C.verbose:\n",
    "                    print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
    "                best_loss = curr_loss\n",
    "                model_all.save_weights('weights.hdf5')\n",
    "\n",
    "            break\n",
    "\n",
    "print('Training complete, exiting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
