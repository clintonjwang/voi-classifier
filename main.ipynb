{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Add, Dense, Activation, Flatten, Dropout, Conv3D, MaxPooling3D, ZeroPadding3D, AveragePooling3D, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "nb_classes = C.nb_classes\n",
    "\n",
    "X_train = np.expand_dims(x_train,axis=3)\n",
    "X_train = np.expand_dims(X_train,axis=4)\n",
    "X_test = np.expand_dims(x_test,axis=3)\n",
    "X_test = np.expand_dims(X_test,axis=4)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\Users\\\\Clinton\\\\Documents\\\\voi-classifier\\\\config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = config.Config()\n",
    "dims = C.dims\n",
    "voi_img = Input(shape=(dims[0], dims[1], dims[2], C.nb_channels))\n",
    "#x = Dropout(0.2)(voi_img)\n",
    "#x = GaussianNoise(1)(x)\n",
    "#x = ZeroPadding3D(padding=(3,3,2))(voi_img)\n",
    "#x = Conv3D(filters=128, kernel_size=(3,3,2), activation='relu', kernel_regularizer=l2(.01))(x)\n",
    "x = Conv3D(filters=32, kernel_size=(3,3,1), activation='relu')(voi_img)\n",
    "x = Conv3D(filters=64, kernel_size=(3,3,1), activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "intermed = MaxPooling3D((2, 2, 2))(x)\n",
    "x = Flatten()(intermed)\n",
    "x = Dense(128, activation='relu')(x)#, kernel_initializer='normal', kernel_regularizer=l1(.01), kernel_constraint=max_norm(3.))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "pred_class = Dense(C.nb_classes, activation='softmax')(x)#Dense(C.nb_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 20, 10, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 18, 18, 10, 32)    608       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 16, 16, 10, 64)    18496     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 10, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 8, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20480)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               2621568   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,640,930\n",
      "Trainable params: 2,640,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = Adam(lr=0.1)#, decay=0.001)\n",
    "early_stopping = EarlyStopping(min_delta=0.01, patience=5)\n",
    "\n",
    "model = Model(voi_img, pred_class)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(voi_img, intermed)\n",
    "\n",
    "for l in range(2,len(model2.layers)):\n",
    "    model2.layers[l].set_weights(model.layers[l].get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X_train.append(np.ones(dims + [C.nb_channels]))\n",
    "    Y_train.append([1,0])\n",
    "for _ in range(10):\n",
    "    X_train.append(np.ones(dims + [C.nb_channels]))\n",
    "    X_train[-1][5:15,5:15,5:7,0] = 2\n",
    "    Y_train.append([0,1])\n",
    "    \n",
    "X_train = np.array(X_train) # X[:total_size//2]\n",
    "#X_val = np.array(X_test)\n",
    "Y_train = np.array(Y_train) # Y[:total_size//2]\n",
    "#Y_val = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "max_samples = 10000\n",
    "base_dir = \"..\\\\liver-mr-processor\\\\train_imgs\\\\\"\n",
    "\n",
    "least_in_one_class = max_samples\n",
    "\n",
    "for class_name in os.listdir(base_dir):\n",
    "    x = np.empty((max_samples, dims[0], dims[1], dims[2], C.nb_channels))\n",
    "    z = []\n",
    "    \n",
    "    for index, img_fn in enumerate(os.listdir(base_dir+class_name)):\n",
    "        x[index] = np.load(base_dir+class_name+\"\\\\\"+img_fn)\n",
    "        z.append(img_fn)\n",
    "    \n",
    "    least_in_one_class = min(index, least_in_one_class)\n",
    "    x.resize((index, dims[0], dims[1], dims[2], C.nb_channels))\n",
    "    max_samples = index\n",
    "    data_dict[class_name] = [x,np.array(z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = least_in_one_class*3//4 * C.nb_classes\n",
    "X_train = []\n",
    "Y_train = []\n",
    "Z_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "Z_test = []\n",
    "train_frac = 0.75\n",
    "cls_mapping = []\n",
    "\n",
    "for cls_num, cls in enumerate(data_dict):\n",
    "    order = np.random.permutation(list(range(max_samples)))\n",
    "    X_train = X_train + list(data_dict[cls][0][order[:round(least_in_one_class*train_frac)]])\n",
    "    X_test = X_test + list(data_dict[cls][0][order[round(least_in_one_class*train_frac):]])\n",
    "    Z_train = Z_train + list(data_dict[cls][1][order[:round(least_in_one_class*train_frac)]])\n",
    "    Z_test = Z_test + list(data_dict[cls][1][order[round(least_in_one_class*train_frac):]])\n",
    "    Y_train = Y_train + [[0] * cls_num + [1] + [0] * (C.nb_classes - cls_num - 1)] * (round(least_in_one_class*train_frac))\n",
    "    Y_test = Y_test + [[0] * cls_num + [1] + [0] * (C.nb_classes - cls_num - 1)] * \\\n",
    "                        (max_samples - round(least_in_one_class*train_frac))\n",
    "        \n",
    "    cls_mapping.append(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train) # X[:total_size//2]\n",
    "X_val = np.array(X_test)\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "#X_val = X[total_size//2:total_size*3//4]\n",
    "#X_test = X[total_size*3//4:]\n",
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(Y_test)\n",
    "Z_train = np.array(Z_train)\n",
    "Z_val = np.array(Z_test)\n",
    "#Y_val = Y[total_size//2:total_size*3//4]\n",
    "#Y_test = Y[total_size*3//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = np.array([z for z in x])\n",
    "#Y = np.array(y)\n",
    "#Y = np.array([[0,1] if y[x] == 1 else [1,0] for x in range(len(y))])\n",
    "#Y = K.constant(y, dtype=tf.int32)\n",
    "#Y = K.one_hot(Y, C.nb_classes)\n",
    "\n",
    "#total_size = X.shape[0]\n",
    "\n",
    "#order = np.random.permutation(list(range(total_size)))\n",
    "#X = X[order]\n",
    "#Y = Y[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_generator(X, Y):\n",
    "    while True:\n",
    "        for i in range(len(X)):\n",
    "            yield np.expand_dims(X[i], axis=0), np.expand_dims(Y[i], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_epochs = 10\n",
    "epoch_length = 100\n",
    "best_loss = np.Inf\n",
    "losses = np.zeros(epoch_length)\n",
    "acc = np.zeros(epoch_length)\n",
    "\n",
    "data_gen_train = train_generator(X_train, Y_train)\n",
    "for epoch_num in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "    iter_num = 0\n",
    "    \n",
    "    while True:\n",
    "        X, Y = next(data_gen_train)\n",
    "        losses[iter_num], acc[iter_num] = model.train_on_batch(X, Y)\n",
    "\n",
    "        iter_num += 1\n",
    "        if iter_num == epoch_length:\n",
    "            curr_loss = np.mean(losses)\n",
    "            curr_acc = np.mean(acc)\n",
    "            print(\"Mean Loss:\", curr_loss, \"// Mean Accuracy:\", curr_acc)\n",
    "\n",
    "            if curr_loss < best_loss:\n",
    "                print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
    "                best_loss = curr_loss\n",
    "                model.save_weights(C.model_path)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 120 samples\n",
      "Epoch 1/200\n",
      "358/358 [==============================] - 0s - loss: 0.8896 - acc: 0.4972 - val_loss: 0.7563 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "358/358 [==============================] - 0s - loss: 0.7794 - acc: 0.5000 - val_loss: 0.6971 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "358/358 [==============================] - 0s - loss: 0.6951 - acc: 0.5279 - val_loss: 0.6832 - val_acc: 0.8917\n",
      "Epoch 4/200\n",
      "358/358 [==============================] - 0s - loss: 0.6794 - acc: 0.5978 - val_loss: 0.6729 - val_acc: 0.7833\n",
      "Epoch 5/200\n",
      "358/358 [==============================] - 0s - loss: 0.6641 - acc: 0.6313 - val_loss: 0.6519 - val_acc: 0.6333\n",
      "Epoch 6/200\n",
      "358/358 [==============================] - 0s - loss: 0.6424 - acc: 0.6117 - val_loss: 0.6371 - val_acc: 0.7583\n",
      "Epoch 7/200\n",
      "358/358 [==============================] - 0s - loss: 0.6112 - acc: 0.6341 - val_loss: 0.6031 - val_acc: 0.7500\n",
      "Epoch 8/200\n",
      "358/358 [==============================] - 0s - loss: 0.5701 - acc: 0.7318 - val_loss: 0.5620 - val_acc: 0.7000\n",
      "Epoch 9/200\n",
      "358/358 [==============================] - 0s - loss: 0.5334 - acc: 0.7737 - val_loss: 0.5051 - val_acc: 0.8500\n",
      "Epoch 10/200\n",
      "358/358 [==============================] - 0s - loss: 0.5038 - acc: 0.7263 - val_loss: 0.4944 - val_acc: 0.8833\n",
      "Epoch 11/200\n",
      "358/358 [==============================] - 0s - loss: 0.4217 - acc: 0.8855 - val_loss: 0.4163 - val_acc: 0.8417\n",
      "Epoch 12/200\n",
      "358/358 [==============================] - 0s - loss: 0.3781 - acc: 0.8575 - val_loss: 0.3672 - val_acc: 0.9333\n",
      "Epoch 13/200\n",
      "358/358 [==============================] - 0s - loss: 0.2947 - acc: 0.8966 - val_loss: 0.3073 - val_acc: 0.8833\n",
      "Epoch 14/200\n",
      "358/358 [==============================] - 0s - loss: 0.3002 - acc: 0.8827 - val_loss: 0.2697 - val_acc: 0.8833\n",
      "Epoch 15/200\n",
      "358/358 [==============================] - 0s - loss: 0.2848 - acc: 0.8855 - val_loss: 0.2441 - val_acc: 0.9167\n",
      "Epoch 16/200\n",
      "358/358 [==============================] - 0s - loss: 0.2327 - acc: 0.9106 - val_loss: 0.2470 - val_acc: 0.9583\n",
      "Epoch 17/200\n",
      "358/358 [==============================] - 0s - loss: 0.2014 - acc: 0.9441 - val_loss: 0.2161 - val_acc: 0.8917\n",
      "Epoch 18/200\n",
      "358/358 [==============================] - 0s - loss: 0.2009 - acc: 0.9441 - val_loss: 0.1912 - val_acc: 0.9667\n",
      "Epoch 19/200\n",
      "358/358 [==============================] - 0s - loss: 0.1547 - acc: 0.9721 - val_loss: 0.1483 - val_acc: 0.9417\n",
      "Epoch 20/200\n",
      "358/358 [==============================] - 0s - loss: 0.1357 - acc: 0.9637 - val_loss: 0.1301 - val_acc: 0.9750\n",
      "Epoch 21/200\n",
      "358/358 [==============================] - 0s - loss: 0.1100 - acc: 0.9721 - val_loss: 0.1075 - val_acc: 0.9750\n",
      "Epoch 22/200\n",
      "358/358 [==============================] - 0s - loss: 0.0946 - acc: 0.9804 - val_loss: 0.0994 - val_acc: 0.9667\n",
      "Epoch 23/200\n",
      "358/358 [==============================] - 0s - loss: 0.0770 - acc: 0.9860 - val_loss: 0.0902 - val_acc: 0.9917\n",
      "Epoch 24/200\n",
      "358/358 [==============================] - 0s - loss: 0.0702 - acc: 0.9832 - val_loss: 0.0944 - val_acc: 0.9750\n",
      "Epoch 25/200\n",
      "358/358 [==============================] - 0s - loss: 0.0710 - acc: 0.9804 - val_loss: 0.0762 - val_acc: 0.9833\n",
      "Epoch 26/200\n",
      "358/358 [==============================] - 0s - loss: 0.0673 - acc: 0.9749 - val_loss: 0.0802 - val_acc: 0.9750\n",
      "Epoch 27/200\n",
      "358/358 [==============================] - 0s - loss: 0.0706 - acc: 0.9804 - val_loss: 0.0668 - val_acc: 0.9917\n",
      "Epoch 28/200\n",
      "358/358 [==============================] - 0s - loss: 0.0657 - acc: 0.9749 - val_loss: 0.0703 - val_acc: 0.9750\n",
      "Epoch 29/200\n",
      "358/358 [==============================] - 0s - loss: 0.0530 - acc: 0.9972 - val_loss: 0.0589 - val_acc: 0.9833\n",
      "Epoch 30/200\n",
      "358/358 [==============================] - 0s - loss: 0.0520 - acc: 0.9860 - val_loss: 0.0550 - val_acc: 0.9833\n",
      "Epoch 31/200\n",
      "358/358 [==============================] - 0s - loss: 0.0345 - acc: 0.9972 - val_loss: 0.0526 - val_acc: 0.9833\n",
      "Epoch 32/200\n",
      "358/358 [==============================] - 0s - loss: 0.0449 - acc: 0.9916 - val_loss: 0.0520 - val_acc: 0.9917\n",
      "Epoch 33/200\n",
      "358/358 [==============================] - 0s - loss: 0.0518 - acc: 0.9888 - val_loss: 0.0571 - val_acc: 0.9750\n",
      "Epoch 34/200\n",
      "358/358 [==============================] - 0s - loss: 0.0399 - acc: 0.9972 - val_loss: 0.0581 - val_acc: 0.9750\n",
      "Epoch 35/200\n",
      "358/358 [==============================] - 0s - loss: 0.0414 - acc: 0.9916 - val_loss: 0.0523 - val_acc: 0.9917\n",
      "Epoch 36/200\n",
      "358/358 [==============================] - 0s - loss: 0.0346 - acc: 0.9972 - val_loss: 0.0528 - val_acc: 0.9583\n",
      "Epoch 37/200\n",
      "358/358 [==============================] - 0s - loss: 0.0305 - acc: 0.9944 - val_loss: 0.0428 - val_acc: 0.9917\n",
      "Epoch 38/200\n",
      "358/358 [==============================] - 0s - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9833\n",
      "Epoch 39/200\n",
      "358/358 [==============================] - 0s - loss: 0.0294 - acc: 0.9972 - val_loss: 0.0484 - val_acc: 0.9667\n",
      "Epoch 40/200\n",
      "358/358 [==============================] - 0s - loss: 0.0353 - acc: 0.9972 - val_loss: 0.0439 - val_acc: 0.9917\n",
      "Epoch 41/200\n",
      "358/358 [==============================] - 0s - loss: 0.0367 - acc: 0.9944 - val_loss: 0.0517 - val_acc: 0.9667\n",
      "Epoch 42/200\n",
      "358/358 [==============================] - 0s - loss: 0.0367 - acc: 0.9972 - val_loss: 0.0393 - val_acc: 0.9833\n",
      "Epoch 43/200\n",
      "358/358 [==============================] - 0s - loss: 0.0476 - acc: 0.9888 - val_loss: 0.0391 - val_acc: 0.9917\n",
      "Epoch 44/200\n",
      "358/358 [==============================] - 0s - loss: 0.0245 - acc: 0.9972 - val_loss: 0.0765 - val_acc: 0.9750\n",
      "Epoch 45/200\n",
      "358/358 [==============================] - 0s - loss: 0.0403 - acc: 0.9972 - val_loss: 0.0448 - val_acc: 0.9833\n",
      "Epoch 46/200\n",
      "358/358 [==============================] - 0s - loss: 0.0381 - acc: 0.9944 - val_loss: 0.0444 - val_acc: 0.9833\n",
      "Epoch 47/200\n",
      "358/358 [==============================] - 0s - loss: 0.0356 - acc: 0.9972 - val_loss: 0.0498 - val_acc: 0.9750\n",
      "Epoch 48/200\n",
      "358/358 [==============================] - 0s - loss: 0.0237 - acc: 0.9972 - val_loss: 0.0533 - val_acc: 0.9833\n",
      "Epoch 49/200\n",
      "358/358 [==============================] - 0s - loss: 0.0432 - acc: 0.9888 - val_loss: 0.0348 - val_acc: 0.9833\n",
      "Epoch 50/200\n",
      "358/358 [==============================] - 0s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9833\n",
      "Epoch 51/200\n",
      "358/358 [==============================] - 0s - loss: 0.0263 - acc: 0.9944 - val_loss: 0.0371 - val_acc: 0.9750\n",
      "Epoch 52/200\n",
      "358/358 [==============================] - 0s - loss: 0.0356 - acc: 0.9916 - val_loss: 0.0348 - val_acc: 0.9917\n",
      "Epoch 53/200\n",
      "358/358 [==============================] - 0s - loss: 0.0336 - acc: 0.9916 - val_loss: 0.0854 - val_acc: 0.9667\n",
      "Epoch 54/200\n",
      "358/358 [==============================] - 0s - loss: 0.0330 - acc: 0.9972 - val_loss: 0.0331 - val_acc: 0.9917\n",
      "Epoch 55/200\n",
      "358/358 [==============================] - 0s - loss: 0.0287 - acc: 0.9916 - val_loss: 0.0322 - val_acc: 0.9917\n",
      "Epoch 56/200\n",
      "358/358 [==============================] - 0s - loss: 0.0218 - acc: 0.9944 - val_loss: 0.0362 - val_acc: 0.9833\n",
      "Epoch 57/200\n",
      "358/358 [==============================] - 0s - loss: 0.0231 - acc: 0.9972 - val_loss: 0.0415 - val_acc: 0.9833\n",
      "Epoch 58/200\n",
      "358/358 [==============================] - 0s - loss: 0.0213 - acc: 0.9972 - val_loss: 0.0397 - val_acc: 0.9833\n",
      "Epoch 59/200\n",
      "358/358 [==============================] - 0s - loss: 0.0390 - acc: 0.9972 - val_loss: 0.0364 - val_acc: 0.9833\n",
      "Epoch 60/200\n",
      "358/358 [==============================] - 0s - loss: 0.0298 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9833\n",
      "Epoch 61/200\n",
      "358/358 [==============================] - 0s - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9750\n",
      "Epoch 62/200\n",
      "358/358 [==============================] - 0s - loss: 0.0269 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 0.9750\n",
      "Epoch 63/200\n",
      "358/358 [==============================] - 0s - loss: 0.0233 - acc: 0.9944 - val_loss: 0.0403 - val_acc: 0.9833\n",
      "Epoch 64/200\n",
      "358/358 [==============================] - 0s - loss: 0.0222 - acc: 0.9916 - val_loss: 0.0397 - val_acc: 0.9833\n",
      "Epoch 65/200\n",
      "358/358 [==============================] - 0s - loss: 0.0306 - acc: 0.9916 - val_loss: 0.0499 - val_acc: 0.9583\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s - loss: 0.0373 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 0.9917\n",
      "Epoch 67/200\n",
      "358/358 [==============================] - 0s - loss: 0.0282 - acc: 0.9944 - val_loss: 0.0357 - val_acc: 0.9750\n",
      "Epoch 68/200\n",
      "358/358 [==============================] - 0s - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9667\n",
      "Epoch 69/200\n",
      "358/358 [==============================] - 0s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 0.9833\n",
      "Epoch 70/200\n",
      "358/358 [==============================] - 0s - loss: 0.0201 - acc: 0.9972 - val_loss: 0.0321 - val_acc: 0.9833\n",
      "Epoch 71/200\n",
      "358/358 [==============================] - 0s - loss: 0.0218 - acc: 0.9972 - val_loss: 0.0382 - val_acc: 0.9833\n",
      "Epoch 72/200\n",
      "358/358 [==============================] - 0s - loss: 0.0306 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 0.9750\n",
      "Epoch 73/200\n",
      "358/358 [==============================] - 0s - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9750\n",
      "Epoch 74/200\n",
      "358/358 [==============================] - 0s - loss: 0.0226 - acc: 0.9944 - val_loss: 0.0427 - val_acc: 0.9750\n",
      "Epoch 75/200\n",
      "358/358 [==============================] - 0s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9833\n",
      "Epoch 76/200\n",
      "358/358 [==============================] - 0s - loss: 0.0224 - acc: 0.9944 - val_loss: 0.0355 - val_acc: 0.9833\n",
      "Epoch 77/200\n",
      "358/358 [==============================] - 0s - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9667\n",
      "Epoch 78/200\n",
      "358/358 [==============================] - 0s - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9750\n",
      "Epoch 79/200\n",
      "358/358 [==============================] - 0s - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "Epoch 80/200\n",
      "358/358 [==============================] - 0s - loss: 0.0201 - acc: 0.9972 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "Epoch 81/200\n",
      "358/358 [==============================] - 0s - loss: 0.0304 - acc: 0.9972 - val_loss: 0.0578 - val_acc: 0.9750\n",
      "Epoch 82/200\n",
      "358/358 [==============================] - 0s - loss: 0.0373 - acc: 0.9972 - val_loss: 0.0290 - val_acc: 0.9833\n",
      "Epoch 83/200\n",
      "358/358 [==============================] - 0s - loss: 0.0365 - acc: 0.9972 - val_loss: 0.0302 - val_acc: 0.9833\n",
      "Epoch 84/200\n",
      "358/358 [==============================] - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9750\n",
      "Epoch 85/200\n",
      "358/358 [==============================] - 0s - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9750\n",
      "Epoch 86/200\n",
      "358/358 [==============================] - 0s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 0.9833\n",
      "Epoch 87/200\n",
      "358/358 [==============================] - 0s - loss: 0.0254 - acc: 0.9944 - val_loss: 0.0333 - val_acc: 0.9833\n",
      "Epoch 88/200\n",
      "358/358 [==============================] - 0s - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9667\n",
      "Epoch 89/200\n",
      "358/358 [==============================] - 0s - loss: 0.0275 - acc: 0.9944 - val_loss: 0.0298 - val_acc: 0.9833\n",
      "Epoch 90/200\n",
      "358/358 [==============================] - 0s - loss: 0.0206 - acc: 0.9972 - val_loss: 0.0287 - val_acc: 0.9917\n",
      "Epoch 91/200\n",
      "358/358 [==============================] - 0s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9750\n",
      "Epoch 92/200\n",
      "358/358 [==============================] - 0s - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9750\n",
      "Epoch 93/200\n",
      "358/358 [==============================] - 0s - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9833\n",
      "Epoch 94/200\n",
      "358/358 [==============================] - 0s - loss: 0.0187 - acc: 0.9972 - val_loss: 0.0312 - val_acc: 0.9917\n",
      "Epoch 95/200\n",
      "358/358 [==============================] - 0s - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 96/200\n",
      "358/358 [==============================] - 0s - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 0.9750\n",
      "Epoch 97/200\n",
      "358/358 [==============================] - 0s - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 0.9750\n",
      "Epoch 98/200\n",
      "358/358 [==============================] - 0s - loss: 0.0171 - acc: 0.9972 - val_loss: 0.0453 - val_acc: 0.9750\n",
      "Epoch 99/200\n",
      "358/358 [==============================] - 0s - loss: 0.0327 - acc: 0.9972 - val_loss: 0.0550 - val_acc: 0.9750\n",
      "Epoch 100/200\n",
      "358/358 [==============================] - 0s - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9750\n",
      "Epoch 101/200\n",
      "358/358 [==============================] - 0s - loss: 0.0201 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 0.9833\n",
      "Epoch 102/200\n",
      "358/358 [==============================] - 0s - loss: 0.0234 - acc: 0.9972 - val_loss: 0.0424 - val_acc: 0.9917\n",
      "Epoch 103/200\n",
      "358/358 [==============================] - 0s - loss: 0.0296 - acc: 0.9916 - val_loss: 0.0283 - val_acc: 0.9917\n",
      "Epoch 104/200\n",
      "358/358 [==============================] - 0s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9833\n",
      "Epoch 105/200\n",
      "358/358 [==============================] - 0s - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9750\n",
      "Epoch 106/200\n",
      "358/358 [==============================] - 0s - loss: 0.0181 - acc: 0.9972 - val_loss: 0.0251 - val_acc: 0.9917\n",
      "Epoch 107/200\n",
      "358/358 [==============================] - 0s - loss: 0.0206 - acc: 0.9972 - val_loss: 0.0336 - val_acc: 0.9917\n",
      "Epoch 108/200\n",
      "358/358 [==============================] - 0s - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9917\n",
      "Epoch 109/200\n",
      "358/358 [==============================] - 0s - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9750\n",
      "Epoch 110/200\n",
      "358/358 [==============================] - 0s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9750\n",
      "Epoch 111/200\n",
      "358/358 [==============================] - 0s - loss: 0.0215 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9833\n",
      "Epoch 112/200\n",
      "358/358 [==============================] - 0s - loss: 0.0184 - acc: 0.9972 - val_loss: 0.0289 - val_acc: 0.9833\n",
      "Epoch 113/200\n",
      "358/358 [==============================] - 0s - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 0.9750\n",
      "Epoch 114/200\n",
      "358/358 [==============================] - 0s - loss: 0.0211 - acc: 0.9972 - val_loss: 0.0311 - val_acc: 0.9750\n",
      "Epoch 115/200\n",
      "358/358 [==============================] - 0s - loss: 0.0276 - acc: 0.9916 - val_loss: 0.0426 - val_acc: 0.9917\n",
      "Epoch 116/200\n",
      "358/358 [==============================] - 0s - loss: 0.0353 - acc: 0.9944 - val_loss: 0.0667 - val_acc: 0.9750\n",
      "Epoch 117/200\n",
      "358/358 [==============================] - 0s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9750\n",
      "Epoch 118/200\n",
      "358/358 [==============================] - 0s - loss: 0.0203 - acc: 0.9944 - val_loss: 0.0360 - val_acc: 0.9917\n",
      "Epoch 119/200\n",
      "358/358 [==============================] - 0s - loss: 0.0278 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9750\n",
      "Epoch 120/200\n",
      "358/358 [==============================] - 0s - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9750\n",
      "Epoch 121/200\n",
      "358/358 [==============================] - 0s - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 122/200\n",
      "358/358 [==============================] - 0s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9750\n",
      "Epoch 123/200\n",
      "358/358 [==============================] - 0s - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9833\n",
      "Epoch 124/200\n",
      "358/358 [==============================] - 0s - loss: 0.0251 - acc: 0.9972 - val_loss: 0.0273 - val_acc: 0.9917\n",
      "Epoch 125/200\n",
      "358/358 [==============================] - 0s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9917\n",
      "Epoch 126/200\n",
      "358/358 [==============================] - 0s - loss: 0.0225 - acc: 0.9972 - val_loss: 0.0591 - val_acc: 0.9667\n",
      "Epoch 127/200\n",
      "358/358 [==============================] - 0s - loss: 0.0178 - acc: 0.9972 - val_loss: 0.0829 - val_acc: 0.9667\n",
      "Epoch 128/200\n",
      "358/358 [==============================] - 0s - loss: 0.0306 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 0.9917\n",
      "Epoch 129/200\n",
      "358/358 [==============================] - 0s - loss: 0.0224 - acc: 0.9972 - val_loss: 0.0262 - val_acc: 0.9833\n",
      "Epoch 130/200\n",
      "358/358 [==============================] - 0s - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9750\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 0.9750\n",
      "Epoch 132/200\n",
      "358/358 [==============================] - 0s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 0.9750\n",
      "Epoch 133/200\n",
      "358/358 [==============================] - 0s - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9917\n",
      "Epoch 134/200\n",
      "358/358 [==============================] - 0s - loss: 0.0184 - acc: 0.9972 - val_loss: 0.0266 - val_acc: 0.9833\n",
      "Epoch 135/200\n",
      "358/358 [==============================] - 0s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9833\n",
      "Epoch 136/200\n",
      "358/358 [==============================] - 0s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9917\n",
      "Epoch 137/200\n",
      "358/358 [==============================] - 0s - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0822 - val_acc: 0.9833\n",
      "Epoch 138/200\n",
      "358/358 [==============================] - 0s - loss: 0.0137 - acc: 0.9972 - val_loss: 0.0258 - val_acc: 0.9833\n",
      "Epoch 139/200\n",
      "358/358 [==============================] - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9917\n",
      "Epoch 140/200\n",
      "358/358 [==============================] - 0s - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0396 - val_acc: 0.9833\n",
      "Epoch 141/200\n",
      "358/358 [==============================] - 0s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9750\n",
      "Epoch 142/200\n",
      "358/358 [==============================] - 0s - loss: 0.0295 - acc: 0.9944 - val_loss: 0.0616 - val_acc: 0.9833\n",
      "Epoch 143/200\n",
      "358/358 [==============================] - 0s - loss: 0.0204 - acc: 0.9944 - val_loss: 0.0521 - val_acc: 0.9833\n",
      "Epoch 144/200\n",
      "358/358 [==============================] - 0s - loss: 0.0220 - acc: 1.0000 - val_loss: 0.0778 - val_acc: 0.9750\n",
      "Epoch 145/200\n",
      "358/358 [==============================] - 0s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9750\n",
      "Epoch 146/200\n",
      "358/358 [==============================] - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9833\n",
      "Epoch 147/200\n",
      "358/358 [==============================] - 0s - loss: 0.0231 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9833\n",
      "Epoch 148/200\n",
      "358/358 [==============================] - 0s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0851 - val_acc: 0.9750\n",
      "Epoch 149/200\n",
      "358/358 [==============================] - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9750\n",
      "Epoch 150/200\n",
      "358/358 [==============================] - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0793 - val_acc: 0.9750\n",
      "Epoch 151/200\n",
      "358/358 [==============================] - 0s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 0.9833\n",
      "Epoch 152/200\n",
      "358/358 [==============================] - 0s - loss: 0.0090 - acc: 0.9944 - val_loss: 0.0522 - val_acc: 0.9833\n",
      "Epoch 153/200\n",
      "358/358 [==============================] - 0s - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9750\n",
      "Epoch 154/200\n",
      "358/358 [==============================] - 0s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9750\n",
      "Epoch 155/200\n",
      "358/358 [==============================] - 0s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9750\n",
      "Epoch 156/200\n",
      "358/358 [==============================] - 0s - loss: 0.0140 - acc: 0.9972 - val_loss: 0.1292 - val_acc: 0.9667\n",
      "Epoch 157/200\n",
      "358/358 [==============================] - 0s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9750\n",
      "Epoch 158/200\n",
      "358/358 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0480 - val_acc: 0.9833\n",
      "Epoch 159/200\n",
      "358/358 [==============================] - 0s - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0633 - val_acc: 0.9750\n",
      "Epoch 160/200\n",
      "358/358 [==============================] - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9750\n",
      "Epoch 161/200\n",
      "358/358 [==============================] - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 0.9750\n",
      "Epoch 162/200\n",
      "358/358 [==============================] - 0s - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9833\n",
      "Epoch 163/200\n",
      "358/358 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 0.9833\n",
      "Epoch 164/200\n",
      "358/358 [==============================] - 0s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9750\n",
      "Epoch 165/200\n",
      "358/358 [==============================] - 0s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9750\n",
      "Epoch 166/200\n",
      "358/358 [==============================] - 0s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9750\n",
      "Epoch 167/200\n",
      "358/358 [==============================] - 0s - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0623 - val_acc: 0.9750\n",
      "Epoch 168/200\n",
      "358/358 [==============================] - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9750\n",
      "Epoch 169/200\n",
      "358/358 [==============================] - 0s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9750\n",
      "Epoch 170/200\n",
      "358/358 [==============================] - 0s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9750\n",
      "Epoch 171/200\n",
      "358/358 [==============================] - 0s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0799 - val_acc: 0.9750\n",
      "Epoch 172/200\n",
      "358/358 [==============================] - 0s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 0.9750\n",
      "Epoch 173/200\n",
      "358/358 [==============================] - 0s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9833\n",
      "Epoch 174/200\n",
      "358/358 [==============================] - 0s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0472 - val_acc: 0.9833\n",
      "Epoch 175/200\n",
      "358/358 [==============================] - 0s - loss: 0.0190 - acc: 0.9972 - val_loss: 0.0630 - val_acc: 0.9750\n",
      "Epoch 176/200\n",
      "358/358 [==============================] - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9750\n",
      "Epoch 177/200\n",
      "358/358 [==============================] - 0s - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9917\n",
      "Epoch 178/200\n",
      "358/358 [==============================] - 0s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9917\n",
      "Epoch 179/200\n",
      "358/358 [==============================] - 0s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9917\n",
      "Epoch 180/200\n",
      "358/358 [==============================] - 0s - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9917\n",
      "Epoch 181/200\n",
      "358/358 [==============================] - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0529 - val_acc: 0.9833\n",
      "Epoch 182/200\n",
      "358/358 [==============================] - 0s - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9750\n",
      "Epoch 183/200\n",
      "358/358 [==============================] - 0s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 0.9750\n",
      "Epoch 184/200\n",
      "358/358 [==============================] - 0s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9750\n",
      "Epoch 185/200\n",
      "358/358 [==============================] - 0s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9750\n",
      "Epoch 186/200\n",
      "358/358 [==============================] - 0s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9750\n",
      "Epoch 187/200\n",
      "358/358 [==============================] - 0s - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 0.9750\n",
      "Epoch 188/200\n",
      "358/358 [==============================] - 0s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0481 - val_acc: 0.9833\n",
      "Epoch 189/200\n",
      "358/358 [==============================] - 0s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9917\n",
      "Epoch 190/200\n",
      "358/358 [==============================] - 0s - loss: 0.0128 - acc: 0.9972 - val_loss: 0.0348 - val_acc: 0.9917\n",
      "Epoch 191/200\n",
      "358/358 [==============================] - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9917\n",
      "Epoch 192/200\n",
      "358/358 [==============================] - 0s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9833\n",
      "Epoch 193/200\n",
      "358/358 [==============================] - 0s - loss: 0.0151 - acc: 0.9972 - val_loss: 0.0721 - val_acc: 0.9750\n",
      "Epoch 194/200\n",
      "358/358 [==============================] - 0s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9750\n",
      "Epoch 195/200\n",
      "358/358 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9750\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1266 - val_acc: 0.9750\n",
      "Epoch 197/200\n",
      "358/358 [==============================] - 0s - loss: 0.0166 - acc: 0.9972 - val_loss: 0.0524 - val_acc: 0.9833\n",
      "Epoch 198/200\n",
      "358/358 [==============================] - 0s - loss: 0.0154 - acc: 0.9944 - val_loss: 0.0374 - val_acc: 0.9917\n",
      "Epoch 199/200\n",
      "358/358 [==============================] - 0s - loss: 0.0113 - acc: 0.9944 - val_loss: 0.0192 - val_acc: 0.9917\n",
      "Epoch 200/200\n",
      "358/358 [==============================] - 0s - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9833\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val)) #callbacks=[early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "activ = model2.predict(X_train)\n",
    "#activ = model2.predict(np.expand_dims(X_train[10],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8e3907550>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvB8ZGkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c8e38b92b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(activ[20][:,:,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,  121.71251678,   53.23372269,    0.        ,\n",
       "          0.        ,   24.43340492,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,    7.88301706,    0.        ], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activ[0][5,5,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12296182_23.npy', '13028374_2.npy', 'E104657225_14.npy',\n",
       "       '12972894_6.npy'],\n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_val[::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: ['cyst', 'cyst', 'hcc', 'hcc']\n",
      "Predictions: ['cyst (99.99999% confidence)', 'cyst (100.00000% confidence)', 'hcc (99.99965% confidence)', 'hcc (99.99998% confidence)']\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "print(\"Ground truth:\", [cls_mapping[max(enumerate(x), key=operator.itemgetter(1))[0]] for x in Y_val[::30]])\n",
    "Y_ = model.predict(X_val[::30])\n",
    "print(\"Predictions:\", [cls_mapping[max(enumerate(x), key=operator.itemgetter(1))[0]] + \" (%.5f%% confidence)\" % (max(x)*100) for x in Y_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'vois.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-7ec0def67b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvoi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vois.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\old-keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'vois.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "voi_df = pd.read_csv('vois.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_fn = \"12296182.npy\"\n",
    "img = np.load(\"full_imgs\\\\\"+img_fn)\n",
    "plt.imshow(np.transpose(img[:,::-1,(df['z1']+df['z2'])//2, 0], (1,0)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.78843247e-04,   9.99721110e-01], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sum(y)/len(y), 1-sum(y)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_)/len(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_ = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(X[650,:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20b42b02b70>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b424cdcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0,:,:,5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1650, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'loss': [1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07,\n",
       "  1.1920930376163597e-07],\n",
       " 'val_acc': [0.33734939759036142,\n",
       "  0.33734939759036142,\n",
       "  0.33734939759036142,\n",
       "  0.33734939759036142,\n",
       "  0.33734939759036142,\n",
       "  0.33734939759036142,\n",
       "  0.33734939759036142,\n",
       "  0.33734939759036142],\n",
       " 'val_loss': [10.682890466896884,\n",
       "  10.682890466896884,\n",
       "  10.682890283056052,\n",
       "  10.682890283056052,\n",
       "  10.682890283056052,\n",
       "  10.682890283056052,\n",
       "  10.682890283056052,\n",
       "  10.682890283056052]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
