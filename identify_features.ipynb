{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "for m in list(sys.modules.keys()):\n",
    "    if m.startswith(\"am.\") or m in [\"cnn_runner\", \"config\", \"cnn_builder\", \"classify_feats\", \"dr_methods\", \"voi_methods\"]:\n",
    "        del(sys.modules[m])\n",
    "import am.main as appr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = appr.Apprentice()\n",
    "import config\n",
    "config.config_A(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:10:57.895992Z",
     "start_time": "2018-07-18T16:10:57.024890Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/shared_software/anaconda3/envs/clinton/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "num_annotations = 10\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"homogeneous texture\")\n",
    "all_features = sorted(list(feat_count.keys()))\n",
    "cls_features = {f: [c for c in C.cls_names if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls, num_annotations)\n",
    "Z_features.pop(\"homogeneous texture\")\n",
    "\n",
    "num_features = len(all_features) # number of features\n",
    "\n",
    "all_imgs = [orig_data_dict[cls][0] for cls in C.cls_names]\n",
    "all_imgs = np.array(all_imgs).flatten()\n",
    "\n",
    "all_lesionids = [orig_data_dict[cls][1] for cls in C.cls_names]\n",
    "all_lesionids = np.array(all_imgs).flatten()\n",
    "test_indices = np.where(np.isin(all_lesionids, C.Z_reader))[0]\n",
    "\n",
    "x_test = all_imgs[test_indices]\n",
    "z_test = all_lesionids[test_indices]\n",
    "\n",
    "full_dfs = []\n",
    "\n",
    "train_indices = np.where(~np.isin(all_lesionids, C.Z_reader))[0]\n",
    "z_train = all_lesionids[train_indices]\n",
    "x_train = all_imgs[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:10:59.536145Z",
     "start_time": "2018-07-18T16:10:59.532175Z"
    }
   },
   "outputs": [],
   "source": [
    "model_prefix = 'fixZ_std_'\n",
    "model_ix = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T14:32:25.565159Z",
     "start_time": "2018-07-19T14:32:25.561171Z"
    }
   },
   "outputs": [],
   "source": [
    "features_cls_dict = {f:[cls for cls in C.cls_names if f in features_by_cls[cls]] for f in all_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_features = {f:[] for f in all_features}\n",
    "for f in all_features:\n",
    "    for g in all_features:\n",
    "        if len(set(features_cls_dict[g]).intersection(features_cls_dict[f])) == 0:\n",
    "            excl_features[f].append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T04:26:42.320902Z",
     "start_time": "2018-07-13T04:26:27.641384Z"
    }
   },
   "source": [
    "fullM = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "M = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "M = common.pop_n_layers(M, 3)\n",
    "\n",
    "all_dense = cnna.get_overall_activations(M, orig_data_dict)\n",
    "feature_dense = cnna.get_feature_activations(M, Z_features, all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:13:02.290494Z",
     "start_time": "2018-07-18T16:11:01.236973Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(cnna)\n",
    "fullM = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "model_fc = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "model_fc = common.pop_n_layers(model_fc, 3)\n",
    "model_conv = keras.models.load_model(join(C.model_dir, model_prefix+\"%d.hdf5\" % model_ix))\n",
    "model_conv = common.pop_n_layers(model_conv, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dense = cnna.get_feature_activations(Z_features, all_features, model_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dense = cnna.get_overall_activations(z_train_cls, model_fc, samples=100)\n",
    "feature_dense = cnna.get_feature_activations(Z_features, all_features, model_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "importlib.reload(cnna)\n",
    "train_df = cnna.predict_test_features(fullM, model_fc, all_dense, feature_dense, x_train, z_train, Z_features=Z_features, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:59:50.128056Z",
     "start_time": "2018-07-19T03:58:37.643572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................"
     ]
    }
   ],
   "source": [
    "importlib.reload(cnna)\n",
    "test_df = cnna.predict_test_features(fullM, model_fc, all_dense, feature_dense, x_test, z_test, num_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.pickle_dump(train_df, join(C.model_dir, \"train_df_fc_22.bin\"))\n",
    "hf.pickle_dump(test_df, join(C.model_dir, \"test_df_fc_22.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = hf.pickle_load(join(C.model_dir, \"train_df_fc_29.bin\"))\n",
    "test_df = hf.pickle_load(join(C.model_dir, \"test_df_fc_29.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {f:0 for f in all_features}\n",
    "thresh = {f:0 for f in all_features}\n",
    "for f in all_features:\n",
    "    priors[f] = np.max(train_df.loc[:, f].values)\n",
    "    thresh[f] = np.min(train_df.loc[Z_features[f], f].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:25:43.201613Z",
     "start_time": "2018-07-18T21:25:43.148726Z"
    },
    "scrolled": true
   },
   "source": [
    "priors = {f:0 for f in all_features}\n",
    "for cls in C.cls_names:\n",
    "    for f in all_features:\n",
    "        priors[f] += np.mean(np.log(train_df.loc[train_df[\"true_cls\"] == cls, f].values))\n",
    "        \n",
    "for f in all_features:\n",
    "    priors[f] = priors[f] / 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f in all_features:\n",
    "    priors[f] = np.max(np.log(test_df[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in all_features:\n",
    "    print(f, thresh[f]/priors[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:05:23.406849Z",
     "start_time": "2018-07-19T04:05:23.402860Z"
    }
   },
   "outputs": [],
   "source": [
    "df = copy.deepcopy(test_df)\n",
    "for l_id in df.index:\n",
    "    for f in all_features:\n",
    "        df.loc[l_id, f] = df.loc[l_id, f] / priors[f] if df.loc[l_id, f] > thresh[f] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "arank = df.drop(['true_cls','pred_cls'], axis=1).apply(np.argsort, axis=1)\n",
    "ranked_cols = df.columns[2:].to_series()[arank.values[:,::-1]]\n",
    "new_df = pd.DataFrame(ranked_cols, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_f_cols = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "for ix,col in enumerate(pred_f_cols):\n",
    "    df[col] = new_df[ix].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lesion_id, row in df.iterrows():\n",
    "    for col in pred_f_cols[1:]:\n",
    "        f = row[col]\n",
    "        #exc = sum([row[g]>0 for g in excl_features[f]])\n",
    "        if row[f] == 0 or row['feature_1'] in excl_features[f]:#exc >= 1:\n",
    "            df.loc[lesion_id, f] = 0\n",
    "            df.loc[lesion_id, col] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arank = df.drop(['true_cls','pred_cls'] + pred_f_cols, axis=1).apply(np.argsort, axis=1)\n",
    "ranked_cols = df.columns[2:].to_series()[arank.values[:,::-1]]\n",
    "new_df = pd.DataFrame(ranked_cols, index=df.index)\n",
    "pred_f_cols = ['feature_1', 'feature_2', 'feature_3', 'feature_4']\n",
    "for ix,col in enumerate(pred_f_cols):\n",
    "    df[col] = new_df[ix].values\n",
    "for lesion_id, row in df.iterrows():\n",
    "    for col in pred_f_cols[1:]:\n",
    "        f = row[col]\n",
    "        if row[f] == 0:\n",
    "            df.loc[lesion_id, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753623188405797"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(116-9)/(154-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                      num_correct  pred_freq  true_freq\n",
       " arterial phase enhancement                   18.0       20.0       19.0\n",
       " central scar                                  1.0        3.0        1.0\n",
       " enhancing rim/capsule                         8.0       11.0       15.0\n",
       " heterogeneous lesion                         14.0       18.0       17.0\n",
       " hyperenhancing mass on delayed phase          5.0        5.0        8.0\n",
       " hypoenhancing core                           13.0       15.0       20.0\n",
       " infiltrative growth                           1.0        5.0        4.0\n",
       " isointense on venous/delayed phase            8.0        9.0        9.0\n",
       " nodular growth                                6.0        9.0        6.0\n",
       " nodular or discontinuous enhancement          8.0        8.0       10.0\n",
       " progressive centripetal filling               7.0        7.0        9.0\n",
       " progressive enhancement                      17.0       19.0       19.0\n",
       " thin-walled                                   5.0        5.0        8.0\n",
       " washout                                       8.0        9.0        9.0,\n",
       "             num_correct  pred_freq  true_freq\n",
       " cholangio          26.0       31.0       30.0\n",
       " colorectal         13.0       20.0       27.0\n",
       " cyst               15.0       15.0       18.0\n",
       " fnh                18.0       24.0       20.0\n",
       " hcc                27.0       30.0       32.0\n",
       " hemangioma         20.0       23.0       27.0,\n",
       " array([0.85 , 0.774]),\n",
       " array([ 3.,  6., 10.,  9.]),\n",
       " array([52., 60.]),\n",
       " array([2., 3.]),\n",
       " {'total': [0.8321678321678322],\n",
       "  'arterial phase enhancement': [0.8999955000225],\n",
       "  'central scar': [0.3333222225925802],\n",
       "  'enhancing rim/capsule': [0.727266115762584],\n",
       "  'heterogeneous lesion': [0.7777734568141288],\n",
       "  'hyperenhancing mass on delayed phase': [0.999980000399992],\n",
       "  'hypoenhancing core': [0.8666608889274071],\n",
       "  'infiltrative growth': [0.1999960000799984],\n",
       "  'isointense on venous/delayed phase': [0.8888790124554172],\n",
       "  'nodular growth': [0.6666592593415629],\n",
       "  'nodular or discontinuous enhancement': [0.999987500156248],\n",
       "  'progressive centripetal filling': [0.999985714489793],\n",
       "  'progressive enhancement': [0.8947321329887737],\n",
       "  'thin-walled': [0.999980000399992],\n",
       "  'washout': [0.8888790124554172],\n",
       "  'cholangio': [0.8387069719129938],\n",
       "  'colorectal': [0.6499967500162499],\n",
       "  'cyst': [0.9999933333777775],\n",
       "  'fnh': [0.7499968750130208],\n",
       "  'hcc': [0.8999970000099999],\n",
       "  'hemangioma': [0.8695614366894057]},\n",
       " {'total': [0.7727272727272727],\n",
       "  'arterial phase enhancement': [0.9473684210526315],\n",
       "  'central scar': [1.0],\n",
       "  'enhancing rim/capsule': [0.5333333333333333],\n",
       "  'heterogeneous lesion': [0.8235294117647058],\n",
       "  'hyperenhancing mass on delayed phase': [0.625],\n",
       "  'hypoenhancing core': [0.65],\n",
       "  'infiltrative growth': [0.25],\n",
       "  'isointense on venous/delayed phase': [0.8888888888888888],\n",
       "  'nodular growth': [1.0],\n",
       "  'nodular or discontinuous enhancement': [0.8],\n",
       "  'progressive centripetal filling': [0.7777777777777778],\n",
       "  'progressive enhancement': [0.8947368421052632],\n",
       "  'thin-walled': [0.625],\n",
       "  'washout': [0.8888888888888888],\n",
       "  'cholangio': [0.8666666666666667],\n",
       "  'colorectal': [0.48148148148148145],\n",
       "  'cyst': [0.8333333333333334],\n",
       "  'fnh': [0.9],\n",
       "  'hcc': [0.84375],\n",
       "  'hemangioma': [0.7407407407407407]})"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cnna)\n",
    "cnna.process_feat_id_dfs(all_features, [df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155.0"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7727272727272727*154/0.7677419354838709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T23:12:36.409085Z",
     "start_time": "2018-06-13T23:12:36.406115Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:39:39.833525Z",
     "start_time": "2018-05-16T18:39:34.602623Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_num = 21\n",
    "model_path = join(C.model_dir, \"model_reader_new%d.hdf5\" % model_num)\n",
    "\n",
    "Z_reader = ['E103312835_1','12823036_0','12569915_0','E102093118_0','E102782525_0','12799652_0','E100894274_0','12874178_3','E100314676_0','12842070_0','13092836_2','12239783_0','12783467_0','13092966_0','E100962970_0','E100183257_1','E102634440_0','E106182827_0','12582632_0','E100121654_0','E100407633_0','E105310461_0','12788616_0','E101225606_0','12678910_1','E101083458_1','12324408_0','13031955_0','E101415263_0','E103192914_0','12888679_2','E106096969_0','E100192709_1','13112385_1','E100718398_0','12207268_0','E105244287_0','E102095465_0','E102613189_0','12961059_0','11907521_0','E105311123_0','12552705_0','E100610622_0','12975280_0','E105918926_0','E103020139_1','E101069048_1','E105427046_0','13028374_0','E100262351_0','12302576_0','12451831_0','E102929168_0','E100383453_0','E105344747_0','12569826_0','E100168661_0','12530153_0','E104697262_0']\n",
    "orig_data_dict, num_samples = cbuild._collect_unaug_data()\n",
    "\n",
    "features_by_cls, feat_count = cnna.collect_features()\n",
    "feat_count.pop(\"homogeneous texture\")\n",
    "#feat_count.pop(\"central scar\")\n",
    "all_features = sorted(list(feat_count.keys()))\n",
    "cls_features = {f: [c for c in C.cls_names if f in features_by_cls[c]] for f in all_features}\n",
    "\n",
    "Z_features = cnna.get_annotated_files(features_by_cls)\n",
    "Z_features.pop(\"homogeneous texture\")\n",
    "#Z_features.pop(\"central scar\")\n",
    "\n",
    "num_features = len(all_features)\n",
    "\n",
    "voi_df = drm.get_voi_dfs()[0]\n",
    "M = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T16:41:23.282420Z",
     "start_time": "2018-05-14T16:41:18.726Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "M.layers[5].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:39:40.526930Z",
     "start_time": "2018-05-16T18:39:40.522920Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    print('Memory use:', py.memory_info()[0]/2.**30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T22:53:06.175337Z",
     "start_time": "2018-05-16T22:53:06.168343Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_num = 26\n",
    "model_path = join(C.model_dir, \"model_reader_new%d.hdf5\" % model_num)\n",
    "inf_xls_path = 'D:\\\\feature_analysis\\\\influence%d.xlsx' % model_num\n",
    "\n",
    "df = pd.DataFrame(columns=[\"true_cls\", \"pred_cls\"] + all_features)\n",
    "#df = pd.read_excel(inf_xls_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:40:01.196009Z",
     "start_time": "2018-05-16T18:40:00.906267Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Z_full = np.concatenate([orig_data_dict[cls][-1] for cls in C.cls_names],0)\n",
    "\n",
    "all_imgs = []\n",
    "all_cls = []\n",
    "\n",
    "for lesion_id in Z_full:\n",
    "    cls = voi_df.loc[lesion_id][\"cls\"]\n",
    "    img = np.load(join(C.orig_dir, cls, lesion_id+\".npy\"))\n",
    "    all_imgs.append(np.expand_dims(img,0))\n",
    "    all_cls.append(C.cls_names.index(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T22:53:20.252976Z",
     "start_time": "2018-05-16T22:53:17.016902Z"
    },
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(finf)\n",
    "del M, IA\n",
    "K.clear_session()\n",
    "M = keras.models.load_model(model_path)\n",
    "IA = finf.InfluenceAnalyzer(M, voi_df, all_imgs, all_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:26:17.670024Z",
     "start_time": "2018-05-17T01:11:44.778564Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "for lesion_id in Z_reader:\n",
    "    cls = voi_df.loc[lesion_id][\"cls\"]\n",
    "    img = np.load(join(C.orig_dir, cls, lesion_id+\".npy\"))\n",
    "    img = np.expand_dims(img,0)\n",
    "    pred_cls = M.predict(img)[0]\n",
    "    pred_cls = C.cls_names[list(pred_cls).index(pred_cls.max())]\n",
    "        \n",
    "    print(lesion_id)\n",
    "    \n",
    "    g_test = IA.get_grad(lesion_id, pred_cls=pred_cls)\n",
    "    s_test = IA.get_stest(g_test)\n",
    "\n",
    "    del M, IA\n",
    "    K.clear_session()\n",
    "    M = keras.models.load_model(model_path)\n",
    "    IA = finf.InfluenceAnalyzer(M, voi_df, all_imgs, all_cls)\n",
    "\n",
    "    I = {}\n",
    "    for f in Z_features:\n",
    "        I[f] = IA.get_avg_influence(Z_features[f], s_test)\n",
    "\n",
    "    del M, IA\n",
    "    K.clear_session()\n",
    "    M = keras.models.load_model(model_path)\n",
    "    IA = finf.InfluenceAnalyzer(M, voi_df, all_imgs, all_cls)\n",
    "    \n",
    "    df.loc[lesion_id] = [cls, pred_cls] + list(I[f] for f in df.columns[2:])\n",
    "\n",
    "    print(time.time() - t)\n",
    "    memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "529px",
    "left": "1032.27px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
